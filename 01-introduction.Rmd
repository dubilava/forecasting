# Introduction to Forecasting

```{r echo=FALSE, include=FALSE, message=FALSE}
library(ggplot2)
library(data.table)
```

Roots of forecasting extend very much to the beginning of human history. In their desire to predict the future, people have attempted to make forecasts of their own, or have used services of others. Fortunetellers, for example, have been forecast experts of some sort, basing their predictions on magic. They are less common in the current age. Astrologers, who rely on astronomical phenomena to foresee the future, maintain their relevance to this date. 

Over time, and particularly with the development of the study of econometrics, more rigorous forecasting methods have been introduced and developed. All methods -- primitive or complex, spurious or scientifically substantiated -- have one thing in common: they all rely (or, at least, pretend to rely) on *information*.

Information is key in forecasting. It comes in many forms, and is summarized in *data*. When organized and stored in a certain way -- chronologically and at regular intervals -- we end up with *time series* data. A diverse set of forecasting methods typically rely on insights from econometric analysis of time series data. In time series analysis, the implied assumption is that the past tends to repeat itself, at least to some extent. So, if we well study the past, we may be able to forecast an event with some degree of accuracy. 

Accurate forecasting is difficult. Indeed, forecasting is difficult because of all the unknowns we deal with in the process.^['*As we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknownsâ€”the ones we don't know we don't know.*'
--- Donald Ramsfeld] So, as we forecast, we are bound to make mistakes, which manifest into the *forecast errors*. We have these errors because we don't know the true model (known unknowns), so we make a guess about the most suitable model for time series analysis, leading to *model uncertainty*. We also have the errors because we don't know the true parameters of the model (unknown knowns). Instead, using a subset of history we estimate the parameters, which are prone to a sampling error due to *parameter uncertainty*. Finally, even if were to perfectly guess the true model, and even if we were to generate precise parameter estimates, our forecasts may still be off because of *temporal uncertainty* for all those factors that have never happened in the past, and only characterize the future (unknown unknowns). 

We can summarize the foregoing decomposition of the forecast error as follows:
$$\begin{aligned}
		e_{t+h|t} & = \big[y_{t+h}-E(y_{t+h}|\Omega_{t})\big]\;~~\text{(unknown unknowns)}  \\
		& + \big[E(y_{t+h}|\Omega_{t}) - g(\Omega_{t};\theta)\big]\;~~\text{(known unknowns)}  \\
		& + \big[g(\Omega_{t};\theta)-g(\Omega_{t};\hat{\theta})\big]\;~~\text{(unknown knowns)}
		\end{aligned}$$
		
where $e_{t+h|t}$ is an error of a forecast made in period $t$ for horizon $h$, $y_{t+h}$ is the realization of an event in period $t+h$, $\Omega_t$ is the information set available at the time when the forecast is made; $g(\cdot)$ is a model of choice of a forecaster applied to the data; $\theta$ is a set of parameters of the model, and $\hat{\theta}$ are their estimates.

There is no such thing as precise forecast, even if by fluke we were to exactly predict an outcome of an event. But some forecasts are better than others. And in search of such forecasts the study of time series econometrics has evolved. 

