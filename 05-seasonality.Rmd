# Seasonality

```{r echo=FALSE, include=FALSE, message=FALSE}
library(ggplot2)
library(data.table)
```


Seasonality is typically modeled as monthly or quarterly pattern, but can also be modeled as a higher frequency pattern (e.g. weekly). Some examples of time series with apparent seasonal patterns are:

- Agricultural production.
- Sales of energy products.
- Airfare (in non-pandemic times).

One way to deal with the seasonality in data is to "remove" it prior to the use of the series (i.e., work with a seasonally adjusted time series). Indeed, some economic time series are only/also available in a seasonally-adjusted form.

Otherwise, and perhaps more interestingly, we can directly model seasonality in a regression setting by incorporating seasonal dummy variables, for example. 


## Modeling

A seasonal model is given by: $$y_t = \sum_{i=1}^{s}\gamma_i d_{it} + \varepsilon_t,$$
where $s$ denotes the frequency of the data, and $d_{it}$ takes the value of 1 repeatedly after every $s$ periods, and such that $\sum_{i} d_{it} = 1$, $\forall t$.

Alternatively the seasonal model can be rewritten as: $$y_t = \alpha + \sum_{i=1}^{s-1}\delta_i d_{it} + \varepsilon_t,$$ in which case $\alpha$ is an intercept of an omitted season, and $\delta_i$ represents a deviation from it during the $i^{th}$ season. This is a more typical form of a seasonal model.

Both variants of a seasonal model result in an identical fit and forecasts.

When dealing with weekly or daily data, the dummy variable approach of modeling seasonality may not be practical, nor efficient in most instances, as that will require estimating another 51 or 364 parameters. A way to model seasonality without giving up too many degrees of freedom is by using the so-called harmonic seasonal variables, which are a set of Fourier terms. 

The Fourier terms can be applied to model seasonality at any frequency, indeed. Suppose, for example, we are working with monthly time series. A model with Fourier terms will have the following form: $$y_t = \alpha+\sum_{k=1}^{K}\left[\beta_{1k}\sin\left(\frac{2\pi kt}{12}\right)+\beta_{2k}\cos\left(\frac{2\pi kt}{12}\right)\right]+\varepsilon_t,$$ where the value of $K$ can be determined using an information criterion (e.g., AIC or SIC). 


## Forecasting

The predictors of the seasonal models are pre-determined, which means, after fitting the model, we can directly obtain the point and interval forecasts  for any horizon $h$.

When using the dummy variable approach to model the seasonality, for example, a future realization of a random variable is: $$y_{t+h} = \alpha + \sum_{i=1}^{s-1}\delta_i d_{i,t+h} + \varepsilon_{t+h}.$$ 

The optimal forecast of $y_{t+h}$ is: $$y_{t+h|t} = E(y_{t+h}|\Omega_t) = \alpha + \sum_{i=1}^{s-1}\delta_i d_{i,t+h}$$

The forecast error is: $$e_{t+h|t} = y_{t+h} - y_{t+h|t} = \varepsilon_{t+h}$$

The forecast variance is: $$\sigma_{t+h|t}^2 = E(e_{t+h|t}^2) =  E(\varepsilon_{t+h}^2) = \hat{\sigma}^2,\;~~\forall\;h$$

The interval forecast is: $$y_{t+h|t} \pm 1.96 \hat{\sigma}.$$

<!-- ## Exercise -->

<!-- ```{r echo=TRUE, message=FALSE, cache=TRUE} -->
<!-- # set the length of a time series to 180 (e.g., 15 years of monthly data) -->
<!-- n <- 180 -->

<!-- # set seed to 2 and generate a sequence of standard normal error terms -->
<!-- set.seed(2) -->
<!-- e <- rnorm(n) -->

<!-- # suppose the data generating process of a time series is:  -->
<!-- # y_{t} = 0.7*y_{t-1}+0.01*t+e_{t} -->
<!-- # simulate these series, assume y_{0} = 0. -->
<!-- y <- e -->

<!-- y[1] <- 0.01+e[1] -->

<!-- for(i in 2:n){ -->
<!--   y[i] <- 0.7*y[i-1]+0.05*i-0.0002*i^2+e[i] -->
<!-- } -->

<!-- # store the simulated series in a data.table, where the first column is a column of dates -->
<!-- dt <- data.table(year=seq(as.Date("1980-01-01"),by="quarter",along.with=y),y=y,trend=c(1:n)) -->

<!-- # plot the series (using ggplot) -->
<!-- ggplot(dt,aes(x=year,y=y))+ -->
<!--   geom_line(size=1)+ -->
<!--   theme_classic()+ -->
<!--   theme(axis.title=element_text(size=14),axis.text=element_text(size=12)) -->

<!-- # suppose we think the linear trend model is appropriate; use the first 120 observations  -->
<!-- # to estimate trend, and using this estimate, generate forecasts for the remaining series -->
<!-- R <- round(.75*n) -->

<!-- reg <- lm(y[1:R]~trend[1:R],data=dt) -->

<!-- # store the vector of coefficients -->
<!-- theta <- reg$coefficients -->

<!-- # calculate the residual standard deviation -->
<!-- sigma <- sqrt(crossprod(reg$residuals)/(R-2)) -->

<!-- # generated and include in the dataset the fitted values and 90% CI bounds -->
<!-- dt[,`:=`(yhat=(theta[1]+theta[2]*trend))] -->
<!-- dt[,`:=`(y.lo=(yhat-1.96*as.vector(sigma)),y.hi=(yhat+1.96*as.vector(sigma)))] -->

<!-- # set the fitted values of the in-sample range to NA -->
<!-- dt[trend <= R,c("yhat","y.lo","y.hi")] <- NA -->

<!-- # re-arrange the dataset into the "long" format (helpful for plotting) -->
<!-- dt_long <- melt(dt[,.(year,y,yhat,y.lo,y.hi)],id.vars="year") -->

<!-- # plot the out-of-sample forecasts along with the observed time series -->
<!-- ggplot(dt_long,aes(x=year,y=value,color=variable,linetype=variable))+ -->
<!--   geom_line(na.rm=T,size=1)+ -->
<!--   scale_color_manual(breaks = c("y","yhat","y.lo","y.hi"),labels = c("time series","point forecast","lower bound","upper bound"),values = c("darkgray","goldenrod","black","black"))+ -->
<!--   scale_linetype_manual(breaks = c("y","yhat","y.lo","y.hi"),labels = c("time series","point forecast","lower bound","upper bound"),values = c(1,1,2,2))+ -->
<!--   theme_classic()+ -->
<!--   theme(axis.title=element_text(size=14),axis.text=element_text(size=12),legend.position = c(.1,.9),legend.title=element_blank()) -->
<!-- ``` -->
