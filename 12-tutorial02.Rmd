# Tutorial 2: Data Management {-}

```{r echo=FALSE, include=FALSE, message=FALSE}
library(ggplot2)
library(data.table)
```

In this tutorial, we will introduce several simple R functions, and will perform a basic forecasting exercise.

Let's generate a sequence of 200 iid random variables with mean zero and variance 4, call it e.

```{r echo=TRUE}
set.seed(1)
e <- rnorm(200,0,2)
```

Notice that prior to sampling we set seed to some value (to one in this instance). We do so to ensure that we can exactly replicate the sample in the future.

Next, generate a sequence of 200 binary variables, call it x.

```{r echo=TRUE}
set.seed(2)
x <- sample(c(0,1),200,replace=T)
```

Construct a dependent variable, y, using the following formula: $y=2+0.5x+e$.

```{r echo=TRUE}
y <- 2+0.5*x+e
```

Regress y on x, using the `lm()` function, to obtain estimates of the intercept and slope parameters. 

```{r echo=TRUE}
ols <- lm(y~x)
ols
```

Generate some "future" realizations (100 observations) of y.

```{r echo=TRUE}
set.seed(3)
e <- rnorm(100,0,2)

set.seed(4)
x <- sample(c(0,1),100,replace=T)

y <- 2+0.5*x+e

```

Note that these represent actual realizations of the variable; these not forecasts.

Suppose we think that in the considered forecast period, x only takes on 1 (below we will refer to this as the Model 1). Based on this, and using parameter estimates from above, let's generate forecasts for this period.

```{r echo=TRUE}
y_f1 <- ols$coefficients[1]+ols$coefficients[2]*rep(1,100)
```

At this point, we have actual realisations of y and its forecasts. Thus, we can obtain forecast errors, mean absolute forecast errors, and root mean square forecast errors.

```{r echo=TRUE}
e_f1 <- y-y_f1

mafe1 <- mean(abs(e_f1))
rmsfe1 <- sqrt(mean(e_f1^2))

mafe1
rmsfe1
```


Suppose, instead, we think that in the considered forecast period x only takes on 0 (below we will refer to this as the Model 2). Based on this, and using parameter estimates from above, let's generate forecasts for this period.

```{r echo=TRUE}
y_f0 <- ols$coefficients[1]+ols$coefficients[2]*rep(0,100)
```

Using these forecasts, obtain forecast errors, mean absolute forecast errors, and root mean square forecast errors.

```{r echo=TRUE}
e_f0 <- y-y_f0

mafe0 <- mean(abs(e_f0))
rmsfe0 <- sqrt(mean(e_f0^2))

mafe0
rmsfe0
```

By comparing the two sets of forecasts, we can observe a somewhat rare and yet not an unlikely scenario: MAFE points to the Model 1 as more accurate of the two models, while RMSFE suggests the Model 2 as the more accurate one. More often than not, however, these two accuracy measures tend to agree.