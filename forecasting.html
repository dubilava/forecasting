<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Forecasting With Econometric Time Series Models Using R" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/forecasting-logo.png" />
<meta property="og:description" content="Forecasting With Econometric Time Series Models Using R" />


<meta name="author" content="David Ubilava" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Forecasting With Econometric Time Series Models Using R">

<title>Forecasting With Econometric Time Series Models Using R</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Forecasting With Econometric Time Series Models Using R<p><p class="author">David Ubilava</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="#foreword">Foreword</a>
<a href="#forecasting-with-time-series-models">Forecasting With Time Series Models</a>
<a href="#introduction-to-forecasting"><span class="toc-section-number">1</span> Introduction to Forecasting</a>
<a href="#features-of-time-series-data"><span class="toc-section-number">2</span> Features of Time Series Data</a>
<a href="#r-spectral-fig.capspectral-density-echofalse-messagefalse-n---120-set.seedn-y---rnormn-fori-in-2n-yi.7yi-1.00iyi-dt---data.tabley-dty1shifty1-ar1---lmyy1dt-b1---ar1coefficientsy1-e1---ar1residuals-spec_dense---functionxmt10-gamma---cacfyplotftypecovariancelag.max-mt0mtacf-j---0mt-omega---ifelsejmt21-6jmt26jmt321-jmt3-12piomega1gamma12sumomega2mt1gamma2mt1cosxc1mt-lambda---seq0pi.01-fl1---sapplylambdaspec_densemtroundn12-fl2---sapplylambdaspec_densemtroundn13-dt---data.tablelambdafl1fl2-lg_dt---meltdtid.varslambdavariable.namecutoffvalue.namespectrum-lg_dtcutoff---factorlg_dtcutofflevelscfl1fl2labelscpaste0mroundn12paste0mroundn13-ggplotlg_dtaesxlambdayspectrumcolorcutofflinetypecutoff-geom_linesize1-scale_color_manualvaluescsteelblueindianred-scale_linetype_manualvaluesc15-labsxexpressionlambdayexpressionflambdam-theme_classic-themeaxis.titleelement_textsize14axis.textelement_textsize12legend.positionc.82.78legend.textelement_texthjust0size12legend.titleelement_blank"><span class="toc-section-number">3</span> <code>{r spectral, fig.cap="Spectral Density", echo=FALSE, message=FALSE} # n &lt;- 120 #  # set.seed(n) # y &lt;- rnorm(n) # for(i in 2:n){ #   y[i]=.7*y[i-1]+.00*i+y[i] # } #  # dt &lt;- data.table(y) # dt[,`:=`(y1=shift(y,1))] #  # ar1 &lt;- lm(y~y1,dt) # b1 &lt;- ar1$coefficients["y1"] # e1 &lt;- ar1$residuals #  # spec_dense &lt;- function(x,mt=10){ #   gamma &lt;- c(acf(y,plot=F,type="covariance",lag.max = mt)[0:mt]$acf) #   j &lt;- 0:mt #   omega &lt;- ifelse(j&lt;=mt/2,1-6*(j/mt)^2+6*(j/mt)^3,2*(1-j/mt)^3) #   (1/(2*pi))*(omega[1]*gamma[1]+2*sum(omega[2:(mt+1)]*gamma[2:(mt+1)]*cos(x*c(1:mt)))) # } #  # lambda &lt;- seq(0,pi,.01) #  # fl1 &lt;- sapply(lambda,spec_dense,mt=round(n^(1/2))) # fl2 &lt;- sapply(lambda,spec_dense,mt=round(n^(1/3))) #  # dt &lt;- data.table(lambda,fl1,fl2) # lg_dt &lt;- melt(dt,id.vars="lambda",variable.name="cutoff",value.name="spectrum") # lg_dt$cutoff &lt;- factor(lg_dt$cutoff,levels=c("fl1","fl2"),labels=c(paste0("m=",round(n^(1/2))),paste0("m=",round(n^(1/3))))) #  # ggplot(lg_dt,aes(x=lambda,y=spectrum,color=cutoff,linetype=cutoff))+ #   geom_line(size=1)+ #   scale_color_manual(values=c("steelblue","indianred"))+ #   scale_linetype_manual(values=c(1,5))+ #   labs(x=expression(lambda),y=expression(f(lambda,m)))+ #   theme_classic()+ #   theme(axis.title=element_text(size=14),axis.text=element_text(size=12),legend.position=c(.82,.78),legend.text=element_text(hjust=0,size=12),legend.title=element_blank()) #</code></a>
<a href="#forecasting-methods-and-routines"><span class="toc-section-number">4</span> Forecasting Methods and Routines</a>
<a href="#trends-and-seasonality"><span class="toc-section-number">5</span> Trends and Seasonality</a>
<a href="#autoregressive-models"><span class="toc-section-number">6</span> Autoregressive Models</a>
<a href="#vector-autoregressive-models"><span class="toc-section-number">7</span> Vector Autoregressive Models</a>
<a href="#dynamic-factor-models"><span class="toc-section-number">8</span> Dynamic Factor Models</a>
<a href="#threshold-autoregressive-models"><span class="toc-section-number">9</span> Threshold Autoregressive Models</a>
<a href="#forecast-evaluation"><span class="toc-section-number">10</span> Forecast Evaluation</a>
<a href="#forecast-combination"><span class="toc-section-number">11</span> Forecast Combination</a>
<a href="#forecasting-using-r">Forecasting Using R</a>
<a href="#tutorial-1-introduction-to-r">Tutorial 1: Introduction to R</a>
<a href="#tutorial-2-data-management">Tutorial 2: Data Management</a>
<a href="#tutorial-3-forecasting-methods-and-routines">Tutorial 3: Forecasting Methods and Routines</a>
<a href="#tutorial-4-trends-and-seasonality">Tutorial 4: Trends and Seasonality</a>
<a href="#tutorial-5-autoregressive-models">Tutorial 5: Autoregressive Models</a>
<a href="#tutorial-6-vector-autoregressive-models">Tutorial 6: Vector Autoregressive Models</a>
<a href="#tutorial-7-dynamic-factor-models">Tutorial 7: Dynamic Factor Models</a>
<a href="#tutorial-8-threshold-autoregression">Tutorial 8: Threshold Autoregression</a>
<a href="#tutorial-9-forecast-evaluation">Tutorial 9: Forecast Evaluation</a>
<a href="#tutorial-10-forecast-combination">Tutorial 10: Forecast Combination</a>
</div>
</li>
</ul>
</div>
<!--bookdown:toc:end-->

<!--bookdown:body:start-->
<div id="foreword" class="section level1 unnumbered">
<h1 class="unnumbered">Foreword</h1>
<p><span class="newthought">What is forecast</span> if not a guess? An educated guess, nonetheless. A good guess doesn’t have to be precise. It almost never is, only if by fluke. An imprecise guess can be of value to a forecaster. That we were unable to exactly predict an event, tells us something about the underlying processes that result in an outcome different from what we predicted. Such conjecture can be useful. Forecasting, even if inaccurate, can be useful. George Box’s ‘all models are wrong but some are useful’ is certainly suitable to the study of forecasting.</p>
<p>Our inability to make perfect forecasts is best summarized in a quote typically attributed to Niels Bohr:<label for="tufte-sn-1" class="margin-toggle sidenote-number">1</label><input type="checkbox" id="tufte-sn-1" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">1</span> The exact origin of this saying, or its variant, is somewhat murky. It appears to had been adopted from a Danish proverb.</span> ‘it is difficult to make predictions, especially about the future.’ I came across this quote as I was wrapping up my doctoral dissertation at Purdue University. The title of my dissertation was ‘Nonlinear Multivariate Modeling and Forecasting of Commodity Prices.’ A chapter of my dissertation, which was largely a forecasting exercise, yielded the so-called ‘null result.’ I felt uneasy about it. I had an urge to justify, somehow, this null result. And then I stumbled across this quote, which ‘saved my day.’ I stuck it as an epigraph of my dissertation. It captured my struggles as a forecaster, and provided the context to the results of my work.</p>
<p>Some years later, I started teaching a course on economic forecasting. As I introduce the subject, I tend to spend a great deal of time explaining—indeed preparing students for the inevitable—that forecasting is difficult, and that more often than not we will not be able to give accurate forecasts. But this should not discourage us from trying, I also stress, because most great achievements have myriads of failed attempts as a foundation. And in any case, a forecast—however inaccurate—is a successful outcome of a thought process directed toward achieving the impossible—making a perfect guess about the unknown.</p>
<p>This book introduces econometric models designed to analyse time series with a specific focus on the use of these models in predicting future realizations of the data.</p>
<!--chapter:end:index.Rmd-->
</div>
<div id="forecasting-with-time-series-models" class="section level1 unnumbered">
<h1 class="unnumbered">Forecasting With Time Series Models</h1>
</div>
<div id="introduction-to-forecasting" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction to Forecasting</h1>
<p><span class="newthought">Roots of forecasting</span> extend very much to the beginning of human history. In their desire to predict the future, people have attempted to make forecasts of their own, or have used services of others. Fortunetellers, for example, have been forecast experts of some sort, basing their predictions on magic. They are less common in the current age. Astrologers, who rely on astronomical phenomena to foresee the future, maintain their relevance to this date.</p>
<p>Over time, and particularly with the development of the study of econometrics, more rigorous forecasting methods have been introduced and developed. All methods – primitive or complex, spurious or scientifically substantiated – have one thing in common: they all rely (or, at least, pretend to rely) on <em>information</em>.</p>
<p>Information is key in forecasting. It comes in many forms, and is summarized in <em>data</em>. When organized and stored in a certain way – chronologically and at regular intervals – we end up with <em>time series</em> data. A diverse set of forecasting methods typically rely on insights from econometric analysis of time series data. In time series analysis, the implied assumption is that the past tends to repeat itself, at least to some extent. So, if we well study the past, we may be able to forecast an event with some degree of accuracy.</p>
<p>Accurate forecasting is difficult. Indeed, forecasting is difficult because of all the unknowns we deal with in the process.<label for="tufte-sn-2" class="margin-toggle sidenote-number">2</label><input type="checkbox" id="tufte-sn-2" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">2</span> ‘<em>As we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns—the ones we don’t know we don’t know.</em>’
— Donald Ramsfeld</span> So, as we forecast, we are bound to make mistakes, which manifest into the <em>forecast errors</em>. We have these errors because we don’t know the true model (known unknowns), so we make a guess about the most suitable model for time series analysis, leading to <em>model uncertainty</em>. We also have the errors because we don’t know the true parameters of the model (unknown knowns). Instead, using a subset of history we estimate the parameters, which are prone to a sampling error due to <em>parameter uncertainty</em>. Finally, even if were to perfectly guess the true model, and even if we were to generate precise parameter estimates, our forecasts may still be off because of <em>temporal uncertainty</em> for all those factors that have never happened in the past, and only characterize the future (unknown unknowns).</p>
<p>We can present the foregoing decomposition of the forecast uncertainty, in terms of a forecast error, as follows:
<span class="math display">\[\begin{aligned}
        e_{t+h} &amp;= y_{t+h}-\hat{y}_{t+h}\;~~\text{(forecast uncertainty)}   \\
        &amp; = \big[y_{t+h}-E(y_{t+h}|\Omega_{t})\big]\;~~\text{(temporal uncertainty)}  \\
        &amp; + \big[E(y_{t+h}|\Omega_{t}) - g(\Omega_{t};\theta)\big]\;~~\text{(model uncertainty)}  \\
        &amp; + \big[g(\Omega_{t};\theta)-\hat{y}_{t+h}\big]\;~~\text{(parameter uncertainty)}
        \end{aligned}\]</span></p>
<p>where <span class="math inline">\(e_{t+h|t}\)</span> is an error of a forecast made in period <span class="math inline">\(t\)</span> for horizon <span class="math inline">\(h\)</span>, <span class="math inline">\(y_{t+h}\)</span> is the realization of an event in period <span class="math inline">\(t+h\)</span>, and <span class="math inline">\(\hat{y}_{t+h}\)</span> is the forecast of the event, which is based on the information set, <span class="math inline">\(\Omega_t\)</span>, at the time when the forecast is made using a forecaster’s model of choice, <span class="math inline">\(g(\cdot)\)</span>, that typically involves a set of parameters, <span class="math inline">\(\theta\)</span>, which we don’t know and need to estimate.</p>
<p>There is no such thing as precise forecast, even if by fluke we were to exactly predict an outcome of an event. But some forecasts are better than others. And in search of such forecasts the study of time series econometrics has evolved.</p>
<!--chapter:end:01-introduction.Rmd-->
</div>
<div id="features-of-time-series-data" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Features of Time Series Data</h1>
<p><span class="newthought">A time series</span> is an observed sequence of realizations of chronologically stored random variables. The sequence of random variables is referred to as the <em>stochastic process</em>. Thus, a time series is a realization of a stochastic process.</p>
<p>We index time periods as <span class="math inline">\(1,2,\ldots,T\)</span>, so that a time series is represented by a set of observations <span class="math inline">\(\{y_t:t=1,\ldots,T\}\)</span>. We can think of a time series as a finite sample from an underlying doubly–infinite sequence: <span class="math inline">\(\{\ldots,y_{-1},y_{0},y_1,y_2,\ldots,y_T,y_{T+1},y_{T+2},\ldots\}\)</span>. This is to say that the history extends beyond the starting and ending time periods of the sample at hand.</p>
<div id="stationarity" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Stationarity</h2>
<p>If all random variables, from where the time series are drawn, have the same distribution, then we refer to such data as <em>stationary</em> time series. Stationarity is an important feature, and the assumption on which the time series analysis heavily relies.</p>
<p>Consider a simplest kind of a time series comprised of realizations from independent and identically distributed normal random variable with zero mean and constant variance: <span class="math inline">\(\e_t \sim iid\left(0,\sigma^2\right)\)</span>. The following graph plots this time series against time.</p>
<div class="figure">
<p class="caption marginnote shownote">
(#fig:white-noise)White noise
</p>
<img src="forecasting_files/figure-html/white-noise-1.png" alt="White noise" width="624"  />
</div>
<p>Such time series are referred to as <em>white noise</em>. That is, a time series <span class="math inline">\(\{x_t: t=1,\ldots,T\}\)</span>, is a white noise process if:
<span class="math display">\[\begin{align*}
&amp; E(x_t) = 0,\;~\forall~t\\
&amp; Var(x_t) = \sigma^2,\;~\forall~t\\
&amp; Cov(x_t,x_{t-k}) = 0,\;~\forall~k \ne 0
\end{align*}\]</span></p>
<p>Because each observation is drawn from the same distribution, white noise is a stationary time series. Indeed, it is a special type of stationary time series insofar as its mean, variance, and covariance are time-invariant. Note, for a time series to be stationary, neither the mean nor the covariances need to be equal to zero. Thus, <span class="math inline">\(\{x_t\}\)</span> is stationary if the mean and variance are independent of <span class="math inline">\(t\)</span>, and the autocovariances are independent of <span class="math inline">\(t\)</span> for all <span class="math inline">\(k\)</span>.</p>
</div>
<div id="serial-dependence" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Serial Dependence</h2>
<p>It is more of the norm rather than the exception for a time series to be correlated over time. Indeed, because of the sequential nature of time series, we commonly observe dependence among the temporally adjacent time series. That is, for most economic time series, we would expect <span class="math inline">\(x_t\)</span> and <span class="math inline">\(x_{t-1}\)</span> to be correlated. Such correlation, referred to as the first order <em>autocorrelations</em>, is given by: <span class="math inline">\(\rho_1=Cor(x_{t},x_{t-1}) = \frac{Cov(x_{t},x_{t-k})}{Var(x_t)}\)</span>. In general, the <span class="math inline">\(k^{th}\)</span> order autocorrelation is given by: <span class="math display">\[\rho_k=Cor(x_{t},x_{t-k}) = \frac{Cov(x_{t},x_{t-k})}{Var(x_{t})},\;~~k=1,2,\ldots\]</span></p>
<p>Autocorrelations are commonly illustrated via the so-called <em>autocorrelogram</em>, which plots the sequence of autocorrelation coefficients against the lags at which these coefficients are obtained. The following figure illustrates an autocorrelogram up to the 12th lag:</p>
<div class="figure">
<p class="caption marginnote shownote">
(#fig:acf)Autocorrelation
</p>
<img src="forecasting_files/figure-html/acf-1.png" alt="Autocorrelation" width="624"  />
</div>
<p>For each lag, <span class="math inline">\(k\)</span>, the vertical line extending from zero represents the autocorrelation coefficient at that lag. The dashed lines denote the 95% confidence interval, given by <span class="math inline">\(\pm 1.96/\sqrt{T}\)</span>, where <span class="math inline">\(T\)</span> is the length of the time series.</p>
<p>Another relevant measure of the time series dependence is <em>partial</em> autocorrelation, which is correlation between <span class="math inline">\(x_t\)</span> and <span class="math inline">\(x_{t-k}\)</span> net of any correlations between <span class="math inline">\(x_t\)</span> and <span class="math inline">\(x_{t-k+j}\)</span>, for all <span class="math inline">\(j=1,\ldots,k-1\)</span>. Similar to autocorrelations, partial autocorrelations can also be illustrated using autocorrelograms:</p>
<div class="figure">
<p class="caption marginnote shownote">
(#fig:pacf)Partial Autocorrelation
</p>
<img src="forecasting_files/figure-html/pacf-1.png" alt="Partial Autocorrelation" width="624"  />
</div>
</div>
</div>
<div id="r-spectral-fig.capspectral-density-echofalse-messagefalse-n---120-set.seedn-y---rnormn-fori-in-2n-yi.7yi-1.00iyi-dt---data.tabley-dty1shifty1-ar1---lmyy1dt-b1---ar1coefficientsy1-e1---ar1residuals-spec_dense---functionxmt10-gamma---cacfyplotftypecovariancelag.max-mt0mtacf-j---0mt-omega---ifelsejmt21-6jmt26jmt321-jmt3-12piomega1gamma12sumomega2mt1gamma2mt1cosxc1mt-lambda---seq0pi.01-fl1---sapplylambdaspec_densemtroundn12-fl2---sapplylambdaspec_densemtroundn13-dt---data.tablelambdafl1fl2-lg_dt---meltdtid.varslambdavariable.namecutoffvalue.namespectrum-lg_dtcutoff---factorlg_dtcutofflevelscfl1fl2labelscpaste0mroundn12paste0mroundn13-ggplotlg_dtaesxlambdayspectrumcolorcutofflinetypecutoff-geom_linesize1-scale_color_manualvaluescsteelblueindianred-scale_linetype_manualvaluesc15-labsxexpressionlambdayexpressionflambdam-theme_classic-themeaxis.titleelement_textsize14axis.textelement_textsize12legend.positionc.82.78legend.textelement_texthjust0size12legend.titleelement_blank" class="section level1" number="3">
<h1><span class="header-section-number">3</span> <code>{r spectral, fig.cap="Spectral Density", echo=FALSE, message=FALSE} # n &lt;- 120 #  # set.seed(n) # y &lt;- rnorm(n) # for(i in 2:n){ #   y[i]=.7*y[i-1]+.00*i+y[i] # } #  # dt &lt;- data.table(y) # dt[,`:=`(y1=shift(y,1))] #  # ar1 &lt;- lm(y~y1,dt) # b1 &lt;- ar1$coefficients["y1"] # e1 &lt;- ar1$residuals #  # spec_dense &lt;- function(x,mt=10){ #   gamma &lt;- c(acf(y,plot=F,type="covariance",lag.max = mt)[0:mt]$acf) #   j &lt;- 0:mt #   omega &lt;- ifelse(j&lt;=mt/2,1-6*(j/mt)^2+6*(j/mt)^3,2*(1-j/mt)^3) #   (1/(2*pi))*(omega[1]*gamma[1]+2*sum(omega[2:(mt+1)]*gamma[2:(mt+1)]*cos(x*c(1:mt)))) # } #  # lambda &lt;- seq(0,pi,.01) #  # fl1 &lt;- sapply(lambda,spec_dense,mt=round(n^(1/2))) # fl2 &lt;- sapply(lambda,spec_dense,mt=round(n^(1/3))) #  # dt &lt;- data.table(lambda,fl1,fl2) # lg_dt &lt;- melt(dt,id.vars="lambda",variable.name="cutoff",value.name="spectrum") # lg_dt$cutoff &lt;- factor(lg_dt$cutoff,levels=c("fl1","fl2"),labels=c(paste0("m=",round(n^(1/2))),paste0("m=",round(n^(1/3))))) #  # ggplot(lg_dt,aes(x=lambda,y=spectrum,color=cutoff,linetype=cutoff))+ #   geom_line(size=1)+ #   scale_color_manual(values=c("steelblue","indianred"))+ #   scale_linetype_manual(values=c(1,5))+ #   labs(x=expression(lambda),y=expression(f(lambda,m)))+ #   theme_classic()+ #   theme(axis.title=element_text(size=14),axis.text=element_text(size=12),legend.position=c(.82,.78),legend.text=element_text(hjust=0,size=12),legend.title=element_blank()) #</code></h1>
<div id="transformations" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Transformations</h2>
<p>It is common to transform time series by taking logarithms, differences, or differences of logarithms (growth rates). Such transformations are done to work with a suitable variable for the desired econometric analysis, or to address some underlying issue of the series. For example, if an economic time series is characterized by an apparent exponential growth (e.g., real GDP), by taking natural logarithms we ‘flatten’ the curve and make the fluctuations around the trend proportionate over time. The following graph illustrates this.</p>
<div class="figure">
<p class="caption marginnote shownote">
(#fig:ts)Australian Real GDP and its transformations.
</p>
<img src="forecasting_files/figure-html/ts-1.png" alt="Australian Real GDP and its transformations." width="624"  />
</div>
<p>The three panels of the graph illustrate (i) a time series with an apparent exponential growth, (ii) the natural logarithm of this time series, and (iii) their differences (i.e., the log-differences of the original series).</p>
<!--chapter:end:02-timeseries.Rmd-->
</div>
</div>
<div id="forecasting-methods-and-routines" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Forecasting Methods and Routines</h1>
<div id="optimal-forecast" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Optimal Forecast</h2>
<p>A forecast is a random variable which has some distribution and, thus, moments. The simplest form of a forecast is a point forecast (usually a mean of the distribution, but can be a median or, indeed, any quantile).</p>
<p>A point forecast made in period <span class="math inline">\(t\)</span> for horizon <span class="math inline">\(h\)</span> can be denoted as <span class="math inline">\(y_{t+h|t}\)</span>; this is our ‘best guess’, that is made in period <span class="math inline">\(t\)</span>, about the actual realization of the random variable in period <span class="math inline">\(t+h\)</span>, denoted by <span class="math inline">\(y_{t+h}\)</span>. The difference between the two is the forecast error. That is, <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t}\]</span></p>
<p>The more accurate is the forecast the smaller is the forecast error. And while on average the forecast error is zero (assuming the forecast is unbiased), the forecast error variance is non-zero, implying uncertainty surrounding a pont forecast. Thus, as uncertainty cannot be avoided, a forecaster is bound to commit forecast errors. The goal of the forecaster is to minimize the ‘cost’ associated with the forecast errors. This is achieved by minimizing the expected loss function.</p>
<p>A loss function, <span class="math inline">\(L(e_{t+h|t})\)</span>, can take many different forms, but is should satisfy the following properties:
<span class="math display">\[\begin{aligned}
        &amp; L(e_{t+h|t}) = 0,\;~~\forall\;e_{t+h|t} = 0 \\
        &amp; L(e_{t+h|t}) \geq 0,\;~~\forall\;e_{t+h|t} \neq 0 \\
        &amp; L(e_{t+h|t}^{(i)}) &gt; L(e_{t+h|t}^{(j)}),\;~~\forall\;|e_{t+h|t}^{(i)}| &gt; |e_{t+h|t}^{(j)}|
        \end{aligned}\]</span></p>
<p>Two commonly used symmetric loss functions are <em>absolute</em> and <em>quadratic</em> loss functions:
<span class="math display">\[\begin{aligned}
        &amp; L{(e_{t+h|t})} = |e_{t+h|t}|\;~~\text{(absolute loss function)} \\
        &amp; L{(e_{t+h|t})} = (e_{t+h|t})^2\;~~\text{(quadratic loss function)}
        \end{aligned}\]</span></p>
<p>The quadratic loss function is popular, partly because we typically select models based on ‘in-sample’ quadratic loss (i.e. by minimizing the sum of squared residuals).</p>
<p>Optimal forecast is the forecast that minimizes the expected loss:
<span class="math display">\[\min_{y_{t+h|t}} E\left[L\left(e_{t+h|t}\right)\right] = \min_{y_{t+h|t}} E\left[L\left(y_{t+h}-y_{t+h|t}\right)\right]\]</span>
where the expected loss is given by:
<span class="math display">\[E\left[L\left(y_{t+h}-y_{t+h|t}\right)\right]=\int L\left(y_{t+h}-y_{t+h|t}\right) f(y_{t+h}|\Omega_t)dy\]</span></p>
<p>We can assume that the conditional density is a normal density with mean <span class="math inline">\(\mu_{t+h} \equiv E(y_{t+h})\)</span>, and variance <span class="math inline">\(\sigma_{t+h}^2 \equiv Var(y_{t+h})\)</span>.</p>
<p>Under the assumption of the quadratic loss function:
<span class="math display">\[\begin{aligned}
        E\left[L(e_{t+h|t})\right] &amp; = E(e_{t+h|t}^2) = E(y_{t+h} - \hat{y}_{t+h|t})^2 \\
        &amp; = E(y_{t+h}^2)-2E(y_{t+h})\hat{y}_{t+h|t} + \hat{y}_{t+h|t}^2
        \end{aligned}\]</span></p>
<p>By solving the optimization problem it follows that: <span class="math display">\[\hat{y}_{t+h|t} = E(y_{t+h}) \equiv \mu_{t+h}\]</span></p>
<p>Thus, the optimal point forecast under the quadratic loss is the <em>mean</em> (for reference, the optimal point forecast under absolute loss is the <em>median</em>).</p>
</div>
<div id="measuring-the-accuracy-of-forecasts" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Measuring the Accuracy of Forecasts</h2>
<p>Forecast accuracy should only be determined by considering how well a model performs on data not used in estimation. But to assess forecast accuracy we need access to the data, typically from future time periods, that was not used in estimation. This leads to the so-called ‘pseudo forecasting’ routine. This routine involves splitting the available data into two segments referred to as ‘in-sample’ and ‘out-of-sample’. The in-sample segment of a series is also known as the ‘estimation set’ or the ‘training set’. The out-of-sample segment of a series is also known as the ‘hold-out set’ or the ‘test set’.</p>
<p>Thus, we make the so-called ‘genuine’ forecasts using only the information from the estimation set, and assess the accuracy of these forecasts in an out-of-sample setting.</p>
<p>Because forecasting is often performed in a time series context, the estimation set typically predates the hold-out set. In non-dynamic settings such chronological ordering may not be necessary, however.</p>
<p>There are different forecasting schemes for updating the information set in the pseudo-forecasting routine. These are: <em>recursive</em>, <em>rolling</em>, and <em>fixed</em>.</p>
<ul>
<li>The recursive forecasting environment uses a sequence of expanding windows to update model estimates and the information set.</li>
<li>The rolling forecasting environment uses a sequence of rolling windows of the same size to update model estimates and the information set.</li>
<li>The fixed forecasting environment uses one fixed window for model estimates, and only updates the information set.</li>
</ul>
<p>The following animation illustrates the distinctive features of these three routines:</p>
<p><img src="forecasting_files/figure-html/routines-1.png" width="624"  /></p>
</div>
<div id="evaluating-time-series-forecasts" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Evaluating Time Series Forecasts</h2>
<p>To evaluate forecasts of a time series, <span class="math inline">\(\{y_t\}\)</span>, with a total of <span class="math inline">\(T\)</span> observations, we divide the sample into two parts, the in-sample set with a total of <span class="math inline">\(R\)</span> observations, such that <span class="math inline">\(R &lt; T\)</span> (typically, <span class="math inline">\(R \approx 0.75T\)</span>), and the out-of-sample set.</p>
<p>For example, if we are interested in one-step-ahead forecast assessment, this way we will produce a sequence of forecasts: <span class="math inline">\(\{y_{R+1|R},y_{R+2|{R+1}},\ldots,y_{T|{T-1}}\}\)</span> for <span class="math inline">\(\{Y_{R+1},Y_{R+2},\ldots,Y_{T}\}\)</span>.</p>
<p>Forecast errors, <span class="math inline">\(e_{R+j} = y_{R+j} - y_{R+j|{R+j-1}}\)</span>, then can be computed for <span class="math inline">\(j = 1,\ldots,T-R\)</span>.</p>
<p>The most commonly applied accuracy measures are the mean absolute forecast error (MAFE) and the root mean squared forecast error (RMSFE):
<span class="math display">\[\begin{aligned}
\text{MAFE}  = &amp; \frac{1}{P}\sum_{i=1}^{P}|e_i|\\
\text{RMSFE} = &amp; \sqrt{\frac{1}{P}\sum_{i=1}^{P}e_i^2}
\end{aligned}\]</span>
where <span class="math inline">\(P\)</span> is the total number of out-of-sample forecasts. The lower is the accuracy measure (of choice), the better a given model performs in generating accurate forecasts. As noted earlier, ‘better’ does not mean ‘without errors’.</p>
<p>Forecast errors of a ‘good’ forecasting method will have the following properties:</p>
<ul>
<li>zero mean; otherwise, the forecasts are biased.</li>
<li>no correlation with the forecasts; otherwise, there is information left that should be used in computing forecasts.</li>
<li>no serial correlation among one-step-ahead forecast errors. Note that <span class="math inline">\(k\)</span>-step-ahead forecasts, for <span class="math inline">\(k&gt;1\)</span>, can be, and usually are, serially correlated.</li>
</ul>
<p>Any forecasting method that does not satisfy these properties has a potential to be improved.</p>
<div id="unbiasedness" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Unbiasedness</h3>
<p>Testing <span class="math inline">\(E(e_{t+h|t})=0\)</span>. Set up a regression: <span class="math display">\[e_{t+h|t} = \alpha+\upsilon_{t+h} \hspace{.5in} t = R,\ldots,T-h,\]</span>
where <span class="math inline">\(R\)</span> is the estimation window size, <span class="math inline">\(T\)</span> is the sample size, and <span class="math inline">\(h\)</span> is the forecast horizon length. The null of zero-mean forecast error is equivalent of testing <span class="math inline">\(H_0: \alpha = 0\)</span> in the OLS setting. For <span class="math inline">\(h\)</span>-step-ahead forecast errors, when <span class="math inline">\(h&gt;1\)</span>, autocorrelation consistent standard errors should be used.</p>
</div>
<div id="efficiency" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Efficiency</h3>
<p>Testing <span class="math inline">\(Cov(e_{t+h|t},y_{t+h|t})=0\)</span>. Set up a regression: <span class="math display">\[e_{t+h|t} = \alpha + \beta y_{t+h|t} + \upsilon_{t+h} \hspace{.5in} t = R,\ldots,T-h.\]</span> The null of forecast error independence of the information set is equivalent of testing <span class="math inline">\(H_0: \beta = 0\)</span> in the OLS setting. For <span class="math inline">\(h\)</span>-step-ahead forecast errors, when <span class="math inline">\(h&gt;1\)</span>, autocorrelation consistent standard errors should be used.</p>
</div>
<div id="no-autocorrelation" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> No Autocorrelation</h3>
<p>Testing <span class="math inline">\(Cov(e_{t+1|t},e_{t|t-1})=0\)</span>. Set up a regression: <span class="math display">\[e_{t+1|t} = \alpha + \gamma e_{t|t-1} + \upsilon_{t+1} \hspace{.5in} t = R+1,\ldots,T-1.\]</span> The null of no forecast error autocorrelation is equivalent of testing <span class="math inline">\(H_0: \gamma = 0\)</span> in the OLS setting.</p>
<!--chapter:end:03-routines.Rmd-->
</div>
</div>
</div>
<div id="trends-and-seasonality" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Trends and Seasonality</h1>
<p>Economic time series usually are characterized by trending behavior, and often present a seasonal pattern as well. Trend is a unidirectional change of time series over an extended period of time that arises from the accumulation of information over time. Seasonality is a repeating pattern <em>within a calendar year</em> that arises from the links of technologies, preferences, and institutions to the calendar. Modeling and forecasting these time series features is a fairly straightforward task. But before we get to it, let’s discuss what may happen if we were to ignore the presence of trends and/or seasonality when analyzing the time series data.</p>
<div id="spurious-relationship" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Spurious Relationship</h2>
<p>Nothing about trending time series necessarily violates the classical linear regression model assumptions. The issue may arise, however, if an unobserved trending variable is simultaneously correlated with the dependent variable as well as one of the independent variables in a time series regression. In such case, we may find a (statistically significant) relationship between two or more unrelated economic variables simply because they are all trending. Such relationship is referred to a <em>spurious relationship</em>.</p>
<p>To illustrate, consider two trending variables: <span class="math display">\[y_t = \gamma t + \nu_t,\;~~\nu\sim N(0,\sigma_{\nu}^2),\]</span> and <span class="math display">\[x_t = \delta t + \upsilon_t,\;~~\upsilon\sim N(0,\sigma_{\upsilon}^2),\]</span> where <span class="math inline">\(Cov(\nu_t,\upsilon_t) = 0\)</span>. For simplicity, we can assume <span class="math inline">\(\sigma_{\nu}^2=\sigma_{\upsilon}^2=1\)</span>. Suppose, <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\delta\)</span> are some positive scalars, say, <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.5\)</span>, respectively. That is, <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> are trending in the same direction. Below is an example of such time series:
<img src="forecasting_files/figure-html/unnamed-chunk-6-1.png" width="624"  /></p>
<p>If we were to estimate <span class="math display">\[y_t = \alpha+\beta x_t + \varepsilon_t,\]</span> we are likely to find the relationship between the two – in this case <span class="math inline">\(\beta&gt;0\)</span> – even though, we know, the two are not related. To illustrate this, we will generate 1000 samples of size 120 for <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, and in each case we will estimate the parameter <span class="math inline">\(\beta\)</span>. The following graph illustrates the empirical distribution of these parameter estimates:
<img src="forecasting_files/figure-html/unnamed-chunk-7-1.png" width="624"  /></p>
<p>Luckily, we can easily “fix” the issue, by incorporating a trend in the regression: <span class="math display">\[y_t = \alpha+\beta x_t + \eta t + \varepsilon_t.\]</span> Once the trend is accounted for, the previously illustrated “bias” disappears. Using a similar simulation exercise as before, the following graph illustrates the empirical distribution of these parameter estimates:
<img src="forecasting_files/figure-html/unnamed-chunk-8-1.png" width="624"  /></p>
<p>In fact, this “fix” is equivalent to regressing a de-trended <span class="math inline">\(y\)</span> on a de-trended <span class="math inline">\(x\)</span>. To de-trend a variable, we first run a regression: <span class="math inline">\(y_t = \gamma_0 + \gamma_1 t + \nu_t\)</span>, and then obtain the fitted values for some fixed trend (typically zero), that is: <span class="math inline">\(\tilde{y}_t = \hat{\gamma}_0+\hat{\nu}_t\)</span>, where <span class="math inline">\(\hat{\gamma}_0\)</span> and <span class="math inline">\(\hat{\nu}_t\)</span> are the parameter estimate and the residuals from the foregoing regression.</p>
</div>
<div id="modeling" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Modeling</h2>
<p>As seen, accounting for trends in a time series can help us resolve some regression issues. But a trend in and of itself can be an inherent feature of a times series. To that end, we can apply deterministic trends to forecast time series.</p>
<p>The simplest (and perhaps most frequently applied) model to account for the trending time series is a <em>linear</em> trend model: <span class="math display">\[y_t = \alpha + \beta t\]</span></p>
<p>Other likely candidate trend specifications are <em>polynomial</em> (e.g. quadratic, cubic, etc.), <em>exponential</em>, and <em>shifting</em> (or <em>switching</em>) trend models, respectively given by:
<span class="math display">\[\begin{aligned}
    y_t &amp;= \alpha + \beta_1 t + \beta_2 t^2 + \ldots + \beta_p t^p \\
    y_t &amp;= e^{\alpha + \beta t}\;~~\mbox{or}\;~~\ln{y_t} = \alpha + \beta t \\
    y_t &amp;= \alpha + \beta_1 t + \beta_2 (t-\tau)I(t&gt;\tau),\;~~\tau\in\mathsf{T}
    \end{aligned}\]</span></p>
<p>Of these, here we will primarily consider linear and quadratic trends. An exponential trend, from the standpoint of modeling and forecasting, is equivalent to a linear trend fitted to natural logarithm of the series. For a time series <span class="math inline">\(\{y_t: t=1,\ldots,T\}\)</span>, the natural logarithm is: <span class="math inline">\(z_t = \ln{y_t}\)</span>. Some of the benefits of such a transformation are that:</p>
<ul>
<li>they are easier to interpret (relative/percentage change).</li>
<li>they homogenizes the variance of the time series.</li>
<li>they may result in improved forecasting accuracy.</li>
</ul>
<p>Exponential trends are suitable when a time series is characterized by a stable relative change over time (e.g., when economic time series grow by 2% every year).</p>
<p>We will cover the shifting/switching trend models in another chapter.</p>
<p>Trends are (relatively) easy to model and forecast. Caution is needed, however, with (higher order) polynomial trends, as they may fit well in-sample, but cause major problems out-of-sample.</p>
<p>Consider a linear trend model with an additive error term: <span class="math display">\[y_t = \alpha + \beta t + \varepsilon_t\]</span> We estimate the model parameters, <span class="math inline">\(\mathbf{\theta}=\{\alpha,\beta\}\)</span>, by fitting the trend model to a time series using the least-squares regression: <span class="math display">\[\hat{\theta} = \operatorname*{argmin}_{\mathbf{\theta}} \sum_{t=1}^{T}\big(y_t - \alpha - \beta t\big)^2.\]</span> Fitted values are then given by: <span class="math display">\[\hat{y}_t = \hat{\alpha} + \hat{\beta} t\]</span></p>
<p>Seasonality is typically modeled as monthly or quarterly pattern, but can also be modeled as a higher frequency pattern (e.g. weekly). Some examples of time series with apparent seasonal patterns are:</p>
<ul>
<li>Agricultural production.</li>
<li>Sales of energy products.</li>
<li>Airfare (in non-pandemic times).</li>
</ul>
<p>One way to deal with the seasonality in data is to “remove” it prior to the use of the series (i.e., work with a seasonally adjusted time series). Indeed, some economic time series are only/also available in a seasonally-adjusted form.</p>
<p>Otherwise, and perhaps more interestingly, we can directly model seasonality in a regression setting by incorporating seasonal dummy variables, for example.</p>
<p>A seasonal model is given by: <span class="math display">\[y_t = \sum_{i=1}^{s}\gamma_i d_{it} + \varepsilon_t,\]</span>
where <span class="math inline">\(s\)</span> denotes the frequency of the data, and <span class="math inline">\(d_{it}\)</span> takes the value of 1 repeatedly after every <span class="math inline">\(s\)</span> periods, and such that <span class="math inline">\(\sum_{i} d_{it} = 1\)</span>, <span class="math inline">\(\forall t\)</span>.</p>
<p>Alternatively the seasonal model can be rewritten as: <span class="math display">\[y_t = \alpha + \sum_{i=1}^{s-1}\delta_i d_{it} + \varepsilon_t,\]</span> in which case <span class="math inline">\(\alpha\)</span> is an intercept of an omitted season, and <span class="math inline">\(\delta_i\)</span> represents a deviation from it during the <span class="math inline">\(i^{th}\)</span> season. This is a more typical form of a seasonal model.</p>
<p>Both variants of a seasonal model result in an identical fit and forecasts.</p>
<p>When dealing with weekly or daily data, the dummy variable approach of modeling seasonality may not be practical, nor efficient in most instances, as that will require estimating another 51 or 364 parameters. A way to model seasonality without giving up too many degrees of freedom is by using the so-called harmonic seasonal variables, which are a set of Fourier terms.</p>
<p>The Fourier terms can be applied to model seasonality at any frequency, indeed. Suppose, for example, we are working with monthly time series. A model with Fourier terms will have the following form: <span class="math display">\[y_t = \alpha+\sum_{k=1}^{K}\left[\beta_{1k}\sin\left(\frac{2\pi kt}{12}\right)+\beta_{2k}\cos\left(\frac{2\pi kt}{12}\right)\right]+\varepsilon_t,\]</span> where the value of <span class="math inline">\(K\)</span> can be determined using an information criterion (e.g., AIC or SIC).</p>
</div>
<div id="forecasting" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Forecasting</h2>
<p>The predictors of the deterministic trend or seasonal models are pre-determined, which means, after fitting the model, we can directly obtain the point and interval forecasts for any horizon <span class="math inline">\(h\)</span>.</p>
<p>If a linear trend model is fitted to the data, then any future realization of the stochastic process is assumed to follow the linear trend model: <span class="math display">\[y_{t+h} = \alpha + \beta (t+h) + \varepsilon_{t+h}.\]</span></p>
<p>An optimal forecast of <span class="math inline">\(y_{t+h}\)</span>, therefore, is given by: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_t) = E[\alpha + \beta (t+h) + \varepsilon_{t+h}] = \alpha + \beta (t+h).\]</span></p>
<p>The forecast error is: <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t} = \varepsilon_{t+h}\]</span></p>
<p>The forecast variance, then, is: <span class="math display">\[\sigma_{t+h|t}^2 = E(e_{t+h|t}^2) =  E(\varepsilon_{t+h}^2) = \hat{\sigma}^2,\;~~\forall\;h\]</span></p>
<p>From this, we can obtain interval forecast at any horizon, which is: <span class="math display">\[y_{t+h|t} \pm 1.96 \hat{\sigma}.\]</span></p>
<p>When using the dummy variable approach to model the seasonality, for example, a future realization of a random variable is: <span class="math display">\[y_{t+h} = \alpha + \sum_{i=1}^{s-1}\delta_i d_{i,t+h} + \varepsilon_{t+h}.\]</span></p>
<p>The optimal forecast of <span class="math inline">\(y_{t+h}\)</span> is: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_t) = \alpha + \sum_{i=1}^{s-1}\delta_i d_{i,t+h}\]</span></p>
<p>The forecast error is: <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t} = \varepsilon_{t+h}\]</span></p>
<p>The forecast variance is: <span class="math display">\[\sigma_{t+h|t}^2 = E(e_{t+h|t}^2) =  E(\varepsilon_{t+h}^2) = \hat{\sigma}^2,\;~~\forall\;h\]</span></p>
<p>The interval forecast is: <span class="math display">\[y_{t+h|t} \pm 1.96 \hat{\sigma}.\]</span></p>
<p>Several characteristics of forecasts from the considered deterministic models:</p>
<ul>
<li>they tend to understate uncertainty (at long horizons as the forecast interval doesn not widen with the horizon);</li>
<li>short-term trend forecasts can perform poorly; long-term trend forecasts typically perform poorly;</li>
<li>sometimes it may be beneficial, from the standpoint of achieving better accuracy, to forecast growth rates, and then reconstruct level forecasts.</li>
</ul>
<!--chapter:end:04-deterministic.Rmd-->
</div>
</div>
<div id="autoregressive-models" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Autoregressive Models</h1>
<p>Economic time series are often characterized by stochastic cycles. A cycle is a pattern of periodic fluctuations, not contained within a calendar year. A stochastic cycle is one generated by random variables. In general terms, the process is given by:
<span class="math display">\[Y_t = f(Y_{t-1},Y_{t-2},\ldots;\mathbf{\theta})+\varepsilon_t.\;~~t=1,\ldots,T\]</span></p>
<p>An autoregressive process (or, simply, an autoregression) is a regression in which the dependent variable and the regressors belong to the same stochastic process.</p>
<p>An autoregression of order <span class="math inline">\(p\)</span>, denoted as <span class="math inline">\(AR(p)\)</span>, has the following functional form:
<span class="math display">\[y_t = \alpha + \beta_1 y_{t-1}+\beta_2 y_{t-2}+ \cdots + \beta_p y_{t-p}+\varepsilon_t\]</span></p>
<p>The sum of the autoregressive parameters, <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span>, depicts the persistence of the series. The larger is the persistence (i.e., closer it is to one), the longer it takes for the effect of a shock to dissolve. The effect will, eventually, dissolve so long as the series are covariance-stationary.</p>
<p>The autocorrelation, <span class="math inline">\(\rho\)</span>, and partial autocorrelation, <span class="math inline">\(\pi\)</span>, functions of the covariance-stationary <span class="math inline">\(AR(p)\)</span> process have the following distinctive features:</p>
<ul>
<li><span class="math inline">\(\rho_1 = \pi_1\)</span>, and <span class="math inline">\(\pi_p = \beta_p\)</span>.</li>
<li>The values of <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span> determine the shape of the autocorrelation function (ACF); in any case, the smaller (in absolute terms) is the persistence measure, the faster the ACF decays toward zero.</li>
<li>The partial autocorrelation function (PACF) is characterized by “statistically significant” first <span class="math inline">\(p\)</span> spikes <span class="math inline">\(\pi_1 \neq 0,\ldots,\pi_p \neq 0\)</span>, and the remaining <span class="math inline">\(\pi_k = 0\)</span>, <span class="math inline">\(\forall k &gt; p\)</span>.</li>
</ul>
<div id="modeling-1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Modeling</h2>
<div id="ar1" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> AR(1)</h3>
<p>The first-order autoregression is given by: <span class="math display">\[y_t = \alpha + \beta_1 y_{t-1} + \varepsilon_t,\]</span> where <span class="math inline">\(\alpha\)</span> is a constant term; <span class="math inline">\(\beta_1\)</span> is the <em>persistence</em> parameter; and <span class="math inline">\(\varepsilon_t\)</span> is a white noise process.</p>
<p>A necessary and sufficient condition for an <span class="math inline">\(AR(1)\)</span> process to be covariance stationary is that <span class="math inline">\(|\beta_1| &lt; 1\)</span>. We can see this by substituting recursively the lagged equations into the lagged dependent variables:
<span class="math display">\[
\begin{aligned}
y_t &amp;= \alpha + \beta_1 y_{t-1} + \varepsilon_t \notag \\
y_t &amp;= \alpha + \beta_1 (\alpha + \beta_1 y_{t-2} + \varepsilon_{t-1}) + \varepsilon_t \notag \\
&amp;= \alpha(1+\beta_1) + \beta_1^2 (\alpha + \beta_1 y_{t-3} + \varepsilon_{t-2}) + \beta_1\varepsilon_{t-1} + \varepsilon_t \notag \\
&amp;\vdots  \notag \\
&amp;= \alpha\sum_{i=0}^{k-1}\beta_1^i + \beta_1^k y_{t-k} + \sum_{i=0}^{k-1}\beta_1^i\varepsilon_{t-i}
\end{aligned}
\]</span>
The end-result is a general linear process with geometrically declining coefficients. Here, <span class="math inline">\(|\beta_1| &lt; 1\)</span> is required for convergence.</p>
<p>Assuming <span class="math inline">\(|\beta_1| &lt; 1\)</span>, as <span class="math inline">\(k \to \infty\)</span> the process converges to: <span class="math display">\[y_t = \frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\]</span></p>
<p>The <em>unconditional mean</em> of this process is: <span class="math display">\[\mu = E\left(y_t\right) = E\left(\frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\right) = \frac{\alpha}{1-\beta_1}\]</span></p>
<p>The <em>unconditional variance</em> of this process is: <span class="math display">\[\gamma_0 = Var\left(y_t\right) = Var\left(\frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\right) = \frac{\sigma_{\varepsilon}^2}{1-\beta_1^2}\]</span></p>
<p>The <em>Autocovariance</em> is simply the covariance between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>, that is: <span class="math display">\[\gamma_k = Cov(y_t,y_{t-k}) = E[(y_t - \mu)(y_{t-k} - \mu)] = E(y_t y_{t-k}) - \mu^2\]</span></p>
<p>Some algebraic manipulation can help us show that: <span class="math display">\[\gamma_k = \beta_1\gamma_{k-1},\]</span> and that: <span class="math display">\[\rho_{k} = \beta_1\rho_{k-1}\]</span> (recall, <span class="math inline">\(\rho_k = \gamma_k/\gamma_0\)</span> is the autocorrelation coefficient).</p>
<p>In fact, for AR(1), an autocorrelation coefficient of some lag can be represented as the autoregression parameter (which in this instance is equivalent to the persistence measure) to that power. That is:
<span class="math display">\[
\begin{aligned}
\rho_1 &amp;= \beta_1\rho_0 = \beta_1 \notag \\
\rho_2 &amp;= \beta_1\rho_1 = \beta_1^2 \notag \\
&amp;\vdots \notag \\
\rho_k &amp;= \beta_1\rho_{k-1} = \beta_1^k
\end{aligned}
\]</span></p>
<p>It follows that the autocorrelation function of a covariance stationary AR(1) is a geometric decay; the smaller is <span class="math inline">\(|\beta_1|\)</span> the more rapid is the decay.</p>
<p>By imposing certain restrictions, the AR(1) will reduce to other already known models:</p>
<ul>
<li>If <span class="math inline">\(\beta_1 = 0\)</span>, <span class="math inline">\(y_t\)</span> is equivalent to a white noise.</li>
<li>If <span class="math inline">\(\beta_1 = 1\)</span> and <span class="math inline">\(\alpha = 0\)</span>, <span class="math inline">\(y_t\)</span> is a random walk.</li>
<li>If <span class="math inline">\(\beta_1 = 1\)</span> and <span class="math inline">\(\alpha \neq 0\)</span>, <span class="math inline">\(y_t\)</span> is a random walk with drift.</li>
</ul>
<p>In general, a smaller persistence parameter results in a quicker adjustment to the <em>unconditional mean</em> of the process.</p>
<p>The autocorrelation and partial autocorrelation functions of the AR(1) process have three distinctive features:</p>
<ul>
<li><span class="math inline">\(\rho_1 = \pi_1 = \beta_1\)</span>. That is, the persistence parameter is also the autocorrelation and the partial autocorrelation coefficient.</li>
<li>The autocorrelation function decreases exponentially toward zero, and the decay is faster when the persistence parameter is smaller.</li>
<li>The partial autocorrelation function is characterized by only one spike <span class="math inline">\(\pi_1 \neq 0\)</span>, and the remaining <span class="math inline">\(\pi_k = 0\)</span>, <span class="math inline">\(\forall k &gt; 1\)</span>.</li>
</ul>
<p>To illustrate the foregoing, let’s generate a series of 100 observations that follow the process: <span class="math inline">\(y_t=0.8y_{t-1}+\varepsilon_t\)</span>, where <span class="math inline">\(y_0=0\)</span> and <span class="math inline">\(\varepsilon\sim N(0,1)\)</span>, and plot the ACF and PACF of this series.</p>
<p><img src="forecasting_files/figure-html/unnamed-chunk-10-1.png" width="624"  /></p>
</div>
<div id="ar2" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> AR(2)</h3>
<p>Now consider the second-order autoregression: <span class="math display">\[y_t = \alpha + \beta_1 y_{t-1} + \beta_2 y_{t-2} + \varepsilon_t\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a constant term; <span class="math inline">\(\beta_1+\beta_2\)</span> is the persistence measure; and <span class="math inline">\(\varepsilon_t\)</span> is a white noise process.</p>
<p>In what follows, the necessary (1 and 2) and sufficient (3 and 4) conditions for an <span class="math inline">\(AR(2)\)</span> process to be covariance stationary are:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(|\beta_2| &lt; 1\)</span></li>
<li><span class="math inline">\(|\beta_1| &lt; 2\)</span></li>
<li><span class="math inline">\(\beta_1 + \beta_2 &lt; 1\)</span></li>
<li><span class="math inline">\(\beta_2 - \beta_1 &lt; 1\)</span></li>
</ol>
<p>The autocorrelation functions of the AR(2) process have the following distinctive features:</p>
<ul>
<li><span class="math inline">\(\rho_1 = \pi_1\)</span> (which is true for any <span class="math inline">\(AR(p)\)</span> process), and <span class="math inline">\(\pi_2 = \beta_2\)</span>.</li>
<li>The autocorrelation function decreases toward zero. The path, however, varies depending on the values of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>. Nonetheless, the decay is faster when the persistence measure is smaller.</li>
<li>The partial autocorrelation function is characterized by only two spikes <span class="math inline">\(\pi_1 \neq 0\)</span> and <span class="math inline">\(\pi_2 \neq 0\)</span>, and the remaining <span class="math inline">\(\pi_k = 0\)</span>, <span class="math inline">\(\forall k &gt; 2\)</span>.</li>
</ul>
<p>Again, to illustrate, let’s generate a series of 100 observations that follow the process: <span class="math inline">\(y_t=1.1y_{t-1}-0.4y_{t-2}+\varepsilon_t\)</span>, where <span class="math inline">\(y_{-1}=y_0=0\)</span> and <span class="math inline">\(\varepsilon\sim N(0,1)\)</span>, and plot the ACF and PACF of this series.</p>
<p><img src="forecasting_files/figure-html/unnamed-chunk-11-1.png" width="624"  /></p>
</div>
</div>
<div id="forecasting-1" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Forecasting</h2>
<p>Making forecasts for some future period, <span class="math inline">\(t+h\)</span>, from an AR(p) model that has been fit to the data up to and including period <span class="math inline">\(t+h-1\)</span> can be a straightforward exercise, so long as we have access to the relevant information set. For one-step-ahead forecasts, the information set is readily available. For multi-step-ahead forecasts, we need to ‘come up’ with the value of the variable that has not been realized yet. For example, when making a two-step-ahead forecast for period <span class="math inline">\(t+2\)</span>, we need data from period <span class="math inline">\(t+1\)</span>, which is not available at the time when the forecast is made. Instead, we need to use our forecast for period <span class="math inline">\(t+1\)</span>. The same applies to forecasts for any subsequent periods in the future. This approach is known as an <em>iterative</em> method of forecasting, wherein we make forecast for some period using the available data, then iterate forward by one period and use the most recent forecast to make the next period’s forecast, and so on and so forth.</p>
<div id="one-step-ahead-forecast-from-ar1" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> One-step-ahead forecast from AR(1)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+1\)</span> is: <span class="math display">\[y_{t+1} = \alpha + \beta_1 y_{t} + \varepsilon_{t+1}\]</span></p>
<p>The optimal one-step-ahead forecast is: <span class="math display">\[y_{t+1|t} = E(y_{t+1}|\Omega_t) = E(\alpha + \beta_1 y_{t} + \varepsilon_{t+1}) = \alpha + \beta_1 y_{t}\]</span></p>
<p>The one-step-ahead forecast error is: <span class="math display">\[e_{t+1|t} = y_{t+1} - y_{t+1|t} = \alpha + \beta_1 y_t + \varepsilon_{t+1} - (\alpha + \beta_1 y_t) = \varepsilon_{t+1}\]</span></p>
<p>The one-step-ahead forecast variance: <span class="math display">\[\sigma_{t+1|t}^2 = Var(y_{t+1}|\Omega_t) = E(e_{t+1|t}^2) = E(\varepsilon_{t+1}^2) = \sigma_{\varepsilon}^2\]</span></p>
<p>The one-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+1|t} \pm z_{.025}\sigma_{t+1|t} = y_{t+1|t} \pm 1.96\sigma_{\varepsilon}\]</span></p>
</div>
<div id="two-step-ahead-forecast-from-ar1" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Two-step-ahead forecast from AR(1)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+2\)</span> is: <span class="math display">\[y_{t+2} = \alpha + \beta_1 y_{t+1} + \varepsilon_{t+2}\]</span></p>
<p>The optimal two-step-ahead forecast is: <span class="math display">\[y_{t+2|t} = E(y_{t+2}|\Omega_t) = E(\alpha + \beta_1 y_{t+1} + \varepsilon_{t+2}) = \alpha(1+\beta_1) + \beta_1^2 y_t\]</span></p>
<p>Note, that here we substituted <span class="math inline">\(y_{t+1}\)</span> with <span class="math inline">\(\alpha + \beta_1 y_t + \varepsilon_{t+1}\)</span>.</p>
<p>The two-step-ahead forecast error is:
<span class="math display">\[\begin{aligned}
e_{t+2|t} &amp;= y_{t+2} - y_{t+2|t} \\
&amp;= \alpha(1+\beta_1) + \beta_1^2 y_t + \beta_1\varepsilon_{t+1} + \varepsilon_{t+2} - [\alpha(1+\beta_1) + \beta_1^2 y_t] \\
&amp;= \beta_1\varepsilon_{t+1} + \varepsilon_{t+2}
\end{aligned}\]</span></p>
<p>The two-step-ahead forecast variance is:
<span class="math display">\[\begin{aligned}
\sigma_{t+2|t}^2 &amp;= Var(y_{t+2}|\Omega_t) \\
&amp;= E(e_{t+2|t}^2) = E(\beta_1\varepsilon_{t+1} + \varepsilon_{t+2})^2 = \sigma_{\varepsilon}^2(1+\beta_1^2)
\end{aligned}\]</span></p>
<p>The two-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+2|t} \pm z_{.025}\sigma_{t+2|t} = y_{t+2|t} \pm 1.96\sigma_{\varepsilon}\sqrt{1+\beta_1^2}\]</span></p>
</div>
<div id="h-step-ahead-forecast-from-ar1" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> h-step-ahead forecast from AR(1)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+h\)</span> is: <span class="math display">\[y_{t+h} = \alpha + \beta_1 y_{t+h-1} + \varepsilon_{t+h}\]</span></p>
<p>The optimal h-step-ahead forecast: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_t) = E(\alpha + \beta_1 y_{t+h-1} + \varepsilon_{t+1}) = \alpha\textstyle\sum_{j=0}^{h-1}\beta_1^j + \beta_1^h y_t\]</span></p>
<p>The h-step-ahead forecast error: <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t} = \textstyle\sum_{j=0}^{h-1}\beta_1^j\varepsilon_{t+h-j}\]</span></p>
<p>The h-step-ahead forecast variance: <span class="math display">\[\sigma_{t+h|t}^2 = Var(y_{t+h}|\Omega_t) = E(e_{t+h|t}^2) = \sigma_{\varepsilon}^2\textstyle\sum_{j=0}^{h-1}\beta_1^{2j}\]</span></p>
<p>The h-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+h|t} \pm z_{.025}\sigma_{t+h|t} = y_{t+1|t} \pm 1.96\sigma_{\varepsilon}\sqrt{\textstyle\sum_{j=0}^{h-1}\beta_1^{2j}}\]</span></p>
<p>If the series represent a covariance-stationary process, i.e. when <span class="math inline">\(|\beta_1| &lt; 1\)</span>, as <span class="math inline">\(h \to \infty\)</span>:</p>
<p>The optimal point forecast converges to: <span class="math display">\[y_{t+h|t} = \frac{\alpha}{1-\beta_1}\]</span></p>
<p>The forecast variance converges to: <span class="math display">\[\sigma_{t+h|t}^2 = \frac{\sigma_{\varepsilon}^2}{1-\beta_1^2}\]</span></p>
<p>The (95%) interval forecast converges to: <span class="math display">\[y_{t+h|t} \pm z_{.025}\sigma_{t+h|t} = \frac{\alpha}{1-\beta_1} \pm 1.96\frac{\sigma_{\varepsilon}}{\sqrt{1-\beta_1^2}}\]</span></p>
</div>
<div id="one-step-ahead-forecast-from-ar2" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> One-step-ahead forecast from AR(2)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+1\)</span> is: <span class="math display">\[y_{t+1} = \alpha + \beta_1 y_{t} + \beta_2 y_{t-1} + \varepsilon_{t+1}\]</span></p>
<p>The optimal one-step-ahead forecast:
<span class="math display">\[\begin{aligned}
y_{t+1|t} &amp;= E(y_{t+1}|\Omega_t) \\
&amp;= E(\alpha + \beta_1 y_{t} + \beta_2 y_{t-1} + \varepsilon_{t+1}) = \alpha + \beta_1 y_{t} + \beta_2 y_{t-1}
\end{aligned}\]</span></p>
<p>The one-step-ahead forecast error:
<span class="math display">\[\begin{aligned}
e_{t+1|t} &amp;= y_{t+1} - y_{t+1|t} \\
&amp;= \alpha + \beta_1 y_t + \beta_2 y_{t-1} + \varepsilon_{t+1} - (\alpha + \beta_1 y_t + \beta_2 y_{t-1}) = \varepsilon_{t+1}
\end{aligned}\]</span></p>
<p>The one-step-ahead forecast variance: <span class="math display">\[\sigma_{t+1|t}^2 = Var(y_{t+1}|\Omega_t) = E(e_{t+1|t}^2) = E(\varepsilon_{t+1}^2) = \sigma_{\varepsilon}^2\]</span></p>
<p>The one-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+1|t} \pm z_{.025}\sigma_{t+1|t} = y_{t+1|t} \pm 1.96\sigma_{\varepsilon}\]</span></p>
</div>
<div id="two-step-ahead-forecast-from-ar2" class="section level3" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> Two-step-ahead forecast from AR(2)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+2\)</span> is: <span class="math display">\[y_{t+2} = \alpha + \beta_1 y_{t+1} + \beta_2 y_{t} + \varepsilon_{t+2}\]</span></p>
<p>The optimal two-step-ahead forecast:
<span class="math display">\[\begin{aligned}
y_{t+2|t} = E(y_{t+2}|\Omega_t) &amp;= E(\alpha + \beta_1 y_{t+1} + \beta_2 y_{t} + \varepsilon_{t+1}) \\
&amp;= \alpha(1+\beta_1) + (\beta_1^2+\beta_2) y_{t} + \beta_1\beta_2 y_{t-1}
\end{aligned}\]</span></p>
<p>The two-step-ahead forecast error:
<span class="math display">\[\begin{aligned}
e_{t+2|t} = y_{t+2} - y_{t+2|t} =&amp; \alpha + \beta_1 y_{t+1} + \beta_2 y_{t} + \varepsilon_{t+2} \\
&amp;- (\alpha + \beta_1 y_{t+1|t} + \beta_2 y_{t}) = \beta_1\varepsilon_{t+1} + \varepsilon_{t+2}
\end{aligned}\]</span></p>
<p>The two-step-ahead forecast variance:
<span class="math display">\[\sigma_{t+2|t}^2 = Var(y_{t+2}|\Omega_t) = E(e_{t+2|t}^2) = E(\beta_1\varepsilon_{t+1} + \varepsilon_{t+2})^2 = \sigma_{\varepsilon}^2(1+\beta_1^2)\]</span></p>
<p>The two-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+2|t} \pm z_{.025}\sigma_{t+2|t} = y_{t+2|t} \pm 1.96\sigma_{\varepsilon}\sqrt{1+\beta_1^2}\]</span></p>
</div>
<div id="one-step-ahead-forecast-from-ar2-1" class="section level3" number="6.2.6">
<h3><span class="header-section-number">6.2.6</span> One-step-ahead forecast from AR(2)</h3>
<p>The realization of the random variable in period <span class="math inline">\(t+h\)</span> is: <span class="math display">\[y_{t+h} = \alpha + \beta_1 y_{t+h-1} + \beta_2 y_{t+h-2} + \varepsilon_{t+h}\]</span></p>
<p>The optimal h-step-ahead forecast (iterated method):
<span class="math display">\[\begin{aligned}
y_{t+1|t} &amp;= \alpha + \beta_1 y_t + \beta_2 y_{t-1} \\
y_{t+2|t} &amp;= \alpha + \beta_1 y_{t+1|t} + \beta_2 y_{t} \\
y_{t+3|t} &amp;= \alpha + \beta_1 y_{t+2|t} + \beta_2 y_{t+1|t} \\
&amp;\vdots \\
y_{t+h|t} &amp;= \alpha + \beta_1 y_{t+h-1|t} + \beta_2 y_{t+h-2|t}
\end{aligned}\]</span></p>
<p>The h-step-ahead forecast error: <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t} = \varepsilon_{t+h}+\beta_1 e_{t+h-1|t}+\beta_2 e_{t+h-2|t}\]</span></p>
<p>The h-step-ahead forecast variance:
<span class="math display">\[\begin{aligned}
\sigma_{t+h|t}^2 &amp;= Var(y_{t+h}|\Omega_t) = E(e_{t+h|t}^2) \\
&amp;= \sigma_{\varepsilon}^2+\beta_1^2 Var(e_{t+h-1|t})+\beta_2^2 Var(e_{t+h-2|t}) \\
&amp;+2\beta_1\beta_2Cov(e_{t+h-1|t},e_{t+h-2|t})
\end{aligned}\]</span></p>
<p>(Note: the formulas for <span class="math inline">\(\sigma_{t+1|t}^2,\sigma_{t+2|t}^2,\ldots,\sigma_{t+h|t}^2\)</span> are the same for any <span class="math inline">\(AR(p)\)</span>, <span class="math inline">\(p \geq h-1\)</span>).</p>
<p>The h-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+h|t} \pm z_{.025}\sigma_{t+h|t} = y_{t+1|t} \pm 1.96\sigma_{t+h|t}\]</span></p>
<p>The optimal h-step-ahead forecast: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_t) = \alpha + \beta_1 y_{t+h-1|t} + \beta_2 y_{t+h-2|t} + \cdots + \beta_p y_{t+h-p|t}\]</span></p>
<p>The h-step-ahead forecast error: <span class="math display">\[e_{t+h|t} = \varepsilon_{t+h} + \beta_1 e_{t+h-1|t} + \beta_2 e_{t+h-2|t} + \cdots + \beta_p e_{t+h-p|t}\]</span></p>
<p>The h-step-ahead forecast variance:
<span class="math display">\[\begin{aligned}
\sigma_{t+h|t}^2 &amp; = Var(y_{t+h}|\Omega_t) = E(e_{t+2|t}^2) \\
&amp;= \sigma_{\varepsilon}^2 + \sum_{i=1}^{p}\beta_i^2 Var(e_{t+h-i|t}) + 2\sum_{i \neq j}\beta_i\beta_j Cov(e_{t+h-i|t},e_{t+h-j|t})
\end{aligned}\]</span></p>
<p>The h-step-ahead (95%) interval forecast: <span class="math display">\[y_{t+h|t} \pm z_{.025}\sigma_{t+h|t} = y_{t+h|t} \pm 1.96\sigma_{t+h|t}\]</span></p>
<!--chapter:end:05-autoregression.Rmd-->
</div>
</div>
</div>
<div id="vector-autoregressive-models" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Vector Autoregressive Models</h1>
<p>Many economic variables are interrelated. For example, changes to household income impact their consumption levels; changes to interest rates impact investments in the economy. Often (albeit not always) the relationship between the variables goes in both directions. For example, higher wages (and, therefore, income) result in higher prices (inflation), which in turn puts an upward pressure on wages.</p>
<p>The foregoing implies that a shock to a variable may propagate a dynamic response not only of that variable, but also of related variables. The dynamic linkages between two (or more) economic variables can be modeled as a <em>system of equations</em>, represented by a vector autoregressive (VAR) process.</p>
<div id="modeling-2" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Modeling</h2>
<p>To begin, consider a bivariate (two-dimensional) VAR of order one, VAR(1).</p>
<p>Let <span class="math inline">\(\{X_{1,t}\}\)</span> and <span class="math inline">\(\{X_{2,t}\}\)</span> be the stationary stochastic processes. A bivariate VAR(1), is then given by:
<span class="math display">\[\begin{aligned}
x_{1,t} &amp;= \alpha_1 + \pi_{11}x_{1,t-1} + \pi_{12}x_{2,t-1} + \varepsilon_{1,t} \\
x_{2,t} &amp;= \alpha_2 + \pi_{21}x_{1,t-1} + \pi_{22}x_{2,t-1} + \varepsilon_{2,t}
\end{aligned}\]</span></p>
<p>where <span class="math inline">\(\varepsilon_{1,t} \sim iid(0,\sigma_1^2)\)</span> and <span class="math inline">\(\varepsilon_{2,t} \sim iid(0,\sigma_2^2)\)</span>, and the two can be correlated, i.e., <span class="math inline">\(Cov(\varepsilon_{1,t},\varepsilon_{2,t}) \neq 0\)</span>.</p>
<p>To generalize, consider a multivariate (<span class="math inline">\(n\)</span>-dimensional) VAR of order <span class="math inline">\(p\)</span>, VAR(p), presented in matrix notation: <span class="math display">\[\mathbf{x}_t = \mathbf{\alpha} + \Pi_1 \mathbf{x}_{t-1} + \ldots + \Pi_p \mathbf{x}_{t-p} + \mathbf{\varepsilon}_t,\]</span> where <span class="math inline">\(\mathbf{x}_t = (x_{1,t},\ldots,x_{n,t})&#39;\)</span> is a vector of <span class="math inline">\(n\)</span> (potentially) related variables; <span class="math inline">\(\mathbf{\varepsilon}_t = (\varepsilon_{1,t},\ldots,\varepsilon_{n,t})&#39;\)</span> is a vector of error terms, such that <span class="math inline">\(E(\mathbf{\varepsilon}_t) = \mathbf{0}\)</span>, <span class="math inline">\(E(\mathbf{\varepsilon}_t^{}\mathbf{\varepsilon}_t^{\prime}) = \Sigma\)</span>, and <span class="math inline">\(E(\mathbf{\varepsilon}_{t}^{}\mathbf{\varepsilon}_{s \neq t}^{\prime}) = 0\)</span>. <span class="math inline">\(\Pi_1,\ldots,\Pi_p\)</span> are <span class="math inline">\(n\)</span>-dimensional parameter matrices:
<span class="math display">\[\Pi_j =
        \left[
        \begin{array}{cccc}
        \pi_{11j} &amp; \pi_{12j} &amp; \cdots &amp;  \pi_{1nj} \\
        \pi_{21j} &amp; \pi_{22j} &amp; \cdots &amp;  \pi_{2nj} \\  
        \vdots &amp; \vdots &amp; \ddots &amp;  \vdots \\  
        \pi_{n1j} &amp; \pi_{n2j} &amp; \cdots &amp;  \pi_{nnj} \\  
        \end{array}
        \right],\;~~j=1,\ldots,p\]</span></p>
<p>When two or more variables are modeled in this way, the implies assumption is that these variables are endogenous to each other; that is, each of the variables affects and is affected by other variables.</p>
<p>There are three forms of vector autoregressions: structural, recursive, and reduced-form. The structural VAR uses economic theory to impose the ‘structure’ on correlations of the error terms in the system, thus, facilitate their ‘causal’ interpretation. The recursive VAR also introduces a structure of some sort, which primarily involves ordering the equations in the system in a specific way so that the error terms in each equation are uncorrelated with those in the preceding equations. To the extent that the ‘identifying assumptions’ are satisfied, some contemporaneous values (of other variables) appear in the equation of a given variable. The reduced-form VAR makes no claims of causality, instead it only includes lagged values of all the variables in each equation of the system. To the extent that the variables entering the system are, indeed, correlated among each other, the error terms of the reduced-form VAR (typically) are contemporaneously correlated. Here, unless otherwise specified, VAR refers to the reduced-form VAR.</p>
<p>Some of the features of the VAR are that:</p>
<ul>
<li>only lagged values of the dependent variables are considered as the right-hand-side variables (although, trend and seasonal variables might also be included in higher-frequency data analysis);</li>
<li>each equation has the same set of right-hand-side variables (however, it is possible to impose a different lag structure across the equations, especially when <span class="math inline">\(p\)</span> is relatively large, to preserve the degrees of freedom, particularly when the sample size is relatively small and when there are several variables in the system).</li>
<li>The autregressive order of the VAR, <span class="math inline">\(p\)</span>, is determined by the maximum lag of a variable across all equations.</li>
</ul>
<p>The order of a VAR, <span class="math inline">\(p\)</span>, can be determined using system-wide information criteria:</p>
<p><span class="math display">\[\begin{aligned}
&amp; AIC = \ln\left|\Sigma_{\varepsilon}\right| + \frac{2}{T}(pn^2+n) \\
&amp; SIC = \ln\left|\Sigma_{\varepsilon}\right| + \frac{\ln{T}}{T}(pn^2+n)
\end{aligned}\]</span></p>
<p>where <span class="math inline">\(\left|\Sigma_{\varepsilon}\right|\)</span> is the determinant of the residual covariance matrix; <span class="math inline">\(n\)</span> is the number of equations, and <span class="math inline">\(T\)</span> is the effective sample size.</p>
<p>We can estimate each equation of the VAR individually using OLS.</p>
<div id="in-sample-granger-causality" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> In-Sample Granger Causality</h3>
<p>A test of joint significance of parameters associated with all the lags of a variable entering the equation of another variable is known as the ‘Granger causality’ test. The use of the term ‘causality’ in this context has been criticized. That one variable can help explain the movement of another variable does not necessarily mean that the former causes the latter. To that end the use of the term is misleading, indeed. Rather, it simply means that the former helps predict the latter, and that is, in effect, the meaning of causality in Granger sense.</p>
<p>To illustrate the testing framework, consider a bivariate VAR(p):
<span class="math display">\[\begin{aligned}
x_{1,t} &amp;= \alpha_1 + \pi_{111} x_{1,t-1} + \cdots + \pi_{11p} x_{1,t-p} \\
&amp;+ \pi_{121} x_{2,t-1} + \cdots + \pi_{12p} x_{2,t-p} +\varepsilon_{1,t}  \\
x_{2,t} &amp;= \alpha_1 + \pi_{211} x_{1,t-1} + \cdots + \pi_{21p} x_{1,t-p} \\
&amp;+ \pi_{221} x_{2,t-1} + \cdots + \pi_{22p} x_{2,t-p} +\varepsilon_{2,t}
\end{aligned}\]</span></p>
<p>It is said that:
- <span class="math inline">\(\{X_2\}\)</span> does not Granger cause <span class="math inline">\(\{X_1\}\)</span> if <span class="math inline">\(\pi_{121}=\cdots=\pi_{12p}=0\)</span>
- <span class="math inline">\(\{X_1\}\)</span> does not Granger cause <span class="math inline">\(\{X_2\}\)</span> if <span class="math inline">\(\pi_{211}=\cdots=\pi_{21p}=0\)</span></p>
<p>So long as the variables of the system are covariance-stationarity, we can apply a F test for the hypotheses testing. If <span class="math inline">\(p=1\)</span>, a t test is equivalently applicable for hypotheses testing.</p>
</div>
</div>
<div id="forecasting-2" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Forecasting</h2>
<p>Generating forecasts for each of the variable comprising the VAR(p) model can be a straightforward exercise, so long as we have access to the relevant information set. As it was the case with autoregressive models, we make one-step-ahead forecasts based on the readily available data; and we make multi-step-ahead forecasts iteratively, using the forecast in periods for which the data are not present.</p>
<div id="one-step-ahead-forecast-from-bivariate-var1" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> One-step-ahead forecast from bivariate VAR(1)</h3>
<p>The realizations of the variables in period <span class="math inline">\(t+1\)</span> are:
<span class="math display">\[\begin{aligned}
x_{1,t+1} &amp;= \alpha_1 + \pi_{11} x_{1,t} + \pi_{12} x_{2,t} + \varepsilon_{1,t+1} \\
x_{2,t+1} &amp;= \alpha_2 + \pi_{21} x_{1,t} + \pi_{22} x_{2,t} + \varepsilon_{2,t+1}
\end{aligned}\]</span></p>
<p>The optimal one-step-ahead forecasts are:
<span class="math display">\[\begin{aligned}
x_{1,t+1|t} &amp;= E(x_{1,t+1}|\Omega_t) = \alpha_1 + \pi_{11} x_{1,t} + \pi_{12} x_{2,t} \\
x_{2,t+1|t} &amp;= E(x_{2,t+1}|\Omega_t) = \alpha_2 + \pi_{21} x_{1,t} + \pi_{22} x_{2,t}
\end{aligned}\]</span></p>
<p>The one-step-ahead forecast errors are:
<span class="math display">\[\begin{aligned}
e_{1,t+1|t} &amp;= x_{1,t+1} - x_{1,t+1|t} = \varepsilon_{1,t+1} \\
e_{2,t+1|t} &amp;= x_{2,t+1} - x_{2,t+1|t} = \varepsilon_{2,t+1}
\end{aligned}\]</span></p>
<p>The one-step-ahead forecast variances are:
<span class="math display">\[\begin{aligned}
\sigma_{1,t+1|t}^2 &amp;= E(x_{1,t+1} - x_{1,t+1|t}|\Omega_t)^2 = E(\varepsilon_{1,t+1}^2) = \sigma_{1}^2 \\
\sigma_{2,t+1|t}^2 &amp;= E(x_{2,t+1} - x_{2,t+1|t}|\Omega_t)^2 = E(\varepsilon_{2,t+1}^2) = \sigma_{2}^2
\end{aligned}\]</span></p>
<p>The one-step-ahead (95%) interval forecasts are:
<span class="math display">\[\begin{aligned}
x_{1,t+1|t} \pm z_{.025}\sigma_{1,t+1|t} = x_{1,t+1|t} \pm 1.96\sigma_{\varepsilon_1} \\
x_{2,t+1|t} \pm z_{.025}\sigma_{2,t+1|t} = x_{2,t+1|t} \pm 1.96\sigma_{\varepsilon_2}
\end{aligned}\]</span></p>
</div>
<div id="two-step-ahead-forecast-from-bivariate-var1" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Two-step-ahead forecast from bivariate VAR(1)</h3>
<p>The realizations of the variables in period <span class="math inline">\(t+2\)</span> are:
<span class="math display">\[\begin{aligned}
x_{1,t+2} &amp;= \alpha_1 + \pi_{11} x_{1,t+1} + \pi_{12} x_{2,t+1} + \varepsilon_{1,t+2} \\
x_{2,t+2} &amp;= \alpha_2 + \pi_{21} x_{1,t+1} + \pi_{22} x_{2,t+1} + \varepsilon_{2,t+2}
\end{aligned}\]</span></p>
<p>The optimal two-step-ahead forecasts are:
<span class="math display">\[\begin{aligned}
x_{1,t+2|t} &amp;= E(x_{1,t+2}|\Omega_t) = \alpha_1 + \pi_{11} x_{1,t+1|t} + \pi_{12} x_{2,t+1|t} \\
x_{2,t+2|t} &amp;= E(x_{2,t+2}|\Omega_t) = \alpha_2 + \pi_{21} x_{1,t+1|t} + \pi_{22} x_{2,t+1|t}
\end{aligned}\]</span></p>
<p>The two-step-ahead forecast errors are:
<span class="math display">\[\begin{aligned}
e_{1,t+2|t} &amp;= x_{1,t+2} - x_{1,t+2|t} = \pi_{11} e_{1,t+1|t} + \pi_{12} e_{2,t+1|t} + \varepsilon_{1,t+2} \\
e_{2,t+2|t} &amp;= x_{2,t+2} - x_{2,t+2|t} = \pi_{21} e_{1,t+1|t} + \pi_{22} e_{2,t+1|t} + \varepsilon_{2,t+2}
\end{aligned}\]</span></p>
<p>The two-step-ahead forecast variances are:
<span class="math display">\[\begin{aligned}
\sigma_{1,t+2|t}^2 &amp;= E(x_{1,t+2} - x_{1,t+2|t}|\Omega_t)^2 \\
&amp;= \sigma_{1}^2(1+\pi_{11}^2) + \sigma_{2}^2\pi_{12}^2 + 2\pi_{11}\pi_{12} Cov(\varepsilon_{1},\varepsilon_{2})\\
\sigma_{2,t+2|t}^2 &amp;= E(x_{2,t+2} - x_{2,t+2|t}|\Omega_t)^2 \\
&amp;= \sigma_{2}^2(1+\pi_{22}^2) + \sigma_{1}^2\pi_{21}^2 + 2\pi_{21}\pi_{22} Cov(\varepsilon_{1},\varepsilon_{2})
\end{aligned}\]</span></p>
<p>The two-step-ahead (95%) interval forecasts are:
<span class="math display">\[\begin{aligned}
x_{1,t+2|t} \pm z_{.025}\sigma_{1,t+2|t} \\
x_{2,t+2|t} \pm z_{.025}\sigma_{2,t+2|t}
\end{aligned}\]</span></p>
</div>
<div id="out-of-sample-granger-causality" class="section level3" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Out-of-Sample Granger Causality</h3>
<p>The previously discussed (in sample) test of causality in Granger sense is frequently performed in practice. But as noted above, the term ‘causality’ may be misleading somewhat. Indeed, the ‘true spirit’ of such test is to assess the ability of a variable to help predict another variable in an out-of-sample setting.</p>
<p>Consider the restricted and unrestricted information sets, where the former only contains information on variable <span class="math inline">\(X_1\)</span>, while the latter contains the same information as well as information on variable <span class="math inline">\(X_2\)</span>:
<span class="math display">\[\begin{aligned}
&amp;\Omega_{t,r} \equiv \Omega_{t}(X_1) = \{x_{1,t},x_{1,t-1},\ldots\} \\
&amp;\Omega_{t,u} \equiv \Omega_{t}(X_1,X_2) = \{x_{1,t},x_{1,t-1},\ldots,x_{2,t},x_{2,t-1},\ldots\}
\end{aligned}\]</span></p>
<p>Following Granger’s definition of causality: <span class="math inline">\(\{X_2\}\)</span> is said to cause <span class="math inline">\(\{X_1\}\)</span> if <span class="math inline">\(\sigma_{x_1}^2\left(\Omega_{t,u}\right) &lt; \sigma_{x_1}^2\left(\Omega_{t,r}\right)\)</span>, meaning that we can better predict <span class="math inline">\(X_1\)</span> using all available information on <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, rather than that on <span class="math inline">\(X_1\)</span> only.</p>
<p>Let the forecasts based on each of the information sets be:
<span class="math display">\[\begin{aligned}
    &amp;x_{1,t+h|t,r} = E\left(x_{1,t+h}|\Omega_{t,r}\right) \\
    &amp;x_{1,t+h|t,u} = E\left(x_{1,t+h}|\Omega_{t,u}\right)
\end{aligned}\]</span></p>
<p>For these forecasts, the corresponding forecast errors are:
<span class="math display">\[\begin{aligned}
    &amp; e_{1,t+h|t,r} = x_{1,t+h} - x_{1,t+h|t,r}\\
    &amp; e_{1,t+h|t,u} = x_{1,t+h} - x_{1,t+h|t,u}
\end{aligned}\]</span></p>
<p>The out-of-sample forecast errors are then evaluated by comparing the loss functions based on these forecasts errors. For example, assuming quadratic loss, and <span class="math inline">\(P\)</span> out-of-sample forecasts:
<span class="math display">\[\begin{aligned}
RMSFE_{r} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{1,R+s|R-1+s,r}\right)^2} \\
RMSFE_{u} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{1,R+s|R-1+s,u}\right)^2}
\end{aligned}\]</span>
where <span class="math inline">\(R\)</span> is the size of the (first) estimation window.</p>
<p><span class="math inline">\(\{X_2\}\)</span> is said to cause <em>in Granger sense</em> <span class="math inline">\(\{X_1\}\)</span> if <span class="math inline">\(RMSFE_{u} &lt; RMSFE_{r}\)</span>.</p>
<!--chapter:end:06-multivariate.Rmd-->
</div>
</div>
</div>
<div id="dynamic-factor-models" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Dynamic Factor Models</h1>
<!--chapter:end:07-factormodels.Rmd-->
</div>
<div id="threshold-autoregressive-models" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Threshold Autoregressive Models</h1>
<p>While a stochastic process can be approximated by a linear model, it is possible that a nonlinear model offers a better fit to the data. Nonlinear models come in many flavours. Here we will consider one type of nonlinear models, which belongs to the family of regime-dependent models.</p>
<p>A regime-dependent model can be seen as a combination of linear specifications that are linked to each other in some (nonlinear) way. To that end, such nonlinear models are also referred to as the piecewise linear models - each piece in and of itself is linear, but when taken together we have a nonlinear model at hand.</p>
<div id="nonlinear-models" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Nonlinear Models</h2>
<p>In what follows, we will consider two representative regime-dependent models: the time-varying threshold autoregression and the self-exciting threshold autoregression. In both instances we will assume that the switch between the regimes happens based on some threshold variable, and that it instantaneously.</p>
<p>Consider an AR(p) process with a deterministic trend: <span class="math display">\[y_t = \alpha_0 + \alpha_1 t + \sum_{i=1}^{p}\beta_i y_{t-i} + \varepsilon_t,\]</span> where <span class="math inline">\(\alpha_0 + \alpha_1 t\)</span> is the time-specific deterministic component.</p>
<p>This specification implies a linear trend, but that doesn’t need to be the case. We can have quadratic or cubic trends, for example, or we can have no trend component at all.</p>
<p>A simple augmentation of the foregoing model is an autoregressive model with a switching trend component: <span class="math display">\[y_t = \delta_{0} + \delta_{1} t + \delta_{2}(t-\tau)I(t&gt;\tau) + \beta y_{t-1} + \varepsilon_t,\]</span> where <span class="math inline">\(\tau\)</span> is the threshold parameter.</p>
<p>Such switch can be extended to the whole autoregressive process. For example, a two-regime AR(p) with drift can be given by: <span class="math display">\[y_t = \delta_0 + \delta_1 t + \sum_{i=1}^{p}\beta_{1i} y_{t-i} + \left[\delta_2(t-\tau) + \sum_{i=1}^{p}\beta_{2i} y_{t-i}\right]I(t&gt;\tau) + \varepsilon_t.\]</span> This equation implies that not only the trend, but also the autoregressive process changes around the threshold parameter <span class="math inline">\(\tau\)</span>.</p>
<p>The foregoing nonlinear specifications assumed that the switch in the model occurs at some point in time, i.e. the regime-switching variable is a function of time. But the regime-switching variable can also be a function of the dependent variable, as well as other (potentially) related variables: <span class="math display">\[y_t = \alpha_0 + \sum_{i=1}^{p}\beta_{0i} y_{t-i} + \left(\alpha_1 + \sum_{i=1}^{p}\beta_{1i} y_{t-i}\right)I(s_t&gt;c) + \varepsilon_t,\]</span> where <span class="math inline">\(s_t\)</span> is the regime-switching variable, and <span class="math inline">\(c\)</span> is the threshold, such that <span class="math inline">\(\underline{s}_t &lt; c &lt; \overline{s}_t\)</span>, where <span class="math inline">\(\underline{s}_t\)</span> and <span class="math inline">\(\overline{s}_t\)</span> are lower and upper quantiles of the regime-switching variable.</p>
<p>This equation is referred as threshold autoregression, or TAR(p). More specifically, if in a TAR(p), <span class="math inline">\(s_t = y_{t-d}\)</span>, <span class="math inline">\(d = 1,\ldots,m\)</span>, then it is a self-exciting threshold autoregression, or SETAR(p); alternatively, if <span class="math inline">\(s_t = \Delta y_{t-d}\)</span>, <span class="math inline">\(d = 1,\ldots,m\)</span>, then the model is referred to as a momentum threshold autoregression, or momentum-TAR(p). The latter is typically preferred when <span class="math inline">\(y_t\)</span> is an I(1) process.</p>
<p>A TAR (any version of it) can take a multiple-regime form: <span class="math display">\[y_t = \alpha_1 + \sum_{i=1}^{p}\beta_{1i} y_{t-i} + \sum_{j=2}^{K}{\left(\alpha_j + \sum_{i=1}^{p}\beta_{ji} y_{t-i}\right)I(s_t&gt;c_j)} + \varepsilon_t,\]</span> where <span class="math inline">\(K\)</span> depicts the number of regimes in the equation.</p>
</div>
<div id="modeling-3" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Modeling</h2>
<p>When estimating TAR-type models, we have no <em>a priori</em> knowledge on the number of regimes, the autoregressive order in each regime, the regime-switching (or threshold) variable, and the threshold values.</p>
<p>When threshold values are unknown (and need to be estimated), standard statistical inference is no longer applicable. Otherwise, and given that the process is stationary, standard statistical inference applies.</p>
<p>Joint estimation of model parameters would require some nonlinear optimization routine. Alternatively, we can approximate such optimization using a grid-search procedure. The procedure relies on the fact that once the threshold parameter is known, the model reduces to a linear model, and the least squares estimator can be applied then. That is, <span class="math display">\[\hat{\tau} = \arg\min_{\tau}\hat{\sigma}^2(\tau),\]</span> where <span class="math display">\[\hat{\sigma}^2(\tau) = \frac{1}{T-k}\sum_{t=1}^{T}\hat{\epsilon}_t^2(\tau)\]</span> for all candidate values of <span class="math inline">\(\tau\)</span>. The candidate values of <span class="math inline">\(\tau\)</span> typically belong to a range between 10th and 90th percentiles of the transition variable, which is simply the trend in the case of the time-varying TAR, and the lagged dependent variable in the case of the self-exciting TAR.</p>
</div>
<div id="forecasting-3" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Forecasting</h2>
<p>In the case of time-varying shifting trend (mean) models, the most recent trend component is used to obtain forecasts. To that end, the forecasting routine is similar to that of linear trend models.</p>
<p>In the case of regime-switching models (e.g., TAR), obtaining one-step-ahead forecasts can be a rather straightforward exercise:
<span class="math display">\[\begin{aligned}
y_{t+1|t} &amp;= \alpha_0+\beta_{01}y_{t}+\beta_{02}y_{t-1}+\ldots \\
          &amp;+ (\alpha_1+\beta_{11}y_{t}+\beta_{12}y_{t-1}+\ldots)I(s_t&gt;c)
\end{aligned}\]</span></p>
<p>Obtaining h-step-ahead forecasts (where <span class="math inline">\(h\geq2\)</span>) is less trivial, however. Of the available options:</p>
<ul>
<li>The iterated method (or, the so-called skeleton extrapolation) is an easy but an inefficient option.</li>
<li>The analytical method can be unbearably tedious.</li>
<li>A numerical method is applicable and, moreover, it resolves the caveats of the previous two options.</li>
</ul>
<div id="skeleton-extrapolation" class="section level3" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Skeleton Extrapolation</h3>
<p>One-step-ahead forecast: <span class="math display">\[y_{t+1|t} = E(y_{t+1}|\Omega_{t}) = g(y_{t},y_{t-1},\ldots,y_{t+1-p};\theta)\]</span></p>
<p>Two-step-ahead forecast: <span class="math display">\[y_{t+2|t} = E(y_{t+2}|\Omega_{t}) = g(y_{t+1|t},y_{t},\ldots,y_{t+2-p};\theta)\]</span></p>
<p>h-step-ahead forecast: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_{t}) = g(y_{t+h-1|t},y_{t+h-2|t},\ldots,y_{t+h-p|t};\theta)\]</span></p>
<p>This is fine for linear models; but not okay for nonlinear models.</p>
</div>
<div id="analytical-method" class="section level3" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Analytical Method</h3>
<p>One-step-ahead forecast is the same as before (no uncertainty about the observed data).</p>
<p>Two-step-ahead forecast is: <span class="math display">\[\tilde{y}_{t+2|t} = \int_{-\infty}^{\infty}g(y_{t+1|t}+\varepsilon_{t+1},y_{t},\ldots,y_{t+2-p};\theta)f(\varepsilon_{t+1})d\varepsilon_{t+1}\]</span></p>
<p>Unless the model is linear, <span class="math inline">\(\tilde{y}_{t+2|t} \ne y_{t+2|t}\)</span>.</p>
<p>Longer horizon forecasts require multiple integrals.</p>
</div>
<div id="numerical-method-bootstrap-resampling" class="section level3" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Numerical Method: Bootstrap Resampling</h3>
<p>Bootstrap resampling helps approximate the optimal forecast from nonlinear models and circumvents the complexity of integration.</p>
<p>As an additional benefit, the procedure generates forecast distribution, from which empirical confidence intervals (along with the point forecast) can be obtained.</p>
<p>Algorithm:</p>
<ol style="list-style-type: decimal">
<li>Estimate the time series model and store the residuals.</li>
<li>From this set of residuals, sample (with replacement) a vector of shocks for a bootstrap iteration, <span class="math inline">\(\varepsilon^b = (\varepsilon_{t+1}^b,\varepsilon_{t+2}^b,\ldots,\varepsilon_{t+h}^b)&#39;\)</span>.</li>
<li>Use this sample of shocks, along with the estimated parameters and historical observations, to generate a forecast path for the given bootstrap iteration.</li>
<li>Repeat steps 2-3 many times to generate an empirical distribution of bootstrap forecasts.</li>
</ol>
<p>One-step-ahead bootstrap iteration: <span class="math display">\[y_{t+1|t,\varepsilon_{t+1}^b} \equiv y_{t+1|t}^b = g(y_{t},y_{t-1},\ldots,y_{t+1-p};\theta)+\varepsilon_{t+1}^b\]</span></p>
<p>Two-step-ahead bootstrap iteration: <span class="math display">\[y_{t+2|t,\varepsilon_{t+1}^b,\varepsilon_{t+2}^b} \equiv y_{t+2|t}^b = g(y_{t+1|t,\varepsilon_{t+1}^b},y_{t},\ldots,y_{t+2-p};\theta)+\varepsilon_{t+2}^b\]</span></p>
<p>For example, consider a linear <span class="math inline">\(\text{AR}(p)\)</span> model.</p>
<p>One-step-ahead bootstrap iteration: <span class="math display">\[y_{t+1|t}^b = \alpha + \beta_1 y_{t} + \ldots + \beta_p y_{t+1-p}+\varepsilon_{t+1}^b\]</span></p>
<p>Two-step-ahead bootstrap iteration: <span class="math display">\[y_{t+2|t}^b = \alpha + \beta_1 \hat{y}_{t+1}^b + \ldots + \beta_p y_{t+2-p}+\varepsilon_{t+2}^b\]</span></p>
<p>Now consider a nonlinear <span class="math inline">\(\text{SETAR}(p,y_{t-1})\)</span> model:</p>
<p>One-step-ahead bootstrap iteration:
<span class="math display">\[\begin{aligned}
y_{t+1|t}^b &amp;= (\alpha_1 + \beta_{11} y_{t} + \ldots + \beta_{1p} y_{t+1-p})I(y_{t} \leq c) \\
                &amp;+ (\alpha_2 + \beta_{21} y_{t} + \ldots + \beta_{2p} y_{t+1-p})I(y_{t} &gt; c)+\varepsilon_{t+1}^b
\end{aligned}\]</span></p>
<p>Two-step-ahead bootstrap iteration:
<span class="math display">\[\begin{aligned}
y_{t+2|t}^b &amp;= (\alpha_1 + \beta_{11} y_{t+1|t}^b + \ldots + \beta_{1p} y_{t+2-p})I(y_{t+1|t}^b \leq c) \\
                &amp;+ (\alpha_2 + \beta_{21} y_{t+1|t}^b + \ldots + \beta_{2p} y_{t+2-p})I(y_{t+1|t}^b &gt; c)+\varepsilon_{t+2}^b
\end{aligned}\]</span></p>
<p>One-step-ahead bootstrap forecast: <span class="math display">\[\bar{y}_{t+1|t} = B^{-1}\sum_{b=1}^{B}y_{t+1|t}^b\]</span></p>
<p>Two-step-ahead bootstrap forecast: <span class="math display">\[\bar{y}_{t+2|t} = B^{-1}\sum_{b=1}^{B}y_{t+2|t}^b\]</span></p>
<p>Here, <span class="math inline">\(B\)</span> is the total number of bootstrap iterations (usually many thousand iterations).</p>
<!--chapter:end:08-nonlinear.Rmd-->
</div>
</div>
</div>
<div id="forecast-evaluation" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Forecast Evaluation</h1>
<div id="the-need-for-the-forecast-evaluation" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> The Need for the Forecast Evaluation</h2>
<p>We typically have several candidate econometric models or methods to forecast an economic variable of interest. Among these, we tend to select the most adequate using in-sample goodness of fit measures (e.g., AIC or SIC).</p>
<p>A more sensible approach, at least from the standpoint of a forecaster, would be to assess goodness of fit in an out-of-sample setting. Recall that models that offer the superior in-sample fit don’t necessarily produce the most accurate out-of-sample forecasts. That is, while a better in-sample fit can be achieved by incorporating additional parameters in the model, such more complex models extrapolate the estimated parameter uncertainty into the forecasts, thus sabotaging their accuracy.</p>
<p>Thus far we have applied the following algorithm to identify ‘the best’ among the competing forecasts:</p>
<ul>
<li>Decide on a loss function (e.g., quadratic loss).</li>
<li>Obtain forecasts, the forecast errors, and the corresponding sample expected loss (e.g., root mean squared forecast error) for each model in consideration.</li>
<li>Rank the models according to their sample expected loss values.</li>
<li>Select the model with the lowest sample expected loss.</li>
</ul>
<p>But the loss function is a function of a random variable, and in practice we deal with sample information, so sampling variation needs to be taken into the account. Statistical methods of evaluation are, therefore, desirable (at the very least).</p>
</div>
<div id="relative-forecast-accuracy-tests" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Relative Forecast Accuracy Tests</h2>
<p>Here we will cover two tests for the hypothesis that two forecasts are equivalent, in the sense that the associated loss differential is not statistically significantly different from zero.</p>
<p>Consider a time series of length <span class="math inline">\(T\)</span>. Suppose <span class="math inline">\(h\)</span>-step-ahead forecasts for periods <span class="math inline">\(R+h\)</span> through <span class="math inline">\(T\)</span> have been generated from two competing models <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>: <span class="math inline">\(y_{t+h|t,i}\)</span> and <span class="math inline">\(y_{t+h|t,j}\)</span>, with corresponding forecast errors: <span class="math inline">\(e_{t+h,i}\)</span> and <span class="math inline">\(e_{t+h,j}\)</span>. The null hypothesis of equal predictive ability can be given in terms of the unconditional expectation of the loss differential: <span class="math display">\[H_0: E\left[d(e_{t+h,ij})\right] = 0,\]</span> where <span class="math inline">\(d(e_{t+h,ij}) = L(e_{t+h,i})-L(e_{t+h,j})\)</span>.</p>
<div id="the-morgan-granger-newbold-test" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> The Morgan-Granger-Newbold Test</h3>
<p>The Morgan-Granger-Newbold (MGN) test is based on auxiliary variables: <span class="math inline">\(u_{1,t+h} = e_{t+h,i}-e_{t+h,j}\)</span> and <span class="math inline">\(u_{2,t+h} = e_{t+h,i}+e_{t+h,j}\)</span>. It follows that: <span class="math display">\[E(u_{1,t+h},u_{2,t+h}) = MSFE(i,t+h)-MSFE(j,t+h).\]</span> Thus, the hypothesis of interest is equivalent to testing whether the two auxiliary variables are correlated.</p>
<p>The MGN test statistic is: <span class="math display">\[\frac{r}{\sqrt{(P-1)^{-1}(1-r^2)}}\sim t_{P-1},\]</span> where <span class="math inline">\(t_{P-1}\)</span> is a Student t distribution with <span class="math inline">\(P-1\)</span> degrees of freedom, <span class="math inline">\(P\)</span> is the number of out-of-sample forecasts, and <span class="math display">\[r=\frac{\sum_{t=R}^{T-h}{u_{1,t+h}u_{2,t+h}}}{\sqrt{\sum_{t=R}^{T-h}{u_{1,t+h}^2}\sum_{t=R}^{T-h}{u_{2,t+h}^2}}}\]</span></p>
<p>The MGN test relies on the assumption that forecast errors (of the forecasts to be compared) are unbiased, normally distributed, and uncorrelated (with each other). These are rather strict assumptions that are, often, violated in empirical applications.</p>
</div>
<div id="the-diebold-mariano-test" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> The Diebold-Mariano Test</h3>
<p>The Diebold-Mariano (DM) test relaxes the aforementioned requirements on the forecast errors. The DM test statistic is: <span class="math display">\[\frac{\bar{d}_h}{\sqrt{\sigma_d^2/P}} \sim N(0,1),\]</span> where <span class="math inline">\(\bar{d}_h=P^{-1}\sum_{t=R}^{T-h} d(e_{t+h,ij})\)</span>, and where <span class="math inline">\(P=T-R-h+1\)</span> is the total number of forecasts generated using a rolling or recursive widnow scheme, for example.</p>
<p>A modified version of the DM statistic, due to Harvey, Leybourne, and Newbold (1998), addresses the finite sample properties of the test, so that: <span class="math display">\[\sqrt{\frac{P+1-2h+P^{-1}h(h-1)}{P}}DM\sim t_{P-1},\]</span> where <span class="math inline">\(t_{P-1}\)</span> is a Student t distribution with <span class="math inline">\(P-1\)</span> degrees of freedom.</p>
<p>In practice, the test of equal predictive ability can be applied within the framework of a regression model as follows: <span class="math display">\[d_{t+h} = \delta + \upsilon_{t+h}\;~~t = R,\ldots,T-h,\]</span> where <span class="math inline">\(d_{t+h} \equiv d(e_{t+h,ij})\)</span>. The null of equal predictive ability is equivalent of testing <span class="math inline">\(H_0: \delta = 0\)</span> in the OLS setting. Moreover, because <span class="math inline">\(d_{t+h}\)</span> may be serially correlated, autocorrelation consistent standard errors should be used for inference.</p>
<!--chapter:end:09-assessment.Rmd-->
</div>
</div>
</div>
<div id="forecast-combination" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Forecast Combination</h1>
<!--chapter:end:10-combination.Rmd-->
</div>
<div id="forecasting-using-r" class="section level1 unnumbered">
<h1 class="unnumbered">Forecasting Using R</h1>
</div>
<div id="tutorial-1-introduction-to-r" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 1: Introduction to R</h1>
<p>R is a programming language for data analysis and visualisation. Here I introduce basic commands that should facilitate your understanding of R. You can further enhance your skillset using numerous online resources, as well as your own trial–and–error. To the extent that new features are added to R on a daily basis, there are virtually no limits to how far you can advance your knowledge of this programming language.</p>
<p>We will work in RStudio—the go-to interface for R (as R itself is not an overly user-friendly platform). Thus, you will need to have installed both, R and RStudio on your devise (the latter will ‘find’ and connect with the former on its own). R is available from <a href="https://cran.r-project.org/">CRAN</a>, and RStudio is available from <a href="https://www.rstudio.com/">RStudio</a>.</p>
<p>There are a number of ways in which we can work with data in R. Let’s begin with matrices.</p>
<p>Consider a string of observations:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">6</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<pre><code>## [1] 1 0 4 3 2 6</code></pre>
<p>A <em>string</em>, unlike a <em>vector</em>, has no dimensions. But we can transform it to a <span class="math inline">\(n \times 1\)</span> vector using the as.matrix() function:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(a)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div>
<pre><code>##      [,1]
## [1,]    1
## [2,]    0
## [3,]    4
## [4,]    3
## [5,]    2
## [6,]    6</code></pre>
<p>The result is a <span class="math inline">\(6 \times 1\)</span> vector, or a column matrix. To obtain a <span class="math inline">\(1 \times 6\)</span> vector, or a row matrix, we <em>transpose</em> the foregoing vector using the t() function:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>bt <span class="ot">&lt;-</span> <span class="fu">t</span>(b)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>bt</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]    1    0    4    3    2    6</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(bt)</span></code></pre></div>
<pre><code>## [1] 1 6</code></pre>
<p>We can create any <span class="math inline">\(n \times k\)</span> matrix, using the matrix() function. For example, consider a <span class="math inline">\(3 \times 2\)</span> matrix:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">matrix</span>(a,<span class="at">nrow=</span><span class="dv">3</span>,<span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>B</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    3
## [2,]    0    2
## [3,]    4    6</code></pre>
<p>We can add column names and row names to this matrix:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(B) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;c1&quot;</span>,<span class="st">&quot;c2&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(B) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;r1&quot;</span>,<span class="st">&quot;r2&quot;</span>,<span class="st">&quot;r3&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>B</span></code></pre></div>
<pre><code>##    c1 c2
## r1  1  3
## r2  0  2
## r3  4  6</code></pre>
<p>If, at this point, we would like to only work with, say, the first column of the matrix, we can call it using its column number, (1), or the column name, (“c1”), as follows:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>B[,<span class="st">&quot;c1&quot;</span>]</span></code></pre></div>
<pre><code>## r1 r2 r3 
##  1  0  4</code></pre>
<p>Similarly, if we want to refer to a matrix element, say <span class="math inline">\(b_{3,2}\)</span>, we can do this as follows:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>B[<span class="dv">3</span>,<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>Matrix multiplication is done using %*% command, granted that the two matrices are compatible. For example, we obtain a product of matrix <span class="math inline">\(B\)</span> and a new <span class="math inline">\(2 \times 1\)</span> vector, <span class="math inline">\(d\)</span>, as follows:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">c</span>(<span class="dv">5</span>,<span class="sc">-</span><span class="dv">2</span>))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>Bd <span class="ot">&lt;-</span> B<span class="sc">%*%</span>d</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>Bd</span></code></pre></div>
<pre><code>##    [,1]
## r1   -1
## r2   -4
## r3    8</code></pre>
<p>We can add columns (and rows) to the existing matrix using a cbind() function:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>c3 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">cbind</span>(B,c3)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>D</span></code></pre></div>
<pre><code>##    c1 c2 c3
## r1  1  3  0
## r2  0  2  1
## r3  4  6  0</code></pre>
<p>We can invert a(n invertible) matrix using the solve() function:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>Di <span class="ot">&lt;-</span> <span class="fu">solve</span>(D)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>Di</span></code></pre></div>
<pre><code>##            r1 r2         r3
## c1 -1.0000000  0  0.5000000
## c2  0.6666667  0 -0.1666667
## c3 -1.3333333  1  0.3333333</code></pre>
<p>One of the comparative advantages of R is in its graphing aesthetics. Currently, the best graphs are plotted via the <strong>ggplot2</strong> package. Notably, this package requires that the data are maintained in the data.frame or the data.table format (for the latter, you need to load the <strong>data.table</strong> package). Let’s create a data.table object and observe its few lines:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">120</span>,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fl">0.2+0.7</span><span class="sc">*</span>x<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">120</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">y=</span>y,<span class="at">x=</span>x)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>dt</span></code></pre></div>
<pre><code>##               y          x
##   1:  2.9733299 0.53101733
##   2:  0.6817335 0.74424780
##   3:  1.6917341 1.14570673
##   4:  1.4994931 1.81641558
##   5: -0.2609185 0.40336386
##  ---                      
## 116:  0.1835826 0.02615515
## 117:  1.9894321 1.43113213
## 118:  2.4197029 0.20636847
## 119:  1.8521905 0.89256870
## 120:  2.3040499 1.28020209</code></pre>
<p>Now, let’s load <strong>ggplot2</strong> and generate a simple scatter plot:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-29-1.png" width="624"  /></p>
<p>We can augment this plot in a number of different ways. Here we change the point color to red, add the fitted regression line to the plot, add labels to the figure, and apply a ‘classic’ background theme:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;goldenrod&quot;</span>)<span class="sc">+</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>,<span class="at">formula=</span>y<span class="sc">~</span>x,<span class="at">se=</span>F,<span class="at">color=</span><span class="st">&quot;darkgray&quot;</span>)<span class="sc">+</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;A scatterplot with fitted regression line&quot;</span>, </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">x=</span><span class="st">&quot;Treatment Variable&quot;</span>, </span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span><span class="st">&quot;Outcome Variable&quot;</span>, </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">caption=</span><span class="st">&quot;Caption: in case if needed.&quot;</span>)<span class="sc">+</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-30-1.png" width="624"  /></p>
<p>As another example, let’s generate a histogram (of the dependent variable):</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>y))<span class="sc">+</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">color=</span><span class="st">&quot;white&quot;</span>,<span class="at">fill=</span><span class="st">&quot;goldenrod&quot;</span>,<span class="at">binwidth=</span>.<span class="dv">5</span>)<span class="sc">+</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;A basic histogram&quot;</span>)<span class="sc">+</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-31-1.png" width="624"  /></p>
<p>We typically apply a line plot to illustrate a time series (that are ordered by date). In what follows, we add a date column to our data frame and then plot the dependent variable in the chronological order:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="fu">as.Date</span>(<span class="st">&quot;2000-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color=</span><span class="st">&quot;goldenrod&quot;</span>)<span class="sc">+</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;A basic time series plot&quot;</span>,  </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">x=</span><span class="st">&quot;Year&quot;</span>, </span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span><span class="st">&quot;Outcome Variable&quot;</span>)<span class="sc">+</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-32-1.png" width="624"  /></p>
<p>To illustrate the OLS regression in R, we apply the previously generated <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> as independent and dependent variables. To begin, we obtain the least squares estimator “by hand” as follows:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>,x)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X)<span class="sc">%*%</span>X)<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div>
<pre><code>##        [,1]
##   0.3577680
## x 0.5781188</code></pre>
<p>This can be easily done using the lm() function:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>ols</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      0.3578       0.5781</code></pre>
<p>We can apply the summary() function to see the complete set of regression results:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ols)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.9662 -0.5983 -0.1127  0.5639  2.3882 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.3578     0.1904   1.879 0.062717 .  
## x             0.5781     0.1641   3.522 0.000609 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9716 on 118 degrees of freedom
## Multiple R-squared:  0.09514,    Adjusted R-squared:  0.08748 
## F-statistic: 12.41 on 1 and 118 DF,  p-value: 0.0006091</code></pre>
<!--chapter:end:11-tutorial01.Rmd-->
</div>
<div id="tutorial-2-data-management" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 2: Data Management</h1>
<p>In this tutorial, we will introduce several simple R functions, and will perform a basic forecasting exercise.</p>
<p>Let’s generate a sequence of 200 iid random variables with mean zero and variance 4, call it e.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>,<span class="dv">0</span>,<span class="dv">2</span>)</span></code></pre></div>
<p>Notice that prior to sampling we set seed to some value (to one in this instance). We do so to ensure that we can exactly replicate the sample in the future.</p>
<p>Next, generate a sequence of 200 binary variables, call it x.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">200</span>,<span class="at">replace=</span>T)</span></code></pre></div>
<p>Construct a dependent variable, y, using the following formula: <span class="math inline">\(y=2+0.5x+e\)</span>.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span><span class="fl">+0.5</span><span class="sc">*</span>x<span class="sc">+</span>e</span></code></pre></div>
<p>Regress y on x, using the <code>lm()</code> function, to obtain estimates of the intercept and slope parameters.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ols</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      2.1244       0.3854</code></pre>
<p>Generate some “future” realizations (100 observations) of y.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">100</span>,<span class="at">replace=</span>T)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span><span class="fl">+0.5</span><span class="sc">*</span>x<span class="sc">+</span>e</span></code></pre></div>
<p>Note that these represent actual realizations of the variable; these not forecasts.</p>
<p>Suppose we think that in the considered forecast period, x only takes on 1 (below we will refer to this as the Model 1). Based on this, and using parameter estimates from above, let’s generate forecasts for this period.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>y_f1 <span class="ot">&lt;-</span> ols<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ols<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span><span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">100</span>)</span></code></pre></div>
<p>At this point, we have actual realisations of y and its forecasts. Thus, we can obtain forecast errors, mean absolute forecast errors, and root mean square forecast errors.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>e_f1 <span class="ot">&lt;-</span> y<span class="sc">-</span>y_f1</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>mafe1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(e_f1))</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>rmsfe1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(e_f1<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>mafe1</span></code></pre></div>
<pre><code>## [1] 1.43523</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>rmsfe1</span></code></pre></div>
<pre><code>## [1] 1.739508</code></pre>
<p>Suppose, instead, we think that in the considered forecast period x only takes on 0 (below we will refer to this as the Model 2). Based on this, and using parameter estimates from above, let’s generate forecasts for this period.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>y_f0 <span class="ot">&lt;-</span> ols<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ols<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span><span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">100</span>)</span></code></pre></div>
<p>Using these forecasts, obtain forecast errors, mean absolute forecast errors, and root mean square forecast errors.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>e_f0 <span class="ot">&lt;-</span> y<span class="sc">-</span>y_f0</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>mafe0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(e_f0))</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>rmsfe0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(e_f0<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>mafe0</span></code></pre></div>
<pre><code>## [1] 1.455768</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>rmsfe0</span></code></pre></div>
<pre><code>## [1] 1.736182</code></pre>
<p>By comparing the two sets of forecasts, we can observe a somewhat rare and yet not an unlikely scenario: MAFE points to the Model 1 as more accurate of the two models, while RMSFE suggests the Model 2 as the more accurate one. More often than not, however, these two accuracy measures tend to agree.</p>
<!--chapter:end:12-tutorial02.Rmd-->
</div>
<div id="tutorial-3-forecasting-methods-and-routines" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 3: Forecasting Methods and Routines</h1>
<p>In this tutorial, we will introduce ‘for loop’, and use it to generate time series as well as to obtain one-step-ahead forecasts using a rolling window procedure; we will also perform forecast error diagnostics.</p>
<p>Let’s generate a random walk process, such that <span class="math inline">\(y_{t} = y_{t-1}+e_{t}\)</span>, where <span class="math inline">\(e_{t} ~ N(0,1)\)</span>, and where <span class="math inline">\(y_{0}=0\)</span>, for <span class="math inline">\(t=1,\ldots,120\)</span>.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">120</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> e[<span class="dv">1</span>]</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> y[i<span class="dv">-1</span>] <span class="sc">+</span> e[i]</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Store <span class="math inline">\(y\)</span> and <span class="math inline">\(e\)</span> in a <strong>data.table</strong>, call it ‘dt’. Add some arbitrary dates to the data (e.g., suppose we deal with the monthly series beginning from January 2011).</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(y,e)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2011-01-01&quot;</span>),<span class="fu">as.Date</span>(<span class="st">&quot;2020-12-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>)</span></code></pre></div>
<p>Plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Random Walk&quot;</span>)<span class="sc">+</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-49-1.png" width="624"  /></p>
<p>Generate a sequence of one-step-ahead forecasts from naive and average methods, using the rolling window scheme, where the first rolling window ranges from period 1 to period 80.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>average <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>naive <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> n<span class="sc">-</span>R</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">&lt;-</span> y[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)]</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>average[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(w)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>naive[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> w[<span class="fu">length</span>(w)]</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Calculate the RMSFE measures for each of the two forecasting methods.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">e_average=</span>y<span class="sc">-</span>average,<span class="at">e_naive=</span>y<span class="sc">-</span>naive)]</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>rmsfe_average <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_average<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>rmsfe_naive <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_naive<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>rmsfe_average</span></code></pre></div>
<pre><code>## [1] 4.672947</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>rmsfe_naive</span></code></pre></div>
<pre><code>## [1] 0.850081</code></pre>
<p>Perform the forecast error diagnostics for the two considered methods.</p>
<p>Zero mean of the forecast errors: <span class="math inline">\(E(e_{t+1|t})=0\)</span>.
We perform this test by regressing the forecast error on the constant, and checking whether the coefficient is statistically significantly different from zero.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_average<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##             Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept) 4.434858  0.2358002 18.80769 3.682273e-21</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_naive<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.1168396    0.13483 0.86657 0.391478</code></pre>
<p>No correlation of the forecast errors with the forecasts: <span class="math inline">\(Cov(e_{t+1|t},y_{t+1|t})=0\)</span>. We perform this test by regressing the forecast error on the forecast, and checking whether the slope coefficient is statistically significantly different from zero.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_average<span class="sc">~</span>average,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##              Estimate Std. Error  t value   Pr(&gt;|t|)
## (Intercept) 2.4180785  1.2929708 1.870172 0.06917788
## average     0.2942557  0.1856048 1.585389 0.12116580</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_naive<span class="sc">~</span>naive,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##                Estimate Std. Error   t value  Pr(&gt;|t|)
## (Intercept)  1.06489905 0.69740557  1.526944 0.1350565
## naive       -0.08486143 0.06127484 -1.384931 0.1741512</code></pre>
<p>No serial correlation in one-step-ahead forecast errors: <span class="math inline">\(Cov(e_{t+1|t},y_{t|t-1})=0\)</span>. We perform this test by regressing the forecast error on its lag, and checking whether the slope coefficient is statistically significantly different from zero.
(Note: first we need to generate lagged forecast errors)</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">e_average.l1=</span><span class="fu">shift</span>(e_average),<span class="at">e_naive.l1=</span><span class="fu">shift</span>(e_naive))]</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_average<span class="sc">~</span>e_average.l1,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##               Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)  0.7898068 0.42027705 1.879253 6.810403e-02
## e_average.l1 0.8275396 0.08966026 9.229726 3.892504e-11</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(e_naive<span class="sc">~</span>e_naive.l1,<span class="at">data=</span>dt))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##               Estimate Std. Error   t value  Pr(&gt;|t|)
## (Intercept) 0.12971406  0.1403668 0.9241081 0.3614178
## e_naive.l1  0.03780853  0.1631333 0.2317647 0.8179979</code></pre>
<p><strong>(this is a direct/iterated stuff)</strong></p>
<p>In this tutorial, we will generate a time series, we will obtain multi-step-ahead forecasts using direct and iterated methods from autoregressive models using a rolling window procedure, and we will assess the accuracy of the forecast. We will then turn to interval forecasts, and we will assess their coverage accuracy. To run the code, the <code>data.table</code>, <code>ggplot2</code>, <code>lmtest</code>, and <code>sandwich</code> packages need to be installed and loaded.</p>
<p>Let’s generate a time series that follow an AR(2) process as follows:
<span class="math display">\[y_t = 0.01t+0.6y_{t-1}+0.2y_{t-2}+\varepsilon_t\]</span>
where <span class="math inline">\(e_{t} \sim N(0,1)\)</span>.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">240</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.01</span><span class="sc">+</span>e[<span class="dv">1</span>]</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">0.02+0.6</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>n){</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> <span class="fl">0.01</span><span class="sc">*</span>i<span class="fl">+0.6</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">+</span><span class="fl">0.2</span><span class="sc">*</span>y[i<span class="dv">-2</span>]<span class="sc">+</span>e[i]</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of arbitrary dates (e.g., the monthly series beginning from January 2000), store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’, and plot the realized time series using the <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2000-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-56-1.png" width="624"  /></p>
<p>Suppose we believe the series follow either the AR(1) or the AR(2) process, and that we want to compare iterated multi-step forecasts obtained from these models to direct multi-step forecasts. In what follows, we will generate twelve-step-ahead point forecasts from these two methods for the considered two models using the rolling window scheme, where the first rolling window ranges from period 1 to period 180. In obtaining the iterated multi-step forecasts, for each rolling window, we will generate a sequence of one-to-twelve-step-ahead forecasts, but only retain the twelve-step-ahead forecasts.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> dt[,.(date,y,<span class="at">y1=</span><span class="fu">shift</span>(y,<span class="dv">1</span>),<span class="at">y2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">y12=</span><span class="fu">shift</span>(y,h),<span class="at">y13=</span><span class="fu">shift</span>(y,h<span class="sc">+</span><span class="dv">1</span>))]</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> dt[<span class="fu">complete.cases</span>(dt)]</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">a1i=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a1d=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a2i=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a2d=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))]</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R<span class="sc">-</span>h<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">### iterated multi-step method</span></span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>  a1i <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>  a2i <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1<span class="sc">+</span>y2,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>  iter_dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">hor=</span><span class="dv">1</span><span class="sc">:</span>h,<span class="at">a1=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a2=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>  <span class="do">## AR(1)</span></span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>  iter_dt<span class="sc">$</span>a1[<span class="dv">1</span>] <span class="ot">&lt;-</span> a1i<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a1i<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>h){</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>    iter_dt<span class="sc">$</span>a1[j] <span class="ot">&lt;-</span> a1i<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a1i<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>iter_dt<span class="sc">$</span>a1[j<span class="dv">-1</span>]</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a>  <span class="do">## AR(2)</span></span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>  iter_dt<span class="sc">$</span>a2[<span class="dv">1</span>] <span class="ot">&lt;-</span> a2i<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y1</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>  iter_dt<span class="sc">$</span>a2[<span class="dv">2</span>] <span class="ot">&lt;-</span> a2i<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>iter_dt<span class="sc">$</span>a2[<span class="dv">1</span>]<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y</span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>h){</span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>    iter_dt<span class="sc">$</span>a2[j] <span class="ot">&lt;-</span> a2i<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>iter_dt<span class="sc">$</span>a2[j<span class="dv">-1</span>]<span class="sc">+</span>a2i<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>iter_dt<span class="sc">$</span>a2[j<span class="dv">-2</span>]</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1i[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> iter_dt<span class="sc">$</span>a1[h]</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a2i[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> iter_dt<span class="sc">$</span>a2[h]</span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a>  <span class="do">### direct multi-step method</span></span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a>  a1d <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y12,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a>  a2d <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y12<span class="sc">+</span>y13,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1d[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> a1d<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a1d<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y</span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a2d[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> a2d<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a2d<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y<span class="sc">+</span>a2d<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y1</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-42"><a href="#cb73-42" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can now test whether the forecasts of the iterated method ‘statistically significantly’ outperform those of the direct method?</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a1i_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a1i</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a2i_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a2i</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a1d_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a1d</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a2d_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a2d</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld1 <span class="ot">&lt;-</span> dt<span class="sc">$</span>a1d_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a1i_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld2 <span class="ot">&lt;-</span> dt<span class="sc">$</span>a2d_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a2i_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>reg_ld1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld1<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>reg_ld2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld2<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg_ld1,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg_ld1))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  -6.9266     1.7170 -4.0342 0.0002828 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg_ld2,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg_ld2))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -3.1094     1.3271  -2.343  0.02494 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Obtain interval forecasts for horizon 12 using the direct method for an AR(1) model and a linear trend model; plot these interval forecasts along with the observed series.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>trend <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(dt))</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">a1dl=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a1du=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">trdl=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">trdu=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))]</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>  a1d <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y12,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>  trd <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>trend,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>  a1d_pf <span class="ot">&lt;-</span> a1d<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>a1d<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span>]<span class="sc">$</span>y</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>  trd_pf <span class="ot">&lt;-</span> trd<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>trd<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt[R<span class="sc">+</span>i<span class="dv">-1</span><span class="sc">+</span>h]<span class="sc">$</span>trend</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>  a1d_sd <span class="ot">&lt;-</span> <span class="fu">summary</span>(a1d)<span class="sc">$</span>sigma</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>  trd_sd <span class="ot">&lt;-</span> <span class="fu">summary</span>(trd)<span class="sc">$</span>sigma</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1dl[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> a1d_pf<span class="fl">-1.96</span><span class="sc">*</span>a1d_sd</span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1du[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> a1d_pf<span class="fl">+1.96</span><span class="sc">*</span>a1d_sd</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>trdl[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> trd_pf<span class="fl">-1.96</span><span class="sc">*</span>trd_sd</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>trdu[R<span class="sc">+</span>i<span class="sc">+</span>h<span class="dv">-1</span>] <span class="ot">&lt;-</span> trd_pf<span class="fl">+1.96</span><span class="sc">*</span>trd_sd</span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb78-23"><a href="#cb78-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>)<span class="sc">+</span></span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>a1dl),<span class="at">size=</span><span class="dv">1</span>,<span class="at">color=</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">linetype=</span><span class="dv">5</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>a1du),<span class="at">size=</span><span class="dv">1</span>,<span class="at">color=</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">linetype=</span><span class="dv">5</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb78-26"><a href="#cb78-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>trdl),<span class="at">size=</span><span class="dv">1</span>,<span class="at">color=</span><span class="st">&quot;indianred&quot;</span>,<span class="at">linetype=</span><span class="dv">5</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb78-27"><a href="#cb78-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>trdu),<span class="at">size=</span><span class="dv">1</span>,<span class="at">color=</span><span class="st">&quot;indianred&quot;</span>,<span class="at">linetype=</span><span class="dv">5</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb78-28"><a href="#cb78-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-59-1.png" width="624"  /></p>
<p>Test the unconditional coverage of the interval forecasts from the considered two models.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">i1=</span><span class="fu">ifelse</span>(y<span class="sc">&gt;=</span>a1dl <span class="sc">&amp;</span> y<span class="sc">&lt;=</span>a1du,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">it=</span><span class="fu">ifelse</span>(y<span class="sc">&gt;=</span>trdl <span class="sc">&amp;</span> y<span class="sc">&lt;=</span>trdu,<span class="dv">1</span>,<span class="dv">0</span>))]</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># AR(1)</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(dt<span class="sc">$</span>i1,<span class="at">na.rm=</span>T)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>L10 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="fl">-.95</span>)<span class="sc">^</span>(P<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p1))<span class="sc">*</span>(.<span class="dv">95</span>)<span class="sc">^</span>(P<span class="sc">*</span>p1)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>L11 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">-</span>p1)<span class="sc">^</span>(P<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p1))<span class="sc">*</span>(p1)<span class="sc">^</span>(P<span class="sc">*</span>p1)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>LR1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">log</span>(L10<span class="sc">/</span>L11)</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(LR1,<span class="at">df=</span><span class="dv">1</span>,<span class="at">lower.tail=</span>F)</span></code></pre></div>
<pre><code>## [1] 0.01027851</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># AR(2)</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(dt<span class="sc">$</span>it,<span class="at">na.rm=</span>T)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>L20 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="fl">-.95</span>)<span class="sc">^</span>(P<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p2))<span class="sc">*</span>(.<span class="dv">95</span>)<span class="sc">^</span>(P<span class="sc">*</span>p2)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>L21 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">-</span>p2)<span class="sc">^</span>(P<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p2))<span class="sc">*</span>(p2)<span class="sc">^</span>(P<span class="sc">*</span>p2)</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>LR2 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">log</span>(L20<span class="sc">/</span>L21)</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(LR2,<span class="at">df=</span><span class="dv">1</span>,<span class="at">lower.tail=</span>F)</span></code></pre></div>
<pre><code>## [1] 0.1441849</code></pre>
<!--chapter:end:13-tutorial03.Rmd-->
</div>
<div id="tutorial-4-trends-and-seasonality" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 4: Trends and Seasonality</h1>
<p>In this tutorial, we will generate trending series, we will apply an information criterion to select the most suitable trend model, and we will obtain and compare one-step-ahead forecasts using a rolling window procedure.</p>
<p>Let’s generate a time series that follows a quadratic trend: <span class="math inline">\(y_{t} = 10+0.01t+0.002t^2+e_{t}\)</span>, where <span class="math inline">\(e_{t} \sim N(0,16)\)</span>, for <span class="math inline">\(t=1,\ldots,180\)</span>.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">4</span>)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>trend <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>n)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">10</span><span class="fl">+0.01</span><span class="sc">*</span>trend<span class="fl">+0.002</span><span class="sc">*</span>trend<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>e</span></code></pre></div>
<p>Store <span class="math inline">\(y\)</span> and <span class="math inline">\(trend\)</span> in a <strong>data.table</strong>, call it ‘dt’. Add some arbitrary dates to the data (e.g., suppose we deal with the monthly series beginning from January 2006).</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(y,trend)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2006-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span></code></pre></div>
<p>Plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Trending Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-64-1.png" width="624"  /></p>
<p>Calculate Akaike Information Criteria for linear, quadratic, cubic, and exponential trend models, using all observations in the series.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>AIC_vec <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol=</span><span class="dv">4</span>,<span class="at">nrow=</span><span class="dv">1</span>)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>){</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(i <span class="sc">&lt;</span> <span class="dv">4</span>){</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="fu">poly</span>(trend,<span class="at">degree=</span>i,<span class="at">raw=</span>T),<span class="at">data=</span>dt)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    AIC_vec[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(reg<span class="sc">$</span>residuals))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span><span class="fu">length</span>(reg<span class="sc">$</span>coefficients)<span class="sc">/</span>n</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(y)<span class="sc">~</span>trend,<span class="at">data=</span>dt)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    yhat <span class="ot">&lt;-</span> reg<span class="sc">$</span>fitted.values</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    sig <span class="ot">&lt;-</span> <span class="fu">sd</span>(reg<span class="sc">$</span>residuals)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    ystar <span class="ot">&lt;-</span> <span class="fu">exp</span>(yhat<span class="sc">+</span>sig<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>ystar</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>    AIC_vec[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(res))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span><span class="fu">length</span>(reg<span class="sc">$</span>coefficients)<span class="sc">/</span>n</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>AIC_vec</span></code></pre></div>
<pre><code>##          [,1]     [,2]     [,3]     [,4]
## [1,] 8.879646 7.841645 7.849521 7.975999</code></pre>
<p>Generate a sequence of one-step-ahead forecasts from linear, quadratic, cubic, and exponential trend models, using the rolling window scheme, where the first rolling window ranges from period 1 to period 120.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>t1 <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>t2 <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>t3 <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>te <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">120</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> n<span class="sc">-</span>R</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>  reg1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>trend,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>t1[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> reg1<span class="sc">$</span>coef[<span class="dv">1</span>]<span class="sc">+</span>reg1<span class="sc">$</span>coef[<span class="dv">2</span>]<span class="sc">*</span>(R<span class="sc">+</span>i)</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>  reg2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="fu">poly</span>(trend,<span class="at">degree=</span><span class="dv">2</span>,<span class="at">raw=</span>T),<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>t2[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> reg2<span class="sc">$</span>coef[<span class="dv">1</span>]<span class="sc">+</span>reg2<span class="sc">$</span>coef[<span class="dv">2</span>]<span class="sc">*</span>(R<span class="sc">+</span>i)<span class="sc">+</span>reg2<span class="sc">$</span>coef[<span class="dv">3</span>]<span class="sc">*</span>((R<span class="sc">+</span>i)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>  reg3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="fu">poly</span>(trend,<span class="at">degree=</span><span class="dv">3</span>,<span class="at">raw=</span>T),<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>t3[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> reg3<span class="sc">$</span>coef[<span class="dv">1</span>]<span class="sc">+</span>reg3<span class="sc">$</span>coef[<span class="dv">2</span>]<span class="sc">*</span>(R<span class="sc">+</span>i)<span class="sc">+</span>reg3<span class="sc">$</span>coef[<span class="dv">3</span>]<span class="sc">*</span>((R<span class="sc">+</span>i)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span>reg3<span class="sc">$</span>coef[<span class="dv">4</span>]<span class="sc">*</span>((R<span class="sc">+</span>i)<span class="sc">^</span><span class="dv">3</span>)</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>  rege <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(y)<span class="sc">~</span>trend,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>  sig <span class="ot">&lt;-</span> <span class="fu">sd</span>(rege<span class="sc">$</span>residuals)</span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>te[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> <span class="fu">exp</span>(rege<span class="sc">$</span>coef[<span class="dv">1</span>]<span class="sc">+</span>rege<span class="sc">$</span>coef[<span class="dv">2</span>]<span class="sc">*</span>(R<span class="sc">+</span>i)<span class="sc">+</span>sig<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Plot the original series overlay by the one-step-ahead forecasts from the four considered trend models. Note, for convenience we will first ‘melt’ the data.table in to the ‘long’ format.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>dt_long <span class="ot">&lt;-</span> <span class="fu">melt</span>(dt[,.(date,y,<span class="at">linear=</span>t1,<span class="at">quadratic=</span>t2,<span class="at">cubic=</span>t3,<span class="at">exponential=</span>te)],<span class="at">id.vars=</span><span class="st">&quot;date&quot;</span>)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt_long,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>value,<span class="at">color=</span>variable))<span class="sc">+</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;darkgray&quot;</span>,<span class="st">&quot;black&quot;</span>,<span class="st">&quot;goldenrod&quot;</span>,<span class="st">&quot;steelblue&quot;</span>,<span class="st">&quot;indianred&quot;</span>))<span class="sc">+</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Trending Series and Forecasts&quot;</span>)<span class="sc">+</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()<span class="sc">+</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title=</span><span class="fu">element_blank</span>(),<span class="at">legend.position=</span><span class="fu">c</span>(.<span class="dv">15</span>,.<span class="dv">85</span>))</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-67-1.png" width="624"  /></p>
<p>Calculate the RMSFE measures for each of the two forecasting methods.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">e_t1=</span>y<span class="sc">-</span>t1,<span class="at">e_t2=</span>y<span class="sc">-</span>t2,<span class="at">e_t3=</span>y<span class="sc">-</span>t3,<span class="at">e_te=</span>y<span class="sc">-</span>te)]</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>rmsfe_t1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_t1<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>rmsfe_t2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_t2<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>rmsfe_t3 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_t3<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>rmsfe_te <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>e_te<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>rmsfe_t1</span></code></pre></div>
<pre><code>## [1] 6.151904</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>rmsfe_t2</span></code></pre></div>
<pre><code>## [1] 3.796861</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>rmsfe_t3</span></code></pre></div>
<pre><code>## [1] 3.906023</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>rmsfe_te</span></code></pre></div>
<pre><code>## [1] 5.132312</code></pre>
<!--chapter:end:14-tutorial04.Rmd-->
</div>
<div id="tutorial-5-autoregressive-models" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 5: Autoregressive Models</h1>
<p>(this is a AR stuff, will need to move back)</p>
<p>In this tutorial, we will generate autocorrelated series, we will apply an information criterion to select a suitable autoregressive model, we will obtain and compare one-step-ahead forecasts from competing models using a rolling window procedure, and we will generate one set of multi-step forecasts to illustrate the convergence to unconditional mean of the series.</p>
<p>Let’s generate a time series that follows an AR(2) process: <span class="math inline">\(y_{t} = 1.2y_{t-1}-0.3y_{t-2}+e_{t}\)</span>, where <span class="math inline">\(e_{t} \sim N(0,1)\)</span>, for <span class="math inline">\(t=1,\ldots,180\)</span>.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> e[<span class="dv">1</span>]</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">1.2</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>n){</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> <span class="fl">1.2</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">-</span><span class="fl">0.3</span><span class="sc">*</span>y[i<span class="dv">-2</span>]<span class="sc">+</span>e[i]</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of some arbitrary dates (e.g., suppose we deal with the monthly series beginning from January 2006), and store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2006-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y)</span></code></pre></div>
<p>Plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Trending Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-72-1.png" width="624"  /></p>
<p>Generate and plot the autocorrelation function and the partial autocorrelation function for lags 1 through 18.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>acf_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">acf</span>(dt<span class="sc">$</span>y,<span class="at">lag.max=</span><span class="dv">18</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>pacf_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">pacf</span>(dt<span class="sc">$</span>y,<span class="at">lag.max=</span><span class="dv">18</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>sd_rho <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>n)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>acf_dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">lags=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">18</span>,<span class="at">acf=</span>acf_vec,<span class="at">pacf=</span>pacf_vec)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(acf_dt,<span class="fu">aes</span>(<span class="at">x=</span>lags,<span class="at">y=</span>acf)) <span class="sc">+</span></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="dv">0</span>,<span class="at">color=</span><span class="st">&quot;darkgray&quot;</span>,<span class="at">linetype=</span><span class="dv">3</span>,<span class="at">size=</span>.<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.96</span><span class="sc">*</span>sd_rho,<span class="fl">1.96</span><span class="sc">*</span>sd_rho),<span class="at">color=</span><span class="st">&quot;goldenrod&quot;</span>,<span class="at">linetype=</span><span class="dv">2</span>,<span class="at">size=</span>.<span class="dv">6</span>) <span class="sc">+</span></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend=</span>lags,<span class="at">yend=</span><span class="dv">0</span>),<span class="at">color=</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">size=</span>.<span class="dv">8</span>)<span class="sc">+</span></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Lag&quot;</span>,<span class="at">y=</span><span class="st">&quot;ACF&quot;</span>)<span class="sc">+</span></span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>))<span class="sc">+</span></span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-73-1.png" width="624"  /></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(acf_dt,<span class="fu">aes</span>(<span class="at">x=</span>lags,<span class="at">y=</span>pacf)) <span class="sc">+</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="dv">0</span>,<span class="at">color=</span><span class="st">&quot;darkgray&quot;</span>,<span class="at">linetype=</span><span class="dv">3</span>,<span class="at">size=</span>.<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.96</span><span class="sc">*</span>sd_rho,<span class="fl">1.96</span><span class="sc">*</span>sd_rho),<span class="at">color=</span><span class="st">&quot;goldenrod&quot;</span>,<span class="at">linetype=</span><span class="dv">2</span>,<span class="at">size=</span>.<span class="dv">6</span>) <span class="sc">+</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend=</span>lags,<span class="at">yend=</span><span class="dv">0</span>),<span class="at">color=</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">size=</span>.<span class="dv">8</span>)<span class="sc">+</span></span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Lag&quot;</span>,<span class="at">y=</span><span class="st">&quot;PACF&quot;</span>)<span class="sc">+</span></span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>))<span class="sc">+</span></span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-73-2.png" width="624"  /></p>
<p>Calculate Akaike Information Criteria (AIC) and Schwarz Information Criteria (SIC) for AR(1), AR(2), AR(3), and AR(4) models, using all observations in the series, to decide on the optimal lag length.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">y_l1=</span><span class="fu">shift</span>(y),<span class="at">y_l2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">y_l3=</span><span class="fu">shift</span>(y,<span class="dv">3</span>),<span class="at">y_l4=</span><span class="fu">shift</span>(y,<span class="dv">4</span>))]</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="co"># get rid of the rows with NAs</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> dt[<span class="fu">complete.cases</span>(dt)]</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>IC_dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">lag=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>),<span class="at">AIC=</span><span class="cn">NA</span>,<span class="at">SIC=</span><span class="cn">NA</span>)</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(IC_dt)){</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>  fmla <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="fu">paste</span>(<span class="st">&quot;y&quot;</span>,<span class="fu">paste0</span>(<span class="st">&quot;y_l&quot;</span>,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>i),<span class="at">collapse=</span><span class="st">&quot;+&quot;</span>),<span class="at">sep=</span><span class="st">&quot;~&quot;</span>))</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>  reg.ar <span class="ot">&lt;-</span> <span class="fu">lm</span>(fmla,<span class="at">data=</span>dt)</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>  IC_dt<span class="sc">$</span>AIC[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(reg.ar<span class="sc">$</span>residuals))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>(i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>  IC_dt<span class="sc">$</span>SIC[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(reg.ar<span class="sc">$</span>residuals))<span class="sc">+</span><span class="fu">log</span>(<span class="fu">nrow</span>(dt))<span class="sc">*</span>(i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>IC_dt</span></code></pre></div>
<pre><code>##    lag      AIC      SIC
## 1:   1 5.192156 5.228184
## 2:   2 5.011351 5.065393
## 3:   3 5.018687 5.090743
## 4:   4 5.024127 5.114198</code></pre>
<p>Generate a sequence of one-step-ahead forecasts from random walk, as well as AR(1), AR(2), and AR(3), using the rolling window scheme, where the first rolling window ranges from period 1 to period 120.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">120</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>rw <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ar1 <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ar2 <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>rw[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>  ar1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>  ar2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar1[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar1<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar1<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar2[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar2<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar2<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>ar2<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Calculate the RMSFE measures for all considered models.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">rw_e=</span>y<span class="sc">-</span>rw,<span class="at">ar1_e=</span>y<span class="sc">-</span>ar1,<span class="at">ar2_e=</span>y<span class="sc">-</span>ar2)]</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>rmsfe_rw <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>rmsfe_ar1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>ar1_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>rmsfe_ar2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>ar2_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>rmsfe_rw</span></code></pre></div>
<pre><code>## [1] 0.9569683</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>rmsfe_ar1</span></code></pre></div>
<pre><code>## [1] 0.9298374</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>rmsfe_ar2</span></code></pre></div>
<pre><code>## [1] 0.8901728</code></pre>
<p>Using the first rolling window as the information set, generate the multi-step-ahead forecast for the hold-out period.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">ar2_multi=</span>y)]</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>ar2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2,<span class="at">data=</span>dt[<span class="dv">1</span><span class="sc">:</span>R])</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar2_multi[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar2<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar2<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>ar2_multi[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>ar2<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>ar2_multi[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-11"><a href="#cb112-11" aria-hidden="true" tabindex="-1"></a>dt[<span class="dv">1</span><span class="sc">:</span>R]<span class="sc">$</span>ar2_multi <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb112-12"><a href="#cb112-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-13"><a href="#cb112-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date))<span class="sc">+</span></span>
<span id="cb112-14"><a href="#cb112-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>y),<span class="at">color=</span><span class="st">&quot;darkgray&quot;</span>,<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb112-15"><a href="#cb112-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>ar2_multi),<span class="at">color=</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">na.rm=</span>T,<span class="at">size=</span><span class="dv">1</span>,<span class="at">linetype=</span><span class="dv">5</span>)<span class="sc">+</span></span>
<span id="cb112-16"><a href="#cb112-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-77-1.png" width="624"  /></p>
<!--chapter:end:15-tutorial05.Rmd-->
</div>
<div id="tutorial-6-vector-autoregressive-models" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 6: Vector Autoregressive Models</h1>
<p>(this is a VAR stuff, will need to move back)</p>
<p>In this tutorial, we will generate bivariate series, we will apply a system-wide information criterion to select a suitable vector autoregressive model, we will perform an in-sample test of Granger causality, we will obtain and compare one-step-ahead forecasts from competing models using a rolling window procedure, and in so doing we will investigate the evidence of Granger causality in an out-of-sample setting. To run the code, the <code>data.table</code> and <code>MASS</code> packages need to be installed and loaded.</p>
<p>Let’s generate a two-dimensional vector of time series that follow a VAR(1) process of the following form: <span class="math display">\[\begin{aligned}
x_{1,t} &amp;= 0.3 + 0.7x_{1,t-1} + 0.1x_{2,t-1} + \varepsilon_{1,t} \\
x_{2,t} &amp;= -0.2 + 0.9x_{1,t-1} + \varepsilon_{2,t}
\end{aligned}\]</span> where <span class="math inline">\(\mathbf{e}_{t} \sim N(\mathbf{0},\Sigma)\)</span>, and where <span class="math inline">\(\Sigma\)</span> is the covariance matrix of the residuals such that <span class="math inline">\(Cov(\varepsilon_{1,t},\varepsilon_{2,t}) = 0.3\)</span> for all <span class="math inline">\(t=1,\ldots,180\)</span>. (Note: in the code, <span class="math inline">\(x_1\)</span> is denoted by <span class="math inline">\(y\)</span> and <span class="math inline">\(x_2\)</span> is denoted by <span class="math inline">\(x\)</span>).</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">0.3</span>,<span class="fl">0.3</span>,<span class="dv">1</span>),<span class="at">nrow=</span><span class="dv">2</span>,<span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(n,<span class="at">mu=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">Sigma=</span>R)</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>e_y <span class="ot">&lt;-</span> e[,<span class="dv">1</span>]</span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>e_x <span class="ot">&lt;-</span> e[,<span class="dv">2</span>]</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> e_y[<span class="dv">1</span>]</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">1</span>] <span class="ot">&lt;-</span> e_x[<span class="dv">1</span>]</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> <span class="fl">0.3+0.7</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">+</span><span class="fl">0.1</span><span class="sc">*</span>x[i<span class="dv">-1</span>]<span class="sc">+</span>e_y[i]</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>  x[i] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.2+0.9</span><span class="sc">*</span>x[i<span class="dv">-1</span>]<span class="sc">+</span>e_x[i]</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of some arbitrary dates (e.g., suppose we deal with the monthly series beginning from January 2006), and store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2006-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y,x)</span></code></pre></div>
<p>Plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>dt_long <span class="ot">&lt;-</span> <span class="fu">melt</span>(dt,<span class="at">id.vars=</span><span class="st">&quot;date&quot;</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt_long,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>value,<span class="at">color=</span>variable,<span class="at">linetype=</span>variable))<span class="sc">+</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;darkgray&quot;</span>,<span class="st">&quot;steelblue&quot;</span>))<span class="sc">+</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-81-1.png" width="624"  /></p>
<p>Estimate VAR(1) and VAR(2) by running regressions on each equation separately. Collect residuals and obtain system-wide AIC for each of the two models.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">y_l1=</span><span class="fu">shift</span>(y,<span class="dv">1</span>),<span class="at">y_l2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">x_l1=</span><span class="fu">shift</span>(x,<span class="dv">1</span>),<span class="at">x_l2=</span><span class="fu">shift</span>(x,<span class="dv">2</span>))]</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="co"># VAR(1)</span></span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>var1y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>x_l1,<span class="at">data=</span>dt)</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>var1x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>y_l1<span class="sc">+</span>x_l1,<span class="at">data=</span>dt)</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>var1r <span class="ot">&lt;-</span> <span class="fu">cbind</span>(var1y<span class="sc">$</span>residuals,var1x<span class="sc">$</span>residuals)</span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>cov1r <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(var1r)<span class="sc">/</span>(<span class="fu">nrow</span>(dt)<span class="sc">-</span>(p<span class="sc">*</span>k<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>k))</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a>AIC1 <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">det</span>(cov1r))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>(p<span class="sc">*</span>k<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>k)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a><span class="co"># VAR(2)</span></span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb116-17"><a href="#cb116-17" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb116-18"><a href="#cb116-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-19"><a href="#cb116-19" aria-hidden="true" tabindex="-1"></a>var2y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2<span class="sc">+</span>x_l1<span class="sc">+</span>x_l2,<span class="at">data=</span>dt)</span>
<span id="cb116-20"><a href="#cb116-20" aria-hidden="true" tabindex="-1"></a>var2x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2<span class="sc">+</span>x_l1<span class="sc">+</span>x_l2,<span class="at">data=</span>dt)</span>
<span id="cb116-21"><a href="#cb116-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-22"><a href="#cb116-22" aria-hidden="true" tabindex="-1"></a>var2r <span class="ot">&lt;-</span> <span class="fu">cbind</span>(var2y<span class="sc">$</span>residuals,var2x<span class="sc">$</span>residuals)</span>
<span id="cb116-23"><a href="#cb116-23" aria-hidden="true" tabindex="-1"></a>cov2r <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(var2r)<span class="sc">/</span>(<span class="fu">nrow</span>(dt)<span class="sc">-</span>(p<span class="sc">*</span>k<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>k))</span>
<span id="cb116-24"><a href="#cb116-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-25"><a href="#cb116-25" aria-hidden="true" tabindex="-1"></a>AIC2 <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">det</span>(cov2r))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>(p<span class="sc">*</span>k<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>k)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb116-26"><a href="#cb116-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-27"><a href="#cb116-27" aria-hidden="true" tabindex="-1"></a>AIC1</span></code></pre></div>
<pre><code>## [1] -0.1270596</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>AIC2</span></code></pre></div>
<pre><code>## [1] -0.047212</code></pre>
<p>Perfrom tests of (in-sample) Granger causality in each of the two models. Note, in the case of VAR(1), both t tests and F tests are applicable and they both provide identical inference. In the case of VAR(p), where <span class="math inline">\(p&gt;1\)</span>, the only appropriate test is an F test for joint significance of the parameters associated with the lags of the potentially causal variable.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># VAR(1)</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="do">## t test</span></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(var1y)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ y_l1 + x_l1, data = dt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.32279 -0.63680 -0.00953  0.68826  2.63468 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.34926    0.11146   3.134  0.00202 ** 
## y_l1         0.68903    0.05877  11.725  &lt; 2e-16 ***
## x_l1         0.11304    0.04509   2.507  0.01308 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.976 on 176 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.5689, Adjusted R-squared:  0.564 
## F-statistic: 116.1 on 2 and 176 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(var1x)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = x ~ y_l1 + x_l1, data = dt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.38491 -0.68087  0.03216  0.66109  2.74762 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.22353    0.10805  -2.069    0.040 *  
## y_l1         0.05814    0.05697   1.021    0.309    
## x_l1         0.85285    0.04371  19.511   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9461 on 176 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.7536, Adjusted R-squared:  0.7508 
## F-statistic: 269.2 on 2 and 176 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="do">## F test</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>ar1y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1,<span class="at">data=</span>dt)</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>ar1x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>x_l1,<span class="at">data=</span>dt)</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(var1y,ar1y)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: y ~ y_l1 + x_l1
## Model 2: y ~ y_l1
##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1    176 167.64                              
## 2    177 173.62 -1   -5.9866 6.2852 0.01308 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(var1x,ar1x)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: x ~ y_l1 + x_l1
## Model 2: x ~ x_l1
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    176 157.54                           
## 2    177 158.47 -1  -0.93231 1.0416 0.3089</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="do">## VAR(2)</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="do">### t test (no longer applicable to test GC)</span></span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(var2y)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ y_l1 + y_l2 + x_l1 + x_l2, data = dt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.38088 -0.71387 -0.01504  0.72538  2.70511 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.32203    0.11775   2.735  0.00689 ** 
## y_l1         0.65954    0.07822   8.431  1.3e-14 ***
## y_l2         0.04964    0.07965   0.623  0.53397    
## x_l1         0.15919    0.08052   1.977  0.04962 *  
## x_l2        -0.05991    0.08104  -0.739  0.46080    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9816 on 173 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.5709, Adjusted R-squared:  0.561 
## F-statistic: 57.55 on 4 and 173 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(var2x)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = x ~ y_l1 + y_l2 + x_l1 + x_l2, data = dt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.37790 -0.64364  0.05401  0.67542  2.71827 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.24577    0.11419  -2.152   0.0328 *  
## y_l1         0.03070    0.07586   0.405   0.6862    
## y_l2         0.04486    0.07724   0.581   0.5621    
## x_l1         0.86196    0.07809  11.039   &lt;2e-16 ***
## x_l2        -0.01627    0.07859  -0.207   0.8362    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9519 on 173 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.7546, Adjusted R-squared:  0.7489 
## F-statistic:   133 on 4 and 173 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="do">### F test</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>ar2y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2,<span class="at">data=</span>dt)</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>ar2x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>x_l1<span class="sc">+</span>x_l2,<span class="at">data=</span>dt)</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(var2y,ar2y)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: y ~ y_l1 + y_l2 + x_l1 + x_l2
## Model 2: y ~ y_l1 + y_l2
##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1    173 166.68                              
## 2    175 172.78 -2   -6.0971 3.1641 0.04471 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(var2x,ar2x)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: x ~ y_l1 + y_l2 + x_l1 + x_l2
## Model 2: x ~ x_l1 + x_l2
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    173 156.76                           
## 2    175 158.03 -2   -1.2729 0.7024 0.4968</code></pre>
<p>Generate a sequence of one-step-ahead forecasts from VAR(1) using the rolling window scheme, where the first rolling window ranges from period 1 to period 120.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">120</span></span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ar1y <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ar1x <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>var1y <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>var1x <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a>  ar1y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb136-12"><a href="#cb136-12" aria-hidden="true" tabindex="-1"></a>  ar1x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>x_l1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb136-13"><a href="#cb136-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb136-14"><a href="#cb136-14" aria-hidden="true" tabindex="-1"></a>  var1y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>x_l1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb136-15"><a href="#cb136-15" aria-hidden="true" tabindex="-1"></a>  var1x <span class="ot">&lt;-</span> <span class="fu">lm</span>(x<span class="sc">~</span>y_l1<span class="sc">+</span>x_l1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb136-16"><a href="#cb136-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb136-17"><a href="#cb136-17" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar1y[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar1y<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar1y<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb136-18"><a href="#cb136-18" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar1x[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar1x<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar1x<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>x[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb136-19"><a href="#cb136-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb136-20"><a href="#cb136-20" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>var1y[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> var1y<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>var1y<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>var1y<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>x[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb136-21"><a href="#cb136-21" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>var1x[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> var1x<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>var1x<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>var1x<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>x[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb136-22"><a href="#cb136-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb136-23"><a href="#cb136-23" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Calculate the RMSFE measures for restricted and unrestricted models, and compare those to each other to make a suggestion about out-of-sample Granger causality.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">ar1y_e=</span>y<span class="sc">-</span>ar1y,<span class="at">ar1x_e=</span>x<span class="sc">-</span>ar1x,<span class="at">var1y_e=</span>y<span class="sc">-</span>var1y,<span class="at">var1x_e=</span>x<span class="sc">-</span>var1x)]</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate RMSFE for restructed and unrestricted models</span></span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true" tabindex="-1"></a>rmsfe_yr <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>ar1y_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb137-5"><a href="#cb137-5" aria-hidden="true" tabindex="-1"></a>rmsfe_yu <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>var1y_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb137-6"><a href="#cb137-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-7"><a href="#cb137-7" aria-hidden="true" tabindex="-1"></a>rmsfe_xr <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>ar1x_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb137-8"><a href="#cb137-8" aria-hidden="true" tabindex="-1"></a>rmsfe_xu <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>var1x_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb137-9"><a href="#cb137-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-10"><a href="#cb137-10" aria-hidden="true" tabindex="-1"></a>rmsfe_yr</span></code></pre></div>
<pre><code>## [1] 1.134867</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>rmsfe_yu</span></code></pre></div>
<pre><code>## [1] 1.104268</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>rmsfe_xr</span></code></pre></div>
<pre><code>## [1] 1.00908</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>rmsfe_xu</span></code></pre></div>
<pre><code>## [1] 1.011653</code></pre>
<!--chapter:end:16-tutorial06.Rmd-->
</div>
<div id="tutorial-7-dynamic-factor-models" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 7: Dynamic Factor Models</h1>
<!--chapter:end:17-tutorial07.Rmd-->
</div>
<div id="tutorial-8-threshold-autoregression" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 8: Threshold Autoregression</h1>
<p>(this is a threshold stuff, will need to move back)</p>
<p>In this tutorial, we will generate regime-dependent series, we will apply a grid-search method to obtain the threshold parameter, we will obtain and compare one-step-ahead forecasts from competing models using a rolling window procedure, and we will apply bootstrap resampling method to generate multi-step-ahead forecasts from a threshold regression. To run the code, the <code>data.table</code> and <code>ggplot2</code> packages need to be installed and loaded.</p>
<p>Let’s generate a time series that follow a TAR(2) process of the following form:
<!-- $$y_t = \left\{\begin{array} -->
<!-- {ll} -->
<!-- y_{t-1} + \varepsilon_t & \text{if}~~y_{t-1}\ge0 \\ -->
<!-- 1.2y_{t-1}-0.3y_{t-2} + \varepsilon_t & \text{if}~~y_{t-1} < 0 -->
<!-- \end{array}\right. -->
<!-- $$ -->
where <span class="math inline">\(e_{t} \sim N(0,\sigma^2)\)</span>. This suggests that the time series follow the unit root process if the lagged dependent variable is non-negative, otherwise the time series is a mean-reverting AR(2) process.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">360</span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6</span>)</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> e[<span class="dv">1</span>]</span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(y[<span class="dv">1</span>]<span class="sc">&gt;=</span><span class="dv">0</span>){</span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a>  y[<span class="dv">2</span>] <span class="ot">&lt;-</span>  <span class="fl">1.0</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a>}<span class="cf">else</span>{</span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a>  y[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">1.2</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb145-13"><a href="#cb145-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-14"><a href="#cb145-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>n){</span>
<span id="cb145-15"><a href="#cb145-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(y[i<span class="dv">-1</span>]<span class="sc">&gt;=</span><span class="dv">0</span>){</span>
<span id="cb145-16"><a href="#cb145-16" aria-hidden="true" tabindex="-1"></a>    y[i] <span class="ot">&lt;-</span>  <span class="fl">1.0</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">+</span>e[i]</span>
<span id="cb145-17"><a href="#cb145-17" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb145-18"><a href="#cb145-18" aria-hidden="true" tabindex="-1"></a>    y[i] <span class="ot">&lt;-</span> <span class="fl">1.2</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">-</span><span class="fl">0.3</span><span class="sc">*</span>y[i<span class="dv">-2</span>]<span class="sc">+</span>e[i]</span>
<span id="cb145-19"><a href="#cb145-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb145-20"><a href="#cb145-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of some arbitrary dates (e.g., suppose we deal with the monthly series beginning from January 1991), and store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;1991-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y)</span></code></pre></div>
<p>Plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-89-1.png" width="624"  /></p>
<p>Decide on the optimal lag length based on AIC.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">y_l1=</span><span class="fu">shift</span>(y),<span class="at">y_l2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">y_l3=</span><span class="fu">shift</span>(y,<span class="dv">3</span>),<span class="at">y_l4=</span><span class="fu">shift</span>(y,<span class="dv">4</span>))]</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> dt[<span class="fu">complete.cases</span>(dt)]</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>IC_dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">lag=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>),<span class="at">AIC=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">SIC=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(IC_dt)){</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a>  fmla <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="fu">paste</span>(<span class="st">&quot;y&quot;</span>,<span class="fu">paste0</span>(<span class="st">&quot;y_l&quot;</span>,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>i),<span class="at">collapse=</span><span class="st">&quot;+&quot;</span>),<span class="at">sep=</span><span class="st">&quot;~&quot;</span>))</span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a>  reg.ar <span class="ot">&lt;-</span> <span class="fu">lm</span>(fmla,<span class="at">data=</span>dt)</span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a>  IC_dt<span class="sc">$</span>AIC[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(reg.ar<span class="sc">$</span>residuals))<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>(i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb148-12"><a href="#cb148-12" aria-hidden="true" tabindex="-1"></a>  IC_dt<span class="sc">$</span>SIC[i] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">crossprod</span>(reg.ar<span class="sc">$</span>residuals))<span class="sc">+</span><span class="fu">log</span>(<span class="fu">nrow</span>(dt))<span class="sc">*</span>(i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="fu">nrow</span>(dt)</span>
<span id="cb148-13"><a href="#cb148-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-14"><a href="#cb148-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb148-15"><a href="#cb148-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-16"><a href="#cb148-16" aria-hidden="true" tabindex="-1"></a>IC_dt</span></code></pre></div>
<pre><code>##    lag      AIC      SIC
## 1:   1 5.822589 5.844358
## 2:   2 5.821342 5.853996
## 3:   3 5.826916 5.870454
## 4:   4 5.832294 5.886717</code></pre>
<p>We now need to get an estimate of the threshold parameter (i.e., the value at which the switch between the regimes happens). For that, we perform a grid-search routine. We will consider a range of candidate thresholds that are within 10th and 90th percentile of the lagged dependent variable. For each candidate threshold, we will run an OLS and calculate the residual sums of squares. A threshold that yields the lowest residual sum of squares will be the estimate.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>qy <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">quantile</span>(dt<span class="sc">$</span>y,<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>)),<span class="dv">1</span>)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="fu">seq</span>(qy[<span class="dv">1</span>],qy[<span class="dv">2</span>],<span class="at">by=</span>.<span class="dv">1</span>)</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a>grid_dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(tr,<span class="at">ssr=</span><span class="cn">NA</span>)</span>
<span id="cb150-6"><a href="#cb150-6" aria-hidden="true" tabindex="-1"></a>grid_dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">ssr=</span><span class="fu">as.numeric</span>(ssr))]</span>
<span id="cb150-7"><a href="#cb150-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-8"><a href="#cb150-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> tr){</span>
<span id="cb150-9"><a href="#cb150-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-10"><a href="#cb150-10" aria-hidden="true" tabindex="-1"></a>  dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">d=</span><span class="fu">ifelse</span>(y_l1<span class="sc">&gt;=</span>i,<span class="dv">1</span>,<span class="dv">0</span>))]</span>
<span id="cb150-11"><a href="#cb150-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-12"><a href="#cb150-12" aria-hidden="true" tabindex="-1"></a>  tar <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(d)<span class="sc">+</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(<span class="dv">1</span><span class="sc">-</span>d),<span class="at">data=</span>dt)</span>
<span id="cb150-13"><a href="#cb150-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-14"><a href="#cb150-14" aria-hidden="true" tabindex="-1"></a>  grid_dt[tr<span class="sc">==</span>i]<span class="sc">$</span>ssr <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(tar<span class="sc">$</span>residuals)</span>
<span id="cb150-15"><a href="#cb150-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-16"><a href="#cb150-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb150-17"><a href="#cb150-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-18"><a href="#cb150-18" aria-hidden="true" tabindex="-1"></a>tr_hat <span class="ot">&lt;-</span> grid_dt[ssr<span class="sc">==</span><span class="fu">min</span>(ssr)]<span class="sc">$</span>tr</span>
<span id="cb150-19"><a href="#cb150-19" aria-hidden="true" tabindex="-1"></a>tr_hat</span></code></pre></div>
<pre><code>## [1] -1</code></pre>
<p>Estimate the threshold autoregression and compare the parameter estimates with the true parameters of the model.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">d=</span><span class="fu">ifelse</span>(y_l1<span class="sc">&gt;=</span>tr_hat,<span class="dv">1</span>,<span class="dv">0</span>))]</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>tar <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(d)<span class="sc">+</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(<span class="dv">1</span><span class="sc">-</span>d),<span class="at">data=</span>dt)</span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tar)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ (y_l1 + y_l2):I(d) + (y_l1 + y_l2):I(1 - d), 
##     data = dt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.97704 -0.60528 -0.02506  0.61754  2.66733 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -0.01380    0.07519  -0.183 0.854535    
## y_l1:I(d)      0.97060    0.06283  15.449  &lt; 2e-16 ***
## y_l2:I(d)      0.00998    0.06160   0.162 0.871403    
## y_l1:I(1 - d)  1.24182    0.10229  12.140  &lt; 2e-16 ***
## y_l2:I(1 - d) -0.34188    0.10158  -3.366 0.000848 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9586 on 351 degrees of freedom
## Multiple R-squared:  0.916,  Adjusted R-squared:  0.9151 
## F-statistic: 957.5 on 4 and 351 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Generate a sequence of one-step-ahead forecasts from TAR(2) using the rolling window scheme, where the first rolling window ranges from period 1 to period 240. For comparison, also generate the one-step-ahead forecasts from the AR(2) and the random walk models. Calculate the RMSFE measures for the three models.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">240</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">rw=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">ar=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">tar=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))]</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>  ar <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y_l1<span class="sc">+</span>y_l2,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>  tar <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(d)<span class="sc">+</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(<span class="dv">1</span><span class="sc">-</span>d),<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="dv">-1</span><span class="sc">+</span>i)])</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>rw[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>ar[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>ar<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>ar<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-16"><a href="#cb154-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">&gt;=</span><span class="dv">0</span>){</span>
<span id="cb154-17"><a href="#cb154-17" aria-hidden="true" tabindex="-1"></a>    dt<span class="sc">$</span>tar[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb154-18"><a href="#cb154-18" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb154-19"><a href="#cb154-19" aria-hidden="true" tabindex="-1"></a>    dt<span class="sc">$</span>tar[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">4</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">5</span>]<span class="sc">*</span>dt<span class="sc">$</span>y[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb154-20"><a href="#cb154-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb154-21"><a href="#cb154-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb154-22"><a href="#cb154-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb154-23"><a href="#cb154-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-24"><a href="#cb154-24" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">rw_e=</span>y<span class="sc">-</span>rw,<span class="at">ar_e=</span>y<span class="sc">-</span>ar,<span class="at">tar_e=</span>y<span class="sc">-</span>tar)]</span>
<span id="cb154-25"><a href="#cb154-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-26"><a href="#cb154-26" aria-hidden="true" tabindex="-1"></a>rmsfe_rw <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb154-27"><a href="#cb154-27" aria-hidden="true" tabindex="-1"></a>rmsfe_ar <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>ar_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb154-28"><a href="#cb154-28" aria-hidden="true" tabindex="-1"></a>rmsfe_tar <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>tar_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span>
<span id="cb154-29"><a href="#cb154-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-30"><a href="#cb154-30" aria-hidden="true" tabindex="-1"></a>rmsfe_rw</span></code></pre></div>
<pre><code>## [1] 0.9258102</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>rmsfe_ar</span></code></pre></div>
<pre><code>## [1] 0.9811523</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>rmsfe_tar</span></code></pre></div>
<pre><code>## [1] 0.9996084</code></pre>
<p>Obtain the multi-step-ahead forecasts from period 241 onward using the so-called ‘skeleton extrapolation’ method (which yields biased forecasts) and the bootstrap resampling method (a numerical method that yields valid multi-step-ahead forecasts from nonlinear models). Plot the two forecasts along with the time series.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">tar_skeleton=</span>y)]</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>tar <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(d)<span class="sc">+</span>(y_l1<span class="sc">+</span>y_l2)<span class="sc">:</span><span class="fu">I</span>(<span class="dv">1</span><span class="sc">-</span>d),<span class="at">data=</span>dt[<span class="dv">1</span><span class="sc">:</span>R])</span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb160-6"><a href="#cb160-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb160-7"><a href="#cb160-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(dt<span class="sc">$</span>tar_skeleton[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">&gt;=</span><span class="dv">0</span>){</span>
<span id="cb160-8"><a href="#cb160-8" aria-hidden="true" tabindex="-1"></a>    dt<span class="sc">$</span>tar_skeleton[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>dt<span class="sc">$</span>tar_skeleton[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>dt<span class="sc">$</span>tar_skeleton[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb160-9"><a href="#cb160-9" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb160-10"><a href="#cb160-10" aria-hidden="true" tabindex="-1"></a>    dt<span class="sc">$</span>tar_skeleton[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">4</span>]<span class="sc">*</span>dt<span class="sc">$</span>tar_skeleton[R<span class="dv">-1</span><span class="sc">+</span>i]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">5</span>]<span class="sc">*</span>dt<span class="sc">$</span>tar_skeleton[R<span class="dv">-2</span><span class="sc">+</span>i]</span>
<span id="cb160-11"><a href="#cb160-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb160-12"><a href="#cb160-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb160-13"><a href="#cb160-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb160-14"><a href="#cb160-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-15"><a href="#cb160-15" aria-hidden="true" tabindex="-1"></a>dt[<span class="dv">1</span><span class="sc">:</span>R]<span class="sc">$</span>tar_skeleton <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb160-16"><a href="#cb160-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-17"><a href="#cb160-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-18"><a href="#cb160-18" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># the number of bootstrap simulations</span></span>
<span id="cb160-19"><a href="#cb160-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-20"><a href="#cb160-20" aria-hidden="true" tabindex="-1"></a>boot_mat <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B,dt<span class="sc">$</span>y)</span>
<span id="cb160-21"><a href="#cb160-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-22"><a href="#cb160-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb160-23"><a href="#cb160-23" aria-hidden="true" tabindex="-1"></a>  eps <span class="ot">&lt;-</span> <span class="fu">sample</span>(tar<span class="sc">$</span>residuals,P,<span class="at">replace=</span>T)</span>
<span id="cb160-24"><a href="#cb160-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb160-25"><a href="#cb160-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb160-26"><a href="#cb160-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb160-27"><a href="#cb160-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(boot_mat[R<span class="dv">-1</span><span class="sc">+</span>i,b]<span class="sc">&gt;=</span><span class="dv">0</span>){</span>
<span id="cb160-28"><a href="#cb160-28" aria-hidden="true" tabindex="-1"></a>      boot_mat[R<span class="sc">+</span>i,b] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>boot_mat[R<span class="dv">-1</span><span class="sc">+</span>i,b]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">3</span>]<span class="sc">*</span>boot_mat[R<span class="dv">-2</span><span class="sc">+</span>i,b]<span class="sc">+</span>eps[i]</span>
<span id="cb160-29"><a href="#cb160-29" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb160-30"><a href="#cb160-30" aria-hidden="true" tabindex="-1"></a>      boot_mat[R<span class="sc">+</span>i,b] <span class="ot">&lt;-</span> tar<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">4</span>]<span class="sc">*</span>boot_mat[R<span class="dv">-1</span><span class="sc">+</span>i,b]<span class="sc">+</span>tar<span class="sc">$</span>coefficients[<span class="dv">5</span>]<span class="sc">*</span>boot_mat[R<span class="dv">-2</span><span class="sc">+</span>i,b]<span class="sc">+</span>eps[i]</span>
<span id="cb160-31"><a href="#cb160-31" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb160-32"><a href="#cb160-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb160-33"><a href="#cb160-33" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb160-34"><a href="#cb160-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb160-35"><a href="#cb160-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb160-36"><a href="#cb160-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-37"><a href="#cb160-37" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>tar_boot <span class="ot">&lt;-</span> <span class="fu">rowMeans</span>(boot_mat)</span>
<span id="cb160-38"><a href="#cb160-38" aria-hidden="true" tabindex="-1"></a>dt[<span class="dv">1</span><span class="sc">:</span>R]<span class="sc">$</span>tar_boot <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb160-39"><a href="#cb160-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-40"><a href="#cb160-40" aria-hidden="true" tabindex="-1"></a>sub_lg <span class="ot">&lt;-</span> <span class="fu">melt</span>(dt[,.(date,y,tar_skeleton,tar_boot)],<span class="at">id.vars=</span><span class="st">&quot;date&quot;</span>)</span>
<span id="cb160-41"><a href="#cb160-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-42"><a href="#cb160-42" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sub_lg,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>value,<span class="at">color=</span>variable,<span class="at">linetype=</span>variable))<span class="sc">+</span></span>
<span id="cb160-43"><a href="#cb160-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>,<span class="at">na.rm=</span>T)<span class="sc">+</span></span>
<span id="cb160-44"><a href="#cb160-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;darkgray&quot;</span>,<span class="st">&quot;indianred&quot;</span>,<span class="st">&quot;steelblue&quot;</span>))<span class="sc">+</span></span>
<span id="cb160-45"><a href="#cb160-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_linetype_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>))<span class="sc">+</span></span>
<span id="cb160-46"><a href="#cb160-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb160-47"><a href="#cb160-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()<span class="sc">+</span></span>
<span id="cb160-48"><a href="#cb160-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;top&quot;</span>,<span class="at">legend.title=</span><span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-94-1.png" width="624"  /></p>
<!--chapter:end:18-tutorial08.Rmd-->
</div>
<div id="tutorial-9-forecast-evaluation" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 9: Forecast Evaluation</h1>
<p>(this is a evaluation stuff, will need to move back)</p>
<p>In this tutorial, we will generate a time series, we will obtain one-step-ahead forecasts from competing models using a rolling window procedure, and we will perform the Diebold-Mariano type regression-based test for equal predictive ability of the competing models. To run the code, the <code>data.table</code>, <code>ggplot2</code>, <code>lmtest</code>, and <code>sandwich</code> packages need to be installed and loaded.</p>
<p>Let’s generate a time series that follow an AR(2) process of the following form:
<span class="math display">\[y_t = 0.2+1.1y_{t-1}-0.3y_{t-2}+\varepsilon_t\]</span>
where <span class="math inline">\(e_{t} \sim N(0,\sigma^2)\)</span>.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">240</span></span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6</span>)</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.2</span><span class="sc">+</span>e[<span class="dv">1</span>]</span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">0.2+1.1</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb161-9"><a href="#cb161-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>n){</span>
<span id="cb161-10"><a href="#cb161-10" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> <span class="fl">0.2+1.1</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">-</span><span class="fl">0.3</span><span class="sc">*</span>y[i<span class="dv">-2</span>]<span class="sc">+</span>e[i]</span>
<span id="cb161-11"><a href="#cb161-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of some arbitrary dates (e.g., suppose we deal with the monthly series beginning from January 2000), store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’, and plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2000-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y)</span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb162-7"><a href="#cb162-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb162-8"><a href="#cb162-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-97-1.png" width="624"  /></p>
<p>Suppose the candidate models are AR(1), AR(2), and AR(3), and that we want to compare forecasts obtained from these models to those from a random walk process. Generate a sequence of one-step-ahead forecasts using the rolling window scheme, where the first rolling window ranges from period 1 to period 180. Calculate the RMSFE measures for the canddidate models.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">y1=</span><span class="fu">shift</span>(y,<span class="dv">1</span>),<span class="at">y2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">y3=</span><span class="fu">shift</span>(y,<span class="dv">3</span>))]</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R</span>
<span id="cb163-5"><a href="#cb163-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-6"><a href="#cb163-6" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">rw=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a1=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a2=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a3=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))]</span>
<span id="cb163-7"><a href="#cb163-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-8"><a href="#cb163-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb163-9"><a href="#cb163-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb163-10"><a href="#cb163-10" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>rw[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> dt<span class="sc">$</span>y[R<span class="sc">+</span>i<span class="dv">-1</span>]</span>
<span id="cb163-11"><a href="#cb163-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb163-12"><a href="#cb163-12" aria-hidden="true" tabindex="-1"></a>  ar1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb163-13"><a href="#cb163-13" aria-hidden="true" tabindex="-1"></a>  ar2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1<span class="sc">+</span>y2,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb163-14"><a href="#cb163-14" aria-hidden="true" tabindex="-1"></a>  ar3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1<span class="sc">+</span>y2<span class="sc">+</span>y3,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb163-15"><a href="#cb163-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb163-16"><a href="#cb163-16" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar1<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>)]))</span>
<span id="cb163-17"><a href="#cb163-17" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a2[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar2<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>,<span class="st">&quot;y2&quot;</span>)]))</span>
<span id="cb163-18"><a href="#cb163-18" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a3[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> ar3<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>,<span class="st">&quot;y2&quot;</span>,<span class="st">&quot;y3&quot;</span>)]))</span>
<span id="cb163-19"><a href="#cb163-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb163-20"><a href="#cb163-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb163-21"><a href="#cb163-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-22"><a href="#cb163-22" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>rw_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>rw</span>
<span id="cb163-23"><a href="#cb163-23" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a1_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a1</span>
<span id="cb163-24"><a href="#cb163-24" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a2_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a2</span>
<span id="cb163-25"><a href="#cb163-25" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a3_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a3</span>
<span id="cb163-26"><a href="#cb163-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-27"><a href="#cb163-27" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSFEs</span></span>
<span id="cb163-28"><a href="#cb163-28" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span></code></pre></div>
<pre><code>## [1] 0.9653331</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>a1_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span></code></pre></div>
<pre><code>## [1] 0.9053279</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>a2_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span></code></pre></div>
<pre><code>## [1] 0.8842908</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(dt<span class="sc">$</span>a3_e<span class="sc">^</span><span class="dv">2</span>,<span class="at">na.rm=</span>T))</span></code></pre></div>
<pre><code>## [1] 0.8877883</code></pre>
<p>Do the autoregressive models generate ‘statistically significantly’ more accurate forecasts than the random walk model? We will answer this question by performing the regression-based Diebold-Mariano tests. First we will generate the loss differentials; then we will run three separate regressions to assess predictive accuracy of AR(1), AR(2), and AR(3) relative to the random walk; and finally we will base our decision on the heteroskedasticity and autocorrelation consistent standard errors.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld1 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a1_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld2 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a2_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld3 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a3_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-5"><a href="#cb171-5" aria-hidden="true" tabindex="-1"></a>reg.ld1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld1<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb171-6"><a href="#cb171-6" aria-hidden="true" tabindex="-1"></a>reg.ld2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld2<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb171-7"><a href="#cb171-7" aria-hidden="true" tabindex="-1"></a>reg.ld3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld3<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb171-8"><a href="#cb171-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-9"><a href="#cb171-9" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ld1,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ld1))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 0.112249   0.047525  2.3619   0.0215 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ld2,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ld2))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 0.149898   0.083086  1.8041  0.07632 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ld3,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ld3))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 0.143700   0.081309  1.7673  0.08235 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<!--chapter:end:19-tutorial09.Rmd-->
</div>
<div id="tutorial-10-forecast-combination" class="section level1 unnumbered">
<h1 class="unnumbered">Tutorial 10: Forecast Combination</h1>
<p>(this is a combination stuff, will need to move back)</p>
<p>In this tutorial, we will generate a time series, we will obtain one-step-ahead forecasts from a set of models using a rolling window procedure, we will combine these forecasts and assess the accuracy of the combined forecast. To run the code, the <code>data.table</code>, <code>ggplot2</code>, <code>lmtest</code>, and <code>sandwich</code> packages need to be installed and loaded.</p>
<p>Let’s generate a time series that follow an AR(2) process with the quadratic trend component as follows:
<span class="math display">\[y_t = 0.03t-0.0001t^2+0.6y_{t-1}+0.2y_{t-2}+\varepsilon_t\]</span>
where <span class="math inline">\(e_{t} \sim N(0,\sigma^2)\)</span>.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">240</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb177-4"><a href="#cb177-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb177-5"><a href="#cb177-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-6"><a href="#cb177-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb177-7"><a href="#cb177-7" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.03</span><span class="sc">*</span><span class="dv">1</span><span class="fl">-0.0001</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span>e[<span class="dv">1</span>]</span>
<span id="cb177-8"><a href="#cb177-8" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fl">0.03</span><span class="sc">*</span><span class="dv">2</span><span class="fl">-0.0001</span><span class="sc">*</span>(<span class="dv">2</span><span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fl">0.6</span><span class="sc">*</span>y[<span class="dv">1</span>]<span class="sc">+</span>e[<span class="dv">2</span>]</span>
<span id="cb177-9"><a href="#cb177-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">3</span><span class="sc">:</span>n){</span>
<span id="cb177-10"><a href="#cb177-10" aria-hidden="true" tabindex="-1"></a>  y[i] <span class="ot">&lt;-</span> <span class="fl">0.03</span><span class="sc">*</span>i<span class="fl">-0.0001</span><span class="sc">*</span>(i<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fl">0.6</span><span class="sc">*</span>y[i<span class="dv">-1</span>]<span class="sc">+</span><span class="fl">0.2</span><span class="sc">*</span>y[i<span class="dv">-2</span>]<span class="sc">+</span>e[i]</span>
<span id="cb177-11"><a href="#cb177-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Generate a vector of some arbitrary dates (e.g., suppose we deal with the monthly series beginning from January 2000), store these along with <span class="math inline">\(y\)</span> in a <strong>data.table</strong>, call it ‘dt’, and plot the realized time series using <strong>ggplot</strong> function.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>date <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">&quot;2000-01-01&quot;</span>),<span class="at">by=</span><span class="st">&quot;month&quot;</span>,<span class="at">along.with=</span>y)</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(date,y)</span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt,<span class="fu">aes</span>(<span class="at">x=</span>date,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Series&quot;</span>)<span class="sc">+</span></span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="forecasting_files/figure-html/unnamed-chunk-102-1.png" width="624"  /></p>
<p>Suppose the candidate models are AR(1), AR(2), and a linear trend model, and that we want to compare forecasts obtained from these models to those from a random walk process. Generate a sequence of one-step-ahead forecasts using the rolling window scheme, where the first rolling window ranges from period 1 to period 180.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">y1=</span><span class="fu">shift</span>(y,<span class="dv">1</span>),<span class="at">y2=</span><span class="fu">shift</span>(y,<span class="dv">2</span>),<span class="at">y3=</span><span class="fu">shift</span>(y,<span class="dv">3</span>),<span class="at">trend=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(dt)))]</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">180</span></span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dt)<span class="sc">-</span>R</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>dt[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(<span class="at">rw=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a1=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">a2=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>),<span class="at">tr=</span><span class="fu">as.numeric</span>(<span class="cn">NA</span>))]</span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>P){</span>
<span id="cb179-9"><a href="#cb179-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb179-10"><a href="#cb179-10" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>rw[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> dt<span class="sc">$</span>y[R<span class="sc">+</span>i<span class="dv">-1</span>]</span>
<span id="cb179-11"><a href="#cb179-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb179-12"><a href="#cb179-12" aria-hidden="true" tabindex="-1"></a>  a1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb179-13"><a href="#cb179-13" aria-hidden="true" tabindex="-1"></a>  a2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1<span class="sc">+</span>y2,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb179-14"><a href="#cb179-14" aria-hidden="true" tabindex="-1"></a>  tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>y1<span class="sc">+</span>y2<span class="sc">+</span>trend,<span class="at">data=</span>dt[i<span class="sc">:</span>(R<span class="sc">+</span>i<span class="dv">-1</span>)])</span>
<span id="cb179-15"><a href="#cb179-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb179-16"><a href="#cb179-16" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a1[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> a1<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>)]))</span>
<span id="cb179-17"><a href="#cb179-17" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>a2[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> a2<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>,<span class="st">&quot;y2&quot;</span>)]))</span>
<span id="cb179-18"><a href="#cb179-18" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">$</span>tr[R<span class="sc">+</span>i] <span class="ot">&lt;-</span> tr<span class="sc">$</span>coefficients<span class="sc">%*%</span><span class="fu">as.numeric</span>(<span class="fu">c</span>(<span class="dv">1</span>,dt[R<span class="sc">+</span>i,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>,<span class="st">&quot;y2&quot;</span>,<span class="st">&quot;trend&quot;</span>)]))</span>
<span id="cb179-19"><a href="#cb179-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb179-20"><a href="#cb179-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Does either of the considered models ‘sttaistically significantly’ outperform the random walk?</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>rw_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>rw</span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a1_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a1</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>a2_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>a2</span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>tr_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>tr</span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld1 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a1_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ld2 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>a2_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ldt <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>tr_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>reg.ld1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld1<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb180-11"><a href="#cb180-11" aria-hidden="true" tabindex="-1"></a>reg.ld2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ld2<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb180-12"><a href="#cb180-12" aria-hidden="true" tabindex="-1"></a>reg.ldt <span class="ot">&lt;-</span> <span class="fu">lm</span>(ldt<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb180-13"><a href="#cb180-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-14"><a href="#cb180-14" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ld1,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ld1))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 0.081204   0.048040  1.6903  0.09624 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ld2,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ld2))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  0.32634    0.14912  2.1883  0.03262 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ldt,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ldt))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.24461    0.14943  1.6369    0.107</code></pre>
<p>All of the models do, on average, generate more accurate forecasts than random walk. The AR(2) generates statistically significantly more accurate forecasts, based on Diebold-Mariano test applied on quadratic loss function.</p>
<p>Might each model contain some useful information for improving forecast accuracy? Let’s combine the forecasts from the AR(1) and the linear trend model using equal weights scheme and assess the combined forecast.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>t1 <span class="ot">&lt;-</span> dt<span class="sc">$</span>a1<span class="sc">*</span>.<span class="dv">5</span><span class="sc">+</span>dt<span class="sc">$</span>tr<span class="sc">*</span>.<span class="dv">5</span></span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>t1_e <span class="ot">&lt;-</span> dt<span class="sc">$</span>y<span class="sc">-</span>dt<span class="sc">$</span>t1</span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>dt<span class="sc">$</span>ldt1 <span class="ot">&lt;-</span> dt<span class="sc">$</span>rw_e<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>dt<span class="sc">$</span>t1_e<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a>reg.ldt1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(ldt1<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>dt)</span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(reg.ldt1,<span class="at">vcov.=</span><span class="fu">vcovHAC</span>(reg.ldt1))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 0.232926   0.098544  2.3637  0.02141 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<!--chapter:end:20-tutorial10.Rmd-->
</div>
<!--bookdown:body:end-->



</body>
</html>
