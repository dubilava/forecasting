<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.3 Forecasting | Educated Guess" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/forecasting-logo.png" />
<meta property="og:description" content="Forecasting With Time Series Models Using R" />


<meta name="author" content="David Ubilava" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Forecasting With Time Series Models Using R">

<title>7.3 Forecasting | Educated Guess</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<!--bookdown:toc:end-->
<!--bookdown:toc:start-->
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="forecasting-3" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Forecasting</h2>
<p>Generating forecasts for each of the variable comprising the VAR(p) model can be a straightforward exercise, so long as we have access to the relevant information set. As was the case with autoregressive models, we make one-step-ahead forecasts based on the readily available data; and we make multi-step-ahead forecasts iteratively, using the forecast in periods for which the data are not present.</p>
<div id="one-step-ahead-forecasts" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> One-step-ahead forecasts</h3>
<p>In a VAR(p), the realization of a dependent variable <span class="math inline">\(i\)</span> in period <span class="math inline">\(t+1\)</span> is:
<span class="math display">\[x_{it+1} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j} + \varepsilon_{t+1},\;~~i=1,\ldots,n.\]</span></p>
<p>Point forecast, ignoring parameter uncertainty, is:
<span class="math display">\[x_{it+1|t} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j},\;~~i=1,\ldots,n.\]</span></p>
<p>Forecast error is: <span class="math display">\[e_{it+1} = x_{it+1}-x_{it+1|t}=\varepsilon_{it+1},\;~~i=1,\ldots,n.\]</span></p>
<p>Forecast variance is: <span class="math display">\[\sigma_{it+1}^2 = E(\varepsilon_{it+1}^2) = \sigma_{i}^2,\;~~i=1,\ldots,n,\]</span> where <span class="math inline">\(\sigma_{i}^2\)</span> is the i<span class="math inline">\(^{th}\)</span> element of the main diagonal of the error variance-covariance matrix of the VAR(p).</p>
<p>The (95%) interval forecast is:
<span class="math display">\[x_{it+1|t}\pm1.96\sigma_{i}^2,\;~~i=1,\ldots,n.\]</span></p>
</div>
<div id="multi-step-ahead-forecasts" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Multi-step-ahead forecasts</h3>
<p>The realization of a dependent variables <span class="math inline">\(i\)</span> in period <span class="math inline">\(t+h\)</span> is:
<span class="math display">\[x_{it+h} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+h-j} + \varepsilon_{t+h},\;~~i=1,\ldots,n.\]</span></p>
<p>Point forecast is:
<span class="math display">\[\mathbf{x}_{t+h|t} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+h-j|t},\;~~i=1,\ldots,n.\]</span> where the iterative method is applied to generate forecasts, and where <span class="math inline">\(x_{kt+h-j|t}=x_{t+h-j}\)</span> if <span class="math inline">\(j\ge h\)</span>.</p>
<p>Forecast error is:
<span class="math display">\[e_{it+h} = x_{it+h}-x_{t+h|t}=\sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} e_{kt+h-j} + \varepsilon_{t+h},\;~~i=1,\ldots,n.\]</span> Note that the forecast error reduces to <span class="math inline">\(\varepsilon_{t+h}\)</span>, when <span class="math inline">\(h=1\)</span>, which is what we saw above. More intriguingly, observe that the multi-step-ahead forecast error of a given variable is the function of preceding forecast errors of all variables in the system, each multiplied by some parameter of the model.</p>
<p>Forecast variance, <span class="math inline">\(\sigma_{it+h}^2\)</span>, is the function of error variances and covariances, and the model parameters.</p>
<p>The (95%) interval forecast is:
<span class="math display">\[x_{it+h|t}\pm1.96\sigma_{it+h},\;~~i=1,\ldots,n.\]</span></p>
</div>
<div id="out-of-sample-granger-causality" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Out-of-Sample Granger Causality</h3>
<p>The previously discussed (in sample) test of causality in Granger sense is frequently performed in practice. But as noted above, the term ‘causality’ may be misleading somewhat. Indeed, the ‘true spirit’ of such test is to assess the ability of a variable to help predict another variable in an out-of-sample setting.</p>
<p>Consider a set of variables, <span class="math inline">\(\{X_1\},\ldots,\{X_n\}\)</span>. Suppose there are two information sets, the unrestricted information set, <span class="math inline">\(\Omega_{t}^{(u)}\)</span>, and the restricted information set, <span class="math inline">\(\Omega_{t}^{(r)}\)</span>. The former consists of the current and lagged values of all the variables in the set. The latter consists of the current and lagged values of all but one variables in the set. Suppose the omitted variable is <span class="math inline">\(\{X_1\}\)</span>.
Then, following Granger’s definition of causality: <span class="math inline">\(\{X_1\}\)</span> is said to cause <span class="math inline">\(\{X_{i\ne 1}\}\)</span> if <span class="math inline">\(\sigma_{i}^2\left(\Omega_{t}^{(u)}\right) &lt; \sigma_{i}^2\left(\Omega_{t}^{(r)}\right)\)</span>, meaning that we can better predict <span class="math inline">\(X_i\)</span> using the available information on <span class="math inline">\(\{X_1\}\)</span> through <span class="math inline">\(\{X_n\]\)</span>, rather than that on <span class="math inline">\(\{X_2\}\)</span> through <span class="math inline">\(\{X_n\}\)</span> only.</p>
<p>In practice, the test involves generating two sets of (one-step-ahead) out-of-sample forecasts from the unrestricted and restricted equations of the vector autoregression. The former is simply the forecast as presented above, that is: <span class="math display">\[x_{it+1|t}^{(u)} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j},\;~~i=2,\ldots,n.\]</span> The latter is the forecast that doesn’t rely on information from the omitted variable (in our example, the first variable in the unrestricted system of equations): <span class="math display">\[x_{it+1|t}^{(r)} = \tilde{\alpha}_i + \sum_{j=1}^{p}\sum_{k=2}^{n}\tilde{\pi}_{ik}^{(j)} x_{kt+1-j},\;~~i=2,\ldots,n.\]</span></p>
<p>For these forecasts, the corresponding forecast errors are:
<span class="math display">\[\begin{aligned}
    &amp; e_{it+1}^{(u)} = x_{1t+1} - x_{1t+1|t}^{(u)}\\
    &amp; e_{it+1}^{(r)} = x_{1t+1} - x_{1t+1|t}^{(r)}
\end{aligned}\]</span></p>
<p>The out-of-sample forecast errors are then evaluated by comparing the loss functions based on these forecasts errors. For example, assuming quadratic loss, and <span class="math inline">\(P\)</span> out-of-sample forecasts:
<span class="math display">\[\begin{aligned}
RMSFE^{(u)} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{iR+s|R-1+s}^{(u)}\right)^2} \\
RMSFE^{(r)} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{iR+s|R-1+s}^{(r)}\right)^2}
\end{aligned}\]</span>
where <span class="math inline">\(R\)</span> is the size of the (first) estimation window.</p>
<p><span class="math inline">\(\{X_1\}\)</span> is said to cause <em>in Granger sense</em> <span class="math inline">\(\{X_{i\ne 1}\}\)</span> if <span class="math inline">\(RMSFE^{(u)} &lt; RMSFE^{(r)}\)</span>.</p>

</div>
</div>
<!-- </div> -->
<p style="text-align: center;">
<a href="7.2-modeling-3.html"><button class="btn btn-default">Previous</button></a>
<a href="8-threshold-autoregression.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
