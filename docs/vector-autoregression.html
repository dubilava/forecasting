<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 7 – Vector Autoregression | Educated Guess" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/forecasting-logo.png" />
<meta property="og:description" content="Forecasting With Time Series Models Using R" />


<meta name="author" content="David Ubilava" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Forecasting With Time Series Models Using R">

<title>Chapter 7 – Vector Autoregression | Educated Guess</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script>
function copy_link(id) {
  var dummy = document.createElement('input'),
  text = window.location.href.split(/[?#]/)[0] + '#' + id;
  document.body.appendChild(dummy);
  dummy.value = text;
  dummy.select();
  document.execCommand('copy');
  document.body.removeChild(dummy);
  
  var tooltip = document.getElementById(id + '-tooltip');
  tooltip.innerHTML = 'Copied!';
}

function reset_tooltip(id) {
  var tooltip = document.getElementById(id);
  tooltip.innerHTML = 'Copy link';
}
</script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>
  $(document).ready(function () {
    var element_label= $("label[for *= 'tufte-sn-']");
    var count = $(element_label).length;
    $(element_label).each(function( index ) {
      //console.log( ++index + ": " + $( this ).text() );
      $(this).attr('for','tufte-sn-'+ ++index);
      $(this).text(index);
    });
  });
  $(document).ready(function () {
    var element_input= $("input[id *= 'tufte-sn-']");
    var count = $(element_input).length;
    $(element_input).each(function( index ) {
      //console.log( ++index + ": " + $( this ).text() );
      $(this).attr('id','tufte-sn-'+ ++index);
    }); 
  });
  $(document).ready(function () {
    var element_span= $("span[class *= 'sidenote-number']");
    var count = $(element_span).length;
    $(element_span).each(function( index ) {
      //console.log( ++index + ": " + $( this ).text() );
      $(this).text(++index);
    }); 
  });
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Educated Guess<p><p class="author">David Ubilava</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html" id="toc-an-intuitive-guide-to-forecasting-with-time-series-models-using-r">An Intuitive Guide to Forecasting With Time Series Models Using R</a>
<a href="forecasting-with-time-series-models.html" id="toc-forecasting-with-time-series-models">Forecasting With Time Series Models</a>
<a href="introduction-to-forecasting.html" id="toc-introduction-to-forecasting"><span class="toc-section-number">1</span> – Introduction to Forecasting</a>
<a href="features-of-time-series-data.html" id="toc-features-of-time-series-data"><span class="toc-section-number">2</span> – Features of Time Series Data</a>
<a href="generating-and-evaluating-forecasts.html" id="toc-generating-and-evaluating-forecasts"><span class="toc-section-number">3</span> – Generating and Evaluating Forecasts</a>
<a href="trends.html" id="toc-trends"><span class="toc-section-number">4</span> – Trends</a>
<a href="seasonality.html" id="toc-seasonality"><span class="toc-section-number">5</span> – Seasonality</a>
<a href="autoregression.html" id="toc-autoregression"><span class="toc-section-number">6</span> – Autoregression</a>
<a id="active-page" href="vector-autoregression.html" id="toc-vector-autoregression"><span class="toc-section-number">7</span> – Vector Autoregression</a><ul class="toc-sections">
<li class="toc"><a href="#dynamic-feedbacks-among-economic-variables"> Dynamic Feedbacks Among Economic Variables</a></li>
<li class="toc"><a href="#modeling-3"> Modeling</a></li>
<li class="toc"><a href="#forecasting-3"> Forecasting</a></li>
</ul>
<a href="threshold-autoregression.html" id="toc-threshold-autoregression"><span class="toc-section-number">8</span> – Threshold Autoregression</a>
<a href="comparing-forecasts.html" id="toc-comparing-forecasts"><span class="toc-section-number">9</span> – Comparing Forecasts</a>
<a href="combining-forecasts.html" id="toc-combining-forecasts"><span class="toc-section-number">10</span> – Combining Forecasts</a>
<a href="forecasting-using-r.html" id="toc-forecasting-using-r">Forecasting Using R</a>
<a href="tutorial-1-introduction-to-r.html" id="toc-tutorial-1-introduction-to-r">Tutorial 1: Introduction to R</a>
<a href="tutorial-2-data-management-and-visualisation.html" id="toc-tutorial-2-data-management-and-visualisation">Tutorial 2: Data Management and Visualisation</a>
<a href="tutorial-3-forecasting-methods-and-routines.html" id="toc-tutorial-3-forecasting-methods-and-routines">Tutorial 3: Forecasting Methods and Routines</a>
<a href="tutorial-4-trends.html" id="toc-tutorial-4-trends">Tutorial 4: Trends</a>
<a href="tutorial-5-seasonality.html" id="toc-tutorial-5-seasonality">Tutorial 5: Seasonality</a>
<a href="tutorial-6-autoregression.html" id="toc-tutorial-6-autoregression">Tutorial 6: Autoregression</a>
<a href="tutorial-7-vector-autoregression.html" id="toc-tutorial-7-vector-autoregression">Tutorial 7: Vector Autoregression</a>
<a href="tutorial-8-threshold-autoregression.html" id="toc-tutorial-8-threshold-autoregression">Tutorial 8: Threshold Autoregression</a>
<a href="tutorial-9-comparing-forecasts.html" id="toc-tutorial-9-comparing-forecasts">Tutorial 9: Comparing Forecasts</a>
<a href="tutorial-10-combining-forecasts.html" id="toc-tutorial-10-combining-forecasts">Tutorial 10: Combining Forecasts</a>
<a href="references.html" id="toc-references">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="vector-autoregression" class="section level1" number="7">
<h1>
<span class="header-section-number">Chapter 7</span> – Vector Autoregression</h1>
<p><img src="art/multivariate.png"></p>
<div id="dynamic-feedbacks-among-economic-variables" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Dynamic Feedbacks Among Economic Variables<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('dynamic-feedbacks-among-economic-variables')" onmouseout="reset_tooltip('dynamic-feedbacks-among-economic-variables-tooltip')"><span class="tooltiptext" id="dynamic-feedbacks-among-economic-variables-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h2>
<p><span class="newthought">Economic variables</span> are interrelated. For example, changes to household income impact their consumption levels; changes to interest rates impact investments in the economy. Often (albeit not always) the relationship between the variables goes in both directions. For example, growth in income results in higher prices (inflation), which in turn puts an upward pressure on wages.<label for="tufte-sn-15" class="margin-toggle sidenote-number">15</label><input type="checkbox" id="tufte-sn-15" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">15</span> The sequence of events in Australia, following the Covid-19 pandemic, is a notable case in point. Fearing economic crisis, the Australian government issued a suite of stimulus packages. A resulting increase in demand became one of the contributing factors to the subsequent price inflation. At that point, the Reserve Bank of Australia was left with no option but to hike interest rates to slow down the economy and, thus, release the inflationary pressure.</span></p>
<p>The foregoing implies that a shock to a variable may propagate a dynamic response not only of that variable, but also of related variables. The dynamic linkages between two (or more) economic variables can be modeled as a <em>system of equations</em>, represented by a vector autoregression (VAR).</p>
<p>There are three general forms of vector autoregressions: <em>structural</em>, <em>recursive</em>, and <em>reduced-form</em>. The structural VAR uses economic theory to impose the ‘structure’ on correlations of the error terms in the system. The recursive VAR also introduces a structure of some sort, which primarily involves ordering the equations in the system in a specific way so that the error terms in each equation are uncorrelated with those in the preceding equations. To the extent that the ‘identifying assumptions’ are satisfied, some contemporaneous values (of other variables) appear in the equation of a given variable.</p>
<p>The reduced-form VAR makes no claims of causality, at least not in the sense that this term is usually understood. The equations include only the lagged values of all the variables in the system. To the extent that these variables are, indeed, correlated with each other, the error terms of the reduced-form VAR (typically) are contemporaneously correlated. In what follows, VAR will refer to the reduced-form VAR, unless otherwise stated.</p>
</div>
<div id="modeling-3" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Modeling<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('modeling-3')" onmouseout="reset_tooltip('modeling-3-tooltip')"><span class="tooltiptext" id="modeling-3-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h2>
<p>The simplest form of the VAR is a bivariate (two-dimensional) VAR of order one, VAR(1).</p>
<p>Let <span class="math inline">\(\{X_{1,t}\}\)</span> and <span class="math inline">\(\{X_{2,t}\}\)</span> be the stationary stochastic processes. A bivariate VAR(1), is then given by:
<span class="math display">\[\begin{aligned}
x_{1t} &amp;= \alpha_1 + \pi_{11}x_{1t-1} + \pi_{12}x_{2t-1} + \varepsilon_{1t} \\
x_{2t} &amp;= \alpha_2 + \pi_{21}x_{1t-1} + \pi_{22}x_{2t-1} + \varepsilon_{2t}
\end{aligned}\]</span></p>
<p>where <span class="math inline">\(\varepsilon_{1,t} \sim iid(0,\sigma_1^2)\)</span> and <span class="math inline">\(\varepsilon_{2,t} \sim iid(0,\sigma_2^2)\)</span>, and the two can be correlated, i.e., <span class="math inline">\(Cov(\varepsilon_{1,t},\varepsilon_{2,t}) \neq 0\)</span>.</p>
<p>To generalize, consider a multivariate (<span class="math inline">\(n\)</span>-dimensional) VAR of order <span class="math inline">\(p\)</span>, VAR(p), presented in matrix notation: <span class="math display">\[\mathbf{x}_t = \mathbf{\alpha} + \Pi^{(1)} \mathbf{x}_{t-1} + \ldots + \Pi^{(p)} \mathbf{x}_{t-p} + \mathbf{\varepsilon}_t,\]</span> where <span class="math inline">\(\mathbf{x}_t = (x_{1t},\ldots,x_{nt})'\)</span> is a vector of <span class="math inline">\(n\)</span> (potentially) related variables; <span class="math inline">\(\mathbf{\varepsilon}_t = (\varepsilon_{1t},\ldots,\varepsilon_{nt})'\)</span> is a vector of error terms, such that <span class="math inline">\(E(\mathbf{\varepsilon}_t) = \mathbf{0}\)</span>, <span class="math inline">\(E(\mathbf{\varepsilon}_t^{}\mathbf{\varepsilon}_t^{\prime}) = \Sigma_{\mathbf{\varepsilon}}\)</span>, and <span class="math inline">\(E(\mathbf{\varepsilon}_{t}^{}\mathbf{\varepsilon}_{s \neq t}^{\prime}) = 0\)</span>. <span class="math inline">\(\Pi^{(1)},\ldots,\Pi^{(p)}\)</span> are <span class="math inline">\(n\)</span>-dimensional parameter matrices:
<span class="math display">\[\Pi^{(j)} =
        \left[
        \begin{array}{cccc}
        \pi_{11}^{(j)} &amp; \pi_{12}^{(j)} &amp; \cdots &amp;  \pi_{1n}^{(j)} \\
        \pi_{21}^{(j)} &amp; \pi_{22}^{(j)} &amp; \cdots &amp;  \pi_{2n}^{(j)} \\  
        \vdots &amp; \vdots &amp; \ddots &amp;  \vdots \\  
        \pi_{n1}^{(j)} &amp; \pi_{n2}^{(j)} &amp; \cdots &amp;  \pi_{nn}^{(j)}  
        \end{array}
        \right],\;~~j=1,\ldots,p\]</span></p>
<p>When two or more variables are modeled in this way, the implies assumption is that these variables are endogenous to each other; that is, each of the variables affects and is affected by other variables.</p>
<p>Some of the features of the VAR are that:</p>
<ul>
<li>only lagged values of the dependent variables are considered as the right-hand-side variables (although, trend and seasonal variables might also be included in higher-frequency data analysis);</li>
<li>each equation has the same set of right-hand-side variables (however, it is possible to impose a different lag structure across the equations, especially when <span class="math inline">\(p\)</span> is relatively large, to preserve the degrees of freedom, particularly when the sample size is relatively small and when there are several variables in the system).</li>
<li>The autregressive order of the VAR, <span class="math inline">\(p\)</span>, is determined by the maximum lag of a variable across all equations.</li>
</ul>
<p>The order of a VAR, <span class="math inline">\(p\)</span>, can be determined using system-wide information criteria:</p>
<p><span class="math display">\[\begin{aligned}
&amp; AIC = \ln\left|\Sigma_{\varepsilon}\right| + \frac{2}{T}(pn^2+n) \\
&amp; SIC = \ln\left|\Sigma_{\varepsilon}\right| + \frac{\ln{T}}{T}(pn^2+n)
\end{aligned}\]</span></p>
<p>where <span class="math inline">\(\left|\Sigma_{\varepsilon}\right|\)</span> is the determinant of the residual covariance matrix; <span class="math inline">\(n\)</span> is the number of equations, and <span class="math inline">\(T\)</span> is the effective sample size.</p>
<p>We can estimate each equation of the VAR individually using OLS.</p>
<div id="in-sample-granger-causality" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> In-Sample Granger Causality<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('in-sample-granger-causality')" onmouseout="reset_tooltip('in-sample-granger-causality-tooltip')"><span class="tooltiptext" id="in-sample-granger-causality-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h3>
<p>A test of joint significance of parameters associated with all the lags of a variable entering the equation of another variable is known as the ‘Granger causality’ test. The use of the term ‘causality’ in this context has been criticized. That one variable can help explain the movement of another variable does not necessarily mean that the former causes the latter. To that end the use of the term can be seen as misleading, indeed. Rather, causality in Granger sense simply means that the former helps predict the latter.</p>
<p>To illustrate the testing framework, consider a bivariate VAR(p):
<span class="math display">\[\begin{aligned}
x_{1t} &amp;= \alpha_1 + \pi_{11}^{(1)} x_{1t-1} + \cdots + \pi_{11}^{(p)} x_{1t-p} \\
&amp;+ \pi_{12}^{(1)} x_{2t-1} + \cdots + \pi_{12}^{(p)} x_{2,t-p} +\varepsilon_{1t}  \\
x_{2t} &amp;= \alpha_1 + \pi_{21}^{(1)} x_{1t-1} + \cdots + \pi_{21}^{(p)} x_{1t-p} \\
&amp;+ \pi_{22}^{(1)} x_{2t-1} + \cdots + \pi_{22}^{(p)} x_{2t-p} +\varepsilon_{2t}
\end{aligned}\]</span></p>
<p>We say that:</p>
<ul>
<li>
<span class="math inline">\(\{X_2\}\)</span> does not Granger cause <span class="math inline">\(\{X_1\}\)</span> if <span class="math inline">\(\pi_{121}=\cdots=\pi_{12p}=0\)</span>
</li>
<li>
<span class="math inline">\(\{X_1\}\)</span> does not Granger cause <span class="math inline">\(\{X_2\}\)</span> if <span class="math inline">\(\pi_{211}=\cdots=\pi_{21p}=0\)</span>
</li>
</ul>
<p>So long as the variables of the system are covariance-stationarity, we can test the hypothesis using a F test. If <span class="math inline">\(p=1\)</span>, we can also equivalently test the hypothesis using a t test.</p>
</div>
</div>
<div id="forecasting-3" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Forecasting<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('forecasting-3')" onmouseout="reset_tooltip('forecasting-3-tooltip')"><span class="tooltiptext" id="forecasting-3-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h2>
<p>Generating forecasts for each of the variable comprising the VAR(p) model can be a straightforward exercise, so long as we have access to the relevant information set. As was the case with autoregressive models, we make one-step-ahead forecasts based on the readily available data; and we make multi-step-ahead forecasts iteratively, using the forecast in periods for which the data are not present.</p>
<div id="one-step-ahead-forecasts" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> One-step-ahead forecasts<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('one-step-ahead-forecasts')" onmouseout="reset_tooltip('one-step-ahead-forecasts-tooltip')"><span class="tooltiptext" id="one-step-ahead-forecasts-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h3>
<p>In a VAR(p), the realization of a dependent variable <span class="math inline">\(i\)</span> in period <span class="math inline">\(t+1\)</span> is:
<span class="math display">\[x_{it+1} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j} + \varepsilon_{t+1},\;~~i=1,\ldots,n.\]</span></p>
<p>Point forecast, ignoring parameter uncertainty, is:
<span class="math display">\[x_{it+1|t} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j},\;~~i=1,\ldots,n.\]</span></p>
<p>Forecast error is: <span class="math display">\[e_{it+1} = x_{it+1}-x_{it+1|t}=\varepsilon_{it+1},\;~~i=1,\ldots,n.\]</span></p>
<p>Forecast variance is: <span class="math display">\[\sigma_{it+1}^2 = E(\varepsilon_{it+1}^2) = \sigma_{i}^2,\;~~i=1,\ldots,n,\]</span> where <span class="math inline">\(\sigma_{i}^2\)</span> is the i<span class="math inline">\(^{th}\)</span> element of the main diagonal of the error variance-covariance matrix of the VAR(p).</p>
<p>The (95%) interval forecast is:
<span class="math display">\[x_{it+1|t}\pm1.96\sigma_{i}^2,\;~~i=1,\ldots,n.\]</span></p>
</div>
<div id="multi-step-ahead-forecasts" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> Multi-step-ahead forecasts<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('multi-step-ahead-forecasts')" onmouseout="reset_tooltip('multi-step-ahead-forecasts-tooltip')"><span class="tooltiptext" id="multi-step-ahead-forecasts-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h3>
<p>The realization of a dependent variables <span class="math inline">\(i\)</span> in period <span class="math inline">\(t+h\)</span> is:
<span class="math display">\[x_{it+h} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+h-j} + \varepsilon_{t+h},\;~~i=1,\ldots,n.\]</span></p>
<p>Point forecast is:
<span class="math display">\[\mathbf{x}_{t+h|t} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+h-j|t},\;~~i=1,\ldots,n.\]</span> where the iterative method is applied to generate forecasts, and where <span class="math inline">\(x_{kt+h-j|t}=x_{t+h-j}\)</span> if <span class="math inline">\(j\ge h\)</span>.</p>
<p>Forecast error is:
<span class="math display">\[e_{it+h} = x_{it+h}-x_{t+h|t}=\sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} e_{kt+h-j} + \varepsilon_{t+h},\;~~i=1,\ldots,n.\]</span> Note that the forecast error reduces to <span class="math inline">\(\varepsilon_{t+h}\)</span>, when <span class="math inline">\(h=1\)</span>, which is what we saw above. More intriguingly, observe that the multi-step-ahead forecast error of a given variable is the function of preceding forecast errors of all variables in the system, each multiplied by some parameter of the model.</p>
<p>Forecast variance, <span class="math inline">\(\sigma_{it+h}^2\)</span>, is the function of error variances and covariances, and the model parameters.</p>
<p>The (95%) interval forecast is:
<span class="math display">\[x_{it+h|t}\pm1.96\sigma_{it+h},\;~~i=1,\ldots,n.\]</span></p>
</div>
<div id="out-of-sample-granger-causality" class="section level3" number="7.3.3">
<h3>
<span class="header-section-number">7.3.3</span> Out-of-Sample Granger Causality<div class="tooltip"><button class="internal-link-btn" onclick="copy_link('out-of-sample-granger-causality')" onmouseout="reset_tooltip('out-of-sample-granger-causality-tooltip')"><span class="tooltiptext" id="out-of-sample-granger-causality-tooltip">Copy link</span><i class="fa fa-link"></i></button></div>
</h3>
<p>The previously discussed (in sample) test of causality in Granger sense is frequently performed in practice. But as noted above, the term ‘causality’ may be misleading somewhat. Indeed, the ‘true spirit’ of such test is to assess the ability of a variable to help predict another variable in an out-of-sample setting.</p>
<p>Consider a set of variables, <span class="math inline">\(\{X_1\},\ldots,\{X_n\}\)</span>. Suppose there are two information sets, the unrestricted information set, <span class="math inline">\(\Omega_{t}^{(u)}\)</span>, and the restricted information set, <span class="math inline">\(\Omega_{t}^{(r)}\)</span>. The former consists of the current and lagged values of all the variables in the set. The latter consists of the current and lagged values of all but one variables in the set. Suppose the omitted variable is <span class="math inline">\(\{X_1\}\)</span>.
Then, following Granger’s definition of causality: <span class="math inline">\(\{X_1\}\)</span> is said to cause <span class="math inline">\(\{X_{i\ne 1}\}\)</span> if <span class="math inline">\(\sigma_{i}^2\left(\Omega_{t}^{(u)}\right) &lt; \sigma_{i}^2\left(\Omega_{t}^{(r)}\right)\)</span>, meaning that we can better predict <span class="math inline">\(X_i\)</span> using the available information on <span class="math inline">\(\{X_1\}\)</span> through <span class="math inline">\(\{X_n\]\)</span>, rather than that on <span class="math inline">\(\{X_2\}\)</span> through <span class="math inline">\(\{X_n\}\)</span> only.</p>
<p>In practice, the test involves generating two sets of (one-step-ahead) out-of-sample forecasts from the unrestricted and restricted equations of the vector autoregression. The former is simply the forecast as presented above, that is: <span class="math display">\[x_{it+1|t}^{(u)} = \alpha_i + \sum_{j=1}^{p}\sum_{k=1}^{n}\pi_{ik}^{(j)} x_{kt+1-j},\;~~i=2,\ldots,n.\]</span> The latter is the forecast that doesn’t rely on information from the omitted variable (in our example, the first variable in the unrestricted system of equations): <span class="math display">\[x_{it+1|t}^{(r)} = \tilde{\alpha}_i + \sum_{j=1}^{p}\sum_{k=2}^{n}\tilde{\pi}_{ik}^{(j)} x_{kt+1-j},\;~~i=2,\ldots,n.\]</span></p>
<p>For these forecasts, the corresponding forecast errors are:
<span class="math display">\[\begin{aligned}
    &amp; e_{it+1}^{(u)} = x_{1t+1} - x_{1t+1|t}^{(u)}\\
    &amp; e_{it+1}^{(r)} = x_{1t+1} - x_{1t+1|t}^{(r)}
\end{aligned}\]</span></p>
<p>The out-of-sample forecast errors are then evaluated by comparing the loss functions based on these forecasts errors. For example, assuming quadratic loss, and <span class="math inline">\(P\)</span> out-of-sample forecasts:
<span class="math display">\[\begin{aligned}
RMSFE^{(u)} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{iR+s|R-1+s}^{(u)}\right)^2} \\
RMSFE^{(r)} &amp;= \sqrt{\frac{1}{P}\sum_{s=1}^{P}\left(e_{iR+s|R-1+s}^{(r)}\right)^2}
\end{aligned}\]</span>
where <span class="math inline">\(R\)</span> is the size of the (first) estimation window.</p>
<p><span class="math inline">\(\{X_1\}\)</span> is said to cause <em>in Granger sense</em> <span class="math inline">\(\{X_{i\ne 1}\}\)</span> if <span class="math inline">\(RMSFE^{(u)} &lt; RMSFE^{(r)}\)</span>.</p>

</div>
</div>
</div>
<p style="text-align: center;">
<a href="autoregression.html"><button class="btn btn-default">Previous</button></a>
<a href="threshold-autoregression.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2023-03-26
 using 
R version 4.2.2 (2022-10-31 ucrt)
</p>
</div>
</div>



</body>
</html>
