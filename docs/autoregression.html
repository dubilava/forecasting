<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 – Autoregression | Educated Guess</title>
  <meta name="description" content="Forecasting With Time Series Models Using R" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 – Autoregression | Educated Guess" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/forecasting-logo.png" />
  <meta property="og:description" content="Forecasting With Time Series Models Using R" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 – Autoregression | Educated Guess" />
  
  <meta name="twitter:description" content="Forecasting With Time Series Models Using R" />
  <meta name="twitter:image" content="/forecasting-logo.png" />

<meta name="author" content="David Ubilava" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="seasonality.html"/>
<link rel="next" href="vector-autoregression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Educated Guess</a></li>
<li class="divider"></li>
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="chapter" data-level="" data-path="forecasting-with-time-series-models.html"><a href="forecasting-with-time-series-models.html"><i class="fa fa-check"></i>Forecasting With Time Series Models</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html"><i class="fa fa-check"></i><b>1</b> – Introduction to Forecasting</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#what-forecast-is-and-is-not"><i class="fa fa-check"></i><b>1.1</b> What Forecast Is and Is Not</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#a-brief-history-of-the-study-of-forecasting"><i class="fa fa-check"></i><b>1.2</b> A Brief History of the Study of Forecasting</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#through-the-lens-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Through the Lens of Causal Inference</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#self-fulfilling-prophecy"><i class="fa fa-check"></i><b>1.4</b> Self Fulfilling Prophecy</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#knowing-the-unknown"><i class="fa fa-check"></i><b>1.5</b> Knowing the Unknown</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#why-we-cant-get-it-right"><i class="fa fa-check"></i><b>1.6</b> Why We Can’t Get It Right</a></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#minimizing-the-risk-of-getting-it-wrong"><i class="fa fa-check"></i><b>1.7</b> Minimizing the Risk of Getting It Wrong</a></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-forecasting.html"><a href="introduction-to-forecasting.html#getting-it-right-for-the-right-reasons"><i class="fa fa-check"></i><b>1.8</b> Getting It Right for the Right Reasons</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="features-of-time-series-data.html"><a href="features-of-time-series-data.html"><i class="fa fa-check"></i><b>2</b> – Features of Time Series Data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="features-of-time-series-data.html"><a href="features-of-time-series-data.html#stochastic-process-and-time-series"><i class="fa fa-check"></i><b>2.1</b> Stochastic Process and Time Series</a></li>
<li class="chapter" data-level="2.2" data-path="features-of-time-series-data.html"><a href="features-of-time-series-data.html#stationarity"><i class="fa fa-check"></i><b>2.2</b> Stationarity</a></li>
<li class="chapter" data-level="2.3" data-path="features-of-time-series-data.html"><a href="features-of-time-series-data.html#serial-dependence"><i class="fa fa-check"></i><b>2.3</b> Serial Dependence</a></li>
<li class="chapter" data-level="2.4" data-path="features-of-time-series-data.html"><a href="features-of-time-series-data.html#transformations"><i class="fa fa-check"></i><b>2.4</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html"><i class="fa fa-check"></i><b>3</b> – Generating and Evaluating Forecasts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html#pseudo-forecasting-routine"><i class="fa fa-check"></i><b>3.1</b> Pseudo-Forecasting Routine</a></li>
<li class="chapter" data-level="3.2" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html#forecast-assessment"><i class="fa fa-check"></i><b>3.2</b> Forecast Assessment</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html#unbiasedness"><i class="fa fa-check"></i><b>3.2.1</b> Unbiasedness</a></li>
<li class="chapter" data-level="3.2.2" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html#efficiency"><i class="fa fa-check"></i><b>3.2.2</b> Efficiency</a></li>
<li class="chapter" data-level="3.2.3" data-path="generating-and-evaluating-forecasts.html"><a href="generating-and-evaluating-forecasts.html#no-autocorrelation"><i class="fa fa-check"></i><b>3.2.3</b> No Autocorrelation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="trends.html"><a href="trends.html"><i class="fa fa-check"></i><b>4</b> – Trends</a>
<ul>
<li class="chapter" data-level="4.1" data-path="trends.html"><a href="trends.html#trends-in-the-data"><i class="fa fa-check"></i><b>4.1</b> Trends in the Data</a></li>
<li class="chapter" data-level="4.2" data-path="trends.html"><a href="trends.html#spurious-relationships"><i class="fa fa-check"></i><b>4.2</b> Spurious Relationships</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="trends.html"><a href="trends.html#deterministic-trends"><i class="fa fa-check"></i><b>4.2.1</b> Deterministic Trends</a></li>
<li class="chapter" data-level="4.2.2" data-path="trends.html"><a href="trends.html#stochastic-trends"><i class="fa fa-check"></i><b>4.2.2</b> Stochastic Trends</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="trends.html"><a href="trends.html#modeling"><i class="fa fa-check"></i><b>4.3</b> Modeling</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="trends.html"><a href="trends.html#trends-in-mortgage-rates"><i class="fa fa-check"></i><b>4.3.1</b> Trends in mortgage rates</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="trends.html"><a href="trends.html#forecasting"><i class="fa fa-check"></i><b>4.4</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="seasonality.html"><a href="seasonality.html"><i class="fa fa-check"></i><b>5</b> – Seasonality</a>
<ul>
<li class="chapter" data-level="5.1" data-path="seasonality.html"><a href="seasonality.html#seasonal-fluctuations-in-the-data"><i class="fa fa-check"></i><b>5.1</b> Seasonal Fluctuations in the Data</a></li>
<li class="chapter" data-level="5.2" data-path="seasonality.html"><a href="seasonality.html#modeling-1"><i class="fa fa-check"></i><b>5.2</b> Modeling</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="seasonality.html"><a href="seasonality.html#seasonal-dummy-variables"><i class="fa fa-check"></i><b>5.2.1</b> Seasonal dummy variables</a></li>
<li class="chapter" data-level="5.2.2" data-path="seasonality.html"><a href="seasonality.html#seasonal-harmonic-variables"><i class="fa fa-check"></i><b>5.2.2</b> Seasonal harmonic variables</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="seasonality.html"><a href="seasonality.html#forecasting-1"><i class="fa fa-check"></i><b>5.3</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="autoregression.html"><a href="autoregression.html"><i class="fa fa-check"></i><b>6</b> – Autoregression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="autoregression.html"><a href="autoregression.html#stochastic-cycles"><i class="fa fa-check"></i><b>6.1</b> Stochastic Cycles</a></li>
<li class="chapter" data-level="6.2" data-path="autoregression.html"><a href="autoregression.html#modeling-2"><i class="fa fa-check"></i><b>6.2</b> Modeling</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="autoregression.html"><a href="autoregression.html#first-order-autoregression"><i class="fa fa-check"></i><b>6.2.1</b> First-order autoregression</a></li>
<li class="chapter" data-level="6.2.2" data-path="autoregression.html"><a href="autoregression.html#unit-roots-and-non-stationarity"><i class="fa fa-check"></i><b>6.2.2</b> Unit Roots and Non-stationarity</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="autoregression.html"><a href="autoregression.html#forecasting-2"><i class="fa fa-check"></i><b>6.3</b> Forecasting</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="autoregression.html"><a href="autoregression.html#iterative-method-of-multistep-forecasting"><i class="fa fa-check"></i><b>6.3.1</b> Iterative Method of Multistep Forecasting</a></li>
<li class="chapter" data-level="6.3.2" data-path="autoregression.html"><a href="autoregression.html#direct-method-of-multistep-forecasting"><i class="fa fa-check"></i><b>6.3.2</b> Direct Method of Multistep Forecasting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="vector-autoregression.html"><a href="vector-autoregression.html"><i class="fa fa-check"></i><b>7</b> – Vector Autoregression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="vector-autoregression.html"><a href="vector-autoregression.html#dynamic-feedbacks-among-economic-variables"><i class="fa fa-check"></i><b>7.1</b> Dynamic Feedbacks Among Economic Variables</a></li>
<li class="chapter" data-level="7.2" data-path="vector-autoregression.html"><a href="vector-autoregression.html#modeling-3"><i class="fa fa-check"></i><b>7.2</b> Modeling</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="vector-autoregression.html"><a href="vector-autoregression.html#in-sample-granger-causality"><i class="fa fa-check"></i><b>7.2.1</b> In-Sample Granger Causality</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="vector-autoregression.html"><a href="vector-autoregression.html#forecasting-3"><i class="fa fa-check"></i><b>7.3</b> Forecasting</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="vector-autoregression.html"><a href="vector-autoregression.html#one-step-ahead-forecasts"><i class="fa fa-check"></i><b>7.3.1</b> One-step-ahead forecasts</a></li>
<li class="chapter" data-level="7.3.2" data-path="vector-autoregression.html"><a href="vector-autoregression.html#multi-step-ahead-forecasts"><i class="fa fa-check"></i><b>7.3.2</b> Multi-step-ahead forecasts</a></li>
<li class="chapter" data-level="7.3.3" data-path="vector-autoregression.html"><a href="vector-autoregression.html#out-of-sample-granger-causality"><i class="fa fa-check"></i><b>7.3.3</b> Out-of-Sample Granger Causality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html"><i class="fa fa-check"></i><b>8</b> – Threshold Autoregression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#regime-dependent-nonlinearity"><i class="fa fa-check"></i><b>8.1</b> Regime-Dependent Nonlinearity</a></li>
<li class="chapter" data-level="8.2" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#modeling-4"><i class="fa fa-check"></i><b>8.2</b> Modeling</a></li>
<li class="chapter" data-level="8.3" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#forecasting-4"><i class="fa fa-check"></i><b>8.3</b> Forecasting</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#skeleton-extrapolation"><i class="fa fa-check"></i><b>8.3.1</b> Skeleton Extrapolation</a></li>
<li class="chapter" data-level="8.3.2" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#analytical-method"><i class="fa fa-check"></i><b>8.3.2</b> Analytical Method</a></li>
<li class="chapter" data-level="8.3.3" data-path="threshold-autoregression.html"><a href="threshold-autoregression.html#numerical-method-bootstrap-resampling"><i class="fa fa-check"></i><b>8.3.3</b> Numerical Method: Bootstrap Resampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html"><i class="fa fa-check"></i><b>9</b> – Comparing Forecasts</a>
<ul>
<li class="chapter" data-level="9.1" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html#the-need-for-the-forecast-evaluation"><i class="fa fa-check"></i><b>9.1</b> The Need for the Forecast Evaluation</a></li>
<li class="chapter" data-level="9.2" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html#relative-forecast-accuracy-tests"><i class="fa fa-check"></i><b>9.2</b> Relative Forecast Accuracy Tests</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html#the-morgan-granger-newbold-test"><i class="fa fa-check"></i><b>9.2.1</b> The Morgan-Granger-Newbold Test</a></li>
<li class="chapter" data-level="9.2.2" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html#the-diebold-mariano-test"><i class="fa fa-check"></i><b>9.2.2</b> The Diebold-Mariano Test</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="comparing-forecasts.html"><a href="comparing-forecasts.html#forecasting-year-on-year-monthly-inflation-12-steps-ahead"><i class="fa fa-check"></i><b>9.3</b> Forecasting Year-on-Year Monthly Inflation 12-steps-ahead</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="combining-forecasts.html"><a href="combining-forecasts.html"><i class="fa fa-check"></i><b>10</b> – Combining Forecasts</a>
<ul>
<li class="chapter" data-level="10.1" data-path="combining-forecasts.html"><a href="combining-forecasts.html#benefits-of-forecast-combination"><i class="fa fa-check"></i><b>10.1</b> Benefits of Forecast Combination</a></li>
<li class="chapter" data-level="10.2" data-path="combining-forecasts.html"><a href="combining-forecasts.html#optimal-weights-for-forecast-combination"><i class="fa fa-check"></i><b>10.2</b> Optimal Weights for Forecast Combination</a></li>
<li class="chapter" data-level="10.3" data-path="combining-forecasts.html"><a href="combining-forecasts.html#forecast-encompassing"><i class="fa fa-check"></i><b>10.3</b> Forecast Encompassing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="forecasting-using-r.html"><a href="forecasting-using-r.html"><i class="fa fa-check"></i>Forecasting Using R</a></li>
<li class="chapter" data-level="" data-path="tutorial-1-introduction-to-r.html"><a href="tutorial-1-introduction-to-r.html"><i class="fa fa-check"></i>Tutorial 1: Introduction to R</a>
<ul>
<li class="chapter" data-level="" data-path="tutorial-1-introduction-to-r.html"><a href="tutorial-1-introduction-to-r.html#base-r-and-matrix-manipulations"><i class="fa fa-check"></i>Base R and matrix manipulations</a></li>
<li class="chapter" data-level="" data-path="tutorial-1-introduction-to-r.html"><a href="tutorial-1-introduction-to-r.html#estimating-parameters-using-ols"><i class="fa fa-check"></i>Estimating parameters using OLS</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tutorial-2-data-management-and-visualisation.html"><a href="tutorial-2-data-management-and-visualisation.html"><i class="fa fa-check"></i>Tutorial 2: Data Management and Visualisation</a></li>
<li class="chapter" data-level="" data-path="tutorial-3-forecasting-methods-and-routines.html"><a href="tutorial-3-forecasting-methods-and-routines.html"><i class="fa fa-check"></i>Tutorial 3: Forecasting Methods and Routines</a></li>
<li class="chapter" data-level="" data-path="tutorial-4-trends.html"><a href="tutorial-4-trends.html"><i class="fa fa-check"></i>Tutorial 4: Trends</a></li>
<li class="chapter" data-level="" data-path="tutorial-5-seasonality.html"><a href="tutorial-5-seasonality.html"><i class="fa fa-check"></i>Tutorial 5: Seasonality</a></li>
<li class="chapter" data-level="" data-path="tutorial-6-autoregression.html"><a href="tutorial-6-autoregression.html"><i class="fa fa-check"></i>Tutorial 6: Autoregression</a></li>
<li class="chapter" data-level="" data-path="tutorial-7-vector-autoregression.html"><a href="tutorial-7-vector-autoregression.html"><i class="fa fa-check"></i>Tutorial 7: Vector Autoregression</a></li>
<li class="chapter" data-level="" data-path="tutorial-8-threshold-autoregression.html"><a href="tutorial-8-threshold-autoregression.html"><i class="fa fa-check"></i>Tutorial 8: Threshold Autoregression</a></li>
<li class="chapter" data-level="" data-path="tutorial-9-comparing-forecasts.html"><a href="tutorial-9-comparing-forecasts.html"><i class="fa fa-check"></i>Tutorial 9: Comparing Forecasts</a></li>
<li class="chapter" data-level="" data-path="tutorial-10-combining-forecasts.html"><a href="tutorial-10-combining-forecasts.html"><i class="fa fa-check"></i>Tutorial 10: Combining Forecasts</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Educated Guess</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="autoregression" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> – Autoregression<a href="autoregression.html#autoregression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><img src="art/autoregression.png" /></p>
<div id="stochastic-cycles" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Stochastic Cycles<a href="autoregression.html#stochastic-cycles" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="newthought">Often there is</span> a cyclical pattern in economic time series. Cycles are characterized by a sequence of expansions and contractions, almost like in the case of seasonality. Unlike seasonality, however, a cycle is not contained within a calendar year and, moreover, the amplitude and length of cycles may vary from one another. Such cycles, which are (assumed to be) generated by random variables, are referred to as <em>stochastic cycles</em>.</p>
<p>Autoregressive stochastic cycle is a special and widely applied case of a stochastic cycle, where a random variable in a given period of a stochastic process is expressed as a function of random variables, of the same stochastic process, from preceding periods. That is:
<span class="math display">\[Y_t = f(Y_{t-1},Y_{t-2},\ldots),\;~~t=1,\ldots,T.\]</span> Autoregressive models, or simply <em>autoregressions</em> are deployed to approximate dynamics of such stochastic cycles.</p>
</div>
<div id="modeling-2" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Modeling<a href="autoregression.html#modeling-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An autoregression of order <span class="math inline">\(p\)</span>, denoted as <span class="math inline">\(AR(p)\)</span>, has the following functional form:
<span class="math display">\[y_t = \alpha + \beta_1 y_{t-1}+\beta_2 y_{t-2}+ \cdots + \beta_p y_{t-p}+\varepsilon_t,\]</span> where <span class="math inline">\(\varepsilon\sim iid~\text{N}\left(0,\sigma^2_{\varepsilon}\right)\)</span></p>
<p>The sum of the autoregressive parameters, <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span>, depicts the persistence of the series. The larger is the persistence (i.e., closer it is to one), the longer it takes for the effect of a shock to dissolve. The effect will, eventually, dissolve so long as the series are covariance-stationary.</p>
<p>The autocorrelation, <span class="math inline">\(\rho\)</span>, and partial autocorrelation, <span class="math inline">\(\pi\)</span>, functions of the covariance-stationary <span class="math inline">\(AR(p)\)</span> process have the following distinctive features:</p>
<ul>
<li><span class="math inline">\(\rho_1 = \pi_1\)</span>, and <span class="math inline">\(\pi_p = \beta_p\)</span>.</li>
<li>The values of <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span> determine the shape of the autocorrelation function (ACF); in any case, the smaller (in absolute terms) is the persistence measure, the faster the ACF decays toward zero.</li>
<li>The partial autocorrelation function (PACF) is characterized by “statistically significant” first <span class="math inline">\(p\)</span> spikes <span class="math inline">\(\pi_1 \neq 0,\ldots,\pi_p \neq 0\)</span>, and the remaining <span class="math inline">\(\pi_k = 0\)</span>, <span class="math inline">\(\forall k &gt; p\)</span>.</li>
</ul>
<p>In what follows, we consider the cases of the first-order autoregression as an illustration.</p>
<div id="first-order-autoregression" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> First-order autoregression<a href="autoregression.html#first-order-autoregression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A first-order autoregression is given by: <span class="math display">\[y_t = \alpha + \beta_1 y_{t-1} + \varepsilon_t,\]</span> where <span class="math inline">\(\alpha\)</span> is a constant term; <span class="math inline">\(\beta_1\)</span> is the <em>persistence</em> parameter; and <span class="math inline">\(\varepsilon_t\)</span> is a white noise process.</p>
<p>A necessary and sufficient condition for an <span class="math inline">\(AR(1)\)</span> process to be covariance stationary is that <span class="math inline">\(|\beta_1| &lt; 1\)</span>. We can see this by substituting recursively the lagged equations into the lagged dependent variables:
<span class="math display">\[
\begin{aligned}
y_t &amp;= \alpha + \beta_1 y_{t-1} + \varepsilon_t \notag \\
y_t &amp;= \alpha + \beta_1 (\alpha + \beta_1 y_{t-2} + \varepsilon_{t-1}) + \varepsilon_t \notag \\
&amp;= \alpha(1+\beta_1) + \beta_1^2 (\alpha + \beta_1 y_{t-3} + \varepsilon_{t-2}) + \beta_1\varepsilon_{t-1} + \varepsilon_t \notag \\
&amp;\vdots  \notag \\
&amp;= \alpha\sum_{i=0}^{k-1}\beta_1^i + \beta_1^k y_{t-k} + \sum_{i=0}^{k-1}\beta_1^i\varepsilon_{t-i}
\end{aligned}
\]</span>
The end-result is a general linear process with geometrically declining coefficients. Here, <span class="math inline">\(|\beta_1| &lt; 1\)</span> is required for convergence.</p>
<p>Assuming <span class="math inline">\(|\beta_1| &lt; 1\)</span>, as <span class="math inline">\(k \to \infty\)</span> the process converges to: <span class="math display">\[y_t = \frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\]</span></p>
<p>The <em>unconditional mean</em> of this process is: <span class="math display">\[\mu = E\left(y_t\right) = E\left(\frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\right) = \frac{\alpha}{1-\beta_1}\]</span></p>
<p>The <em>unconditional variance</em> of this process is: <span class="math display">\[\gamma_0 = Var\left(y_t\right) = Var\left(\frac{\alpha}{1-\beta_1} + \sum_{i=0}^{\infty}\beta_1^i\varepsilon_{t-i}\right) = \frac{\sigma_{\varepsilon}^2}{1-\beta_1^2}\]</span></p>
<p>The <em>Autocovariance</em> is simply the covariance between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>, that is: <span class="math display">\[\gamma_k = Cov(y_t,y_{t-k}) = E[(y_t - \mu)(y_{t-k} - \mu)] = E(y_t y_{t-k}) - \mu^2\]</span></p>
<p>Some algebraic manipulation can help us show that: <span class="math display">\[\gamma_k = \beta_1\gamma_{k-1},\]</span> and that: <span class="math display">\[\rho_{k} = \beta_1\rho_{k-1}\]</span> (recall, <span class="math inline">\(\rho_k = \gamma_k/\gamma_0\)</span> is the autocorrelation coefficient).</p>
<p>In fact, for AR(1), an autocorrelation coefficient of some lag can be represented as the autoregression parameter (which in this instance is equivalent to the persistence measure) to that power. That is:
<span class="math display">\[
\begin{aligned}
\rho_1 &amp;= \beta_1\rho_0 = \beta_1 \notag \\
\rho_2 &amp;= \beta_1\rho_1 = \beta_1^2 \notag \\
&amp;\vdots \notag \\
\rho_k &amp;= \beta_1\rho_{k-1} = \beta_1^k
\end{aligned}
\]</span></p>
<p>It follows that the autocorrelation function of a covariance stationary AR(1) is a geometric decay; the smaller is <span class="math inline">\(|\beta_1|\)</span> the more rapid is the decay.</p>
<p>Moreover, a smaller persistence parameter results in a quicker adjustment to the <em>unconditional mean</em> of the process.</p>
</div>
<div id="unit-roots-and-non-stationarity" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Unit Roots and Non-stationarity<a href="autoregression.html#unit-roots-and-non-stationarity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A special case of an AR(1) process is a random walk with drift. The latter is obtained by setting <span class="math inline">\(\beta_1=1\)</span>. Note that the unconditional mean and variance are undefined under this restriction.</p>
<p>We cannot directly test the null of non-stationarity in an autoregression. That is, we cannot just estimate: <span class="math display">\[y_t = \alpha+\beta_1 y_{t-1}+\varepsilon_t\]</span> and test whether <span class="math inline">\(\hat{\beta}_1\)</span> is statistically significantly less than unity.</p>
<p>Instead, we can subtract <span class="math inline">\(y_{t-1}\)</span> from both sides of the equation, and estimate: <span class="math display">\[\Delta y_t = \alpha+\phi y_{t-1}+\varepsilon_t,\]</span> where <span class="math inline">\(\phi=\beta_1-1\)</span>, and test whether <span class="math inline">\(\hat{\phi}\)</span> is statistically significantly less than zero. This test is known as the Dickey-Fuller (DF) test.</p>
<p>In practice, we apply the augmented Dickey-Fuller (ADF) test, which is the same test as above, except the lags of the dependent variable, <span class="math inline">\(\Delta y_t\)</span>, are added to the regression to ensure that <span class="math inline">\(\varepsilon_t\)</span> is white noise.</p>
<p>It is important to note that distribution of the test statistic is non-standard. That is, we can not use t distribution to test the null hypothesis of non-stationarity after obtaining the test statistic associated with <span class="math inline">\(\hat{\phi}\)</span>. Instead, we use the relevant version of the Dickey-Fuller table.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<p>To illustrate some of the foregoing, consider the USD/EUR exchange rates.</p>
<div class="figure"><span style="display:block;" id="fig:exchange"></span>
<img src="forecasting_files/figure-html/exchange-1.png" alt="USD/EUR exchange rates" width="624" />
<p class="caption">
Figure 6.1: USD/EUR exchange rates
</p>
</div>
<p>First, let’s observe the autocorrelation and partial autocorrelation functions of the series.</p>
<div class="figure"><span style="display:block;" id="fig:acfexchange"></span>
<img src="forecasting_files/figure-html/acfexchange-1.png" alt="Autocorrelation function" width="624" />
<p class="caption">
Figure 6.2: Autocorrelation function
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:pacfexchange"></span>
<img src="forecasting_files/figure-html/pacfexchange-1.png" alt="Partial autocorrelation function" width="624" />
<p class="caption">
Figure 6.3: Partial autocorrelation function
</p>
</div>
<p>That autocorrelations decrease gradually and eventually become statistically indistinguishable from zero is suggestive of a stationary process. That partial autocorrelations of the first two lags are statistically significantly different from zero is suggestive of the second-order autoregression.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p>Let’s check formally, using augmented Dickey-Fuller test, whether the series are non-stationary. For that, estimate <span class="math inline">\(\Delta y_t=\alpha+\phi y_{t-1}+\delta_1\Delta y_{t-1}+\varepsilon_t\)</span>, and obtain test statistics associated with <span class="math inline">\(\hat{\phi}\)</span>. The test statistic turns out to be -2.757 which lies between the critical values of -2.88 for 5% statistical significance and -2.57 for 10% statistical significance.</p>
</div>
</div>
<div id="forecasting-2" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Forecasting<a href="autoregression.html#forecasting-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Making forecasts for some future period, <span class="math inline">\(t+h\)</span>, from an AR(p) model that has been fit to the data up to and including period <span class="math inline">\(t+h-1\)</span> can be a straightforward exercise, so long as we have access to such data. That is the case for one-step-ahead forecasts, that is when <span class="math inline">\(h=1\)</span>, for which the information set is readily available. For multi-step-ahead forecasts, that is when <span class="math inline">\(h&gt;1\)</span>, this no longer it the case. There are two approaches or methods of multi-step-ahead forecasting that can allowe us to circumvent the issue.</p>
<div id="iterative-method-of-multistep-forecasting" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Iterative Method of Multistep Forecasting<a href="autoregression.html#iterative-method-of-multistep-forecasting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One approach involves ‘coming up’ with the value of the variable that has not been realized yet. For example, when making a two-step-ahead forecast for period <span class="math inline">\(t+2\)</span>, we need data from period <span class="math inline">\(t+1\)</span>, which is not available at the time when the forecast is made. Instead, we need to use our forecast for period <span class="math inline">\(t+1\)</span>. The same applies to forecasts for any subsequent periods in the future. This approach is known as an <em>iterative</em> method of forecasting, wherein we make forecast for some period using the available data, then iterate forward by one period and use the most recent forecast to make the next period’s forecast, and so on and so forth.</p>
<p>Consider an AR(p) model. A future realization of the random variable is <span class="math display">\[y_{t+h} = \alpha + \beta_1 y_{t+h-1} + \cdots  + \beta_p y_{t+h-p}+\varepsilon_{t+h}\]</span></p>
<p>Point forecast (ignoring parameter uncertainty) is: <span class="math display">\[y_{t+h|t} = E(y_{t+h}|\Omega_t) = \alpha + \beta_1 y_{t+h-1|t} + \cdots  + \beta_p y_{t+h-p|t},\]</span> where <span class="math inline">\(y_{t+h-j|t}=y_{t+h-j}\)</span> when <span class="math inline">\(h-j\le 0\)</span>. That is, for a given time period, we use the realization of the random variable if it is observed, otherwise we use the point forecast of the realization.</p>
<p>Forecast error: <span class="math display">\[e_{t+h|t} = y_{t+h} - y_{t+h|t} = \beta_1 e_{t+h-1|t} + \cdots  + \beta_p e_{t+h-p|t} + \varepsilon_{t+h},\]</span> where <span class="math inline">\(e_{t+h-j|t}=0\)</span> when <span class="math inline">\(h-j\le 0\)</span>. So, when <span class="math inline">\(h=1\)</span>, <span class="math inline">\(e_{t+1|t}=\varepsilon_{t+1}\)</span>, which is the same as with previously described models (e.g., trend or seasonal models), but when <span class="math inline">\(h&gt;1\)</span>, forecast error becomes more complex.</p>
<p>The forecast variance: <span class="math display">\[\sigma_{t+h|t}^2 = \sigma_{\varepsilon}^2 + \sum_{i=1}^{p}\beta_i^2 Var(e_{t+h-i|t}) + 2\sum_{i \neq j}\beta_i\beta_j Cov(e_{t+h-i|t},e_{t+h-j|t})\]</span>
These variance and covariances of forecast errors from preceding horizons are some functions of the in-sample error variance and model parameters.</p>
<p>The 95% interval forecast is: <span class="math display">\[y_{t+h|t} \pm 1.96 \hat{\sigma}_{\varepsilon}.\]</span></p>
<p>To illustrate the foregoing, let’s revisit the USD/EUR exchange rate series, and obtain point and interval forecasts for periods from January 2011 onward based on parameter estimates of the second-order autoregression using data up to and including December 2010.</p>
<div class="figure"><span style="display:block;" id="fig:forexchange"></span>
<img src="forecasting_files/figure-html/forexchange-1.png" alt="Second-order autoregression" width="624" />
<p class="caption">
Figure 6.4: Second-order autoregression
</p>
</div>
</div>
<div id="direct-method-of-multistep-forecasting" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Direct Method of Multistep Forecasting<a href="autoregression.html#direct-method-of-multistep-forecasting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The other approach entails directly obtaining multi-step-ahead forecasts. To illustrate, consider a first-order autoregression: <span class="math inline">\(y_t=\alpha+\beta_1 y_{t-1}+\varepsilon_t.\)</span></p>
<p>One-step-ahead point forecast is readily given by: <span class="math inline">\(y_{t+1|t}=\alpha+\beta_1 y_{t}\)</span>. That is, we observe all the variables on the right-hand side of the equation.</p>
<p>To generate the two-step-ahead forecast in a similar manner, that is by ensuring the observed variables on the right-hand side of the equation, we can substitute <span class="math inline">\(y_{t-1}=\alpha+\beta_1 y_{t-2}+\varepsilon_{t-1}\)</span> into the original equation to obtain: <span class="math display">\[y_t=\alpha(1+\beta_1)+\beta_1^2y_{t-2} + \varepsilon_t + \beta_1\varepsilon_{t-1} = \tilde{\alpha} + \tilde{\beta}_1 y_{t-2} + u_t,\]</span> where <span class="math inline">\(\tilde{\alpha}=\alpha(1+\beta_1)\)</span> and <span class="math inline">\(\tilde{\beta}_1=\beta_1^2\)</span>, and <span class="math inline">\(u_t=\varepsilon_t + \beta_1\varepsilon_{t-1}.\)</span></p>
<p>Thus, we can obtain two-step-ahead forecast in a manner similar to that when we obtain one-step-ahead forecast by regressing <span class="math inline">\(y_t\)</span> on <span class="math inline">\(y_{t-2}\)</span>, and then directly forecasting <span class="math inline">\(y_{t+2}\)</span> from <span class="math inline">\(y_{t}\)</span>.</p>
<p>This <em>direct</em> method of multi-step-ahead forecasting can be extended to higher order autoregression, as well as to any forecast horizon.</p>
<p>In the direct method, error terms are serially correlated (by construction).<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> For example, in the direct two-step-ahead forecast from a re-specified AR(1) model, as we saw: <span class="math inline">\(u_t = \varepsilon_t+\beta_1\varepsilon_{t-1}\)</span>. It then follows that: <span class="math display">\[\sigma^2_u = E\left[(\varepsilon_t+\beta_1\varepsilon_{t-1})^2\right] = \sigma^2_{\varepsilon}(1+\beta_1^2).\]</span></p>
<p>This is also the expression of the two-step-ahead forecast error variance under the iterated method.</p>
<p>Thus, when applying the direct method of forecasting, interval forecasts for a given horizon are obtained ‘directly,’ based on the standard deviation of the residuals.</p>
<p>The relative performance of forecasts from the considered two methods—iterative and direct—in terms of bias and efficiency depends on the bias and efficiency of the estimators of each method.</p>
<p>Assuming the autoregressive model is correctly specified, both methods are consistent, but the iterative method is more efficient. Thus, in large samples, the iterative forecast can be expected to perform better than the direct forecast.</p>
<p>In the case of a mis-specified model, however, the direct method may as well outperform the iterated method.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="15">
<li id="fn15"><p>The three versions of the test are (i) unit root, (ii) unit root with drift, and (iii) unit root with drift and trend.<a href="autoregression.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>More formally, the order of autoregression can be determined using an information criterion such as AIC or SIC.<a href="autoregression.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Recall that multi-step-ahead forecast errors tend to be serially correlated. So, direct method merely maintains this feature of multistep forecasts.<a href="autoregression.html#fnref17" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="seasonality.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vector-autoregression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
